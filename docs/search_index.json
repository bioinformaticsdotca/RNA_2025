[["index.html", "RNA-seq Analysis 2025 Workshop Info Class Photo Schedule Pre-work", " RNA-seq Analysis 2025 Faculty: Malachi Griffith and Obi Griffith July 7-9, 2025 Workshop Info Lecture slides are available here Mini-lecture slides are available here Lab instructions are available here Class Photo Schedule Pre-work You can find your pre-work here. "],["meet-your-faculty.html", "Meet Your Faculty", " Meet Your Faculty "],["module-0-introductions-and-environment-setup.html", "Module 0: Introductions and Environment Setup Lecture Environment Setup Tool Installation", " Module 0: Introductions and Environment Setup Lecture Environment Setup This tutorial assumes use of a Linux computer with an ‘x86_64’ architecture. The rest of the tutorial should be conducted in a linux Terminal session. In other words you must already be logged into the Amazon EC2 instance as described in the previous section. Before proceeding you must define a global working directory by setting the environment variable: ‘RNA_HOME’ Log into a server and SET THIS BEFORE RUNNING EVERYTHING. Create a working directory and set the ‘RNA_HOME’ environment variable mkdir -p ~/workspace/rnaseq/ export RNA_HOME=~/workspace/rnaseq Make sure whatever the working dir is, that it is set and is valid echo $RNA_HOME Since all the environment variables we set up for the RNA-seq workshop start with ‘RNA’ we can easily view them all by combined use of the env and grep commands as shown below. The env command shows all environment variables currently defined and the grep command identifies string matches. env | grep RNA You can place the RNA_HOME variable (and other environment variables) in your .bashrc and then logout and login again to avoid having to worry about it. A .bashrc file with these variables has already been created for you. In order to view the contents of this file, you can type: less ~/.bashrc To exit the file, type q. Environment variables used throughout this tutorial: export RNA_HOME=~/workspace/rnaseq export RNA_DATA_DIR=$RNA_HOME/data export RNA_DATA_TRIM_DIR=$RNA_DATA_DIR/trimmed export RNA_REFS_DIR=$RNA_HOME/refs export RNA_REF_INDEX=$RNA_REFS_DIR/chr22_with_ERCC92 export RNA_REF_FASTA=$RNA_REF_INDEX.fa export RNA_REF_GTF=$RNA_REF_INDEX.gtf export RNA_ALIGN_DIR=$RNA_HOME/alignments/hisat2 We will be using picard tools throughout this workshop. To follow along, you will need to set an environment variable pointing to your picard installation. export PICARD=/home/ubuntu/bin/picard.jar For simplicity, we are going to download a preconfigured .bashrc file to use. cd ~ wget http://genomedata.org/rnaseq-tutorial/bashrc_copy mv bashrc_copy ~/.bashrc source ~/.bashrc Now if you run the following command, you should see the RNA environment variables present. env | grep RNA Alternatively, you could have add these enivroment variables manually if they were not part of your .bashrc. First, you can open your .bashrc file with nano by simply typing: nano ~/.bashrc You can now see the contents of this file. Then, you want to add the above environment variables to the bottom of the file. You can do this by copying and pasting. Once you have the variables in the file, you’ll want to type ctrl + o to save the file, then enter to confirm you want the same filename, then ctrl + x to exit nano. Again, check all the RNA related environment variables to make sure things look right. env | grep RNA Note that if you are doing this course on the Google Cloud Platform instead of AWS, you should instead use this .bashrc file: http://genomedata.org/rnaseq-tutorial/bashrc_copy_gcp.sh Tool Installation Note First, make sure your environment is set up correctly. Tools needed for this analysis are: samtools, bam-readcount, HISAT2, stringtie, gffcompare, htseq-count, gtf_to_fasta (TopHat), kallisto, FastQC, Fastp, MultiQC, Picard, Regtools, RSeqQC, bedops, gtfToGenePred, genePredToBed, how_are_we_stranded_here, CellRanger, R, BioConductor, ballgown, and other R packages. In the following installation example, the installs are local and will work whether you have root (i.e. admin) access or not. However, if root is available some binaries can/will be copied to system-wide locations (e.g., ~/bin/). Set up tool installation location: cd $RNA_HOME mkdir student_tools cd student_tools SAMtools Installation type: build C++ binary from source code using make. Citation: PMID: 19505943. The following tool is installed by downloading a compressed archive using wget, decompressing it using bunzip2, unpacking the archive using tar, and building the source code using make to run compiler commands in the “Makefile” provided with the tool. When make is run without options, it attempts the “default goal” in the make file which is the first “target” defined. In this case the first “target” is :all. Once the build is complete, we test that it worked by attempting to execute the samtools binary. Remember that the ./ in ./samtools tells the commandline that you want to execute the samtools binary in the current directory. We do this because there may be other samtools binaries in our PATH. Try which samtools to see the samtools binary that appears first in our PATH and therefore will be the one used when we specify samtools without specifying a particular location of the binary. cd $RNA_HOME/student_tools/ wget https://github.com/samtools/samtools/releases/download/1.18/samtools-1.18.tar.bz2 bunzip2 samtools-1.18.tar.bz2 tar -xvf samtools-1.18.tar cd samtools-1.18 make ./samtools bam-readcount Installation type: build C++ binary from source code using cmake and make. Citation: PMID: 34341766. Installation of the bam-readcount tool involves “cloning” the source code with a code version control system called git. The code is then compiled using cmake and make. cmake is an application for managing the build process of software using a compiler-independent method. It is used in conjunction with native build environments such as make (cmake ref). Note that bam-readcount relies on another tool, samtools, as a dependency. An environment variable is used to specify the path to the samtools install. cd $RNA_HOME/student_tools/ export SAMTOOLS_ROOT=$RNA_HOME/student_tools/samtools-1.18 git clone https://github.com/genome/bam-readcount cd bam-readcount mkdir build cd build cmake .. make ./bin/bam-readcount HISAT2 Installation type: download a precompiled binary. Citation: PMID: 31375807. The hisat2 aligner is installed below by simply downloading an archive of binaries using wget, unpacking them with unzip, and testing the tool to make sure it executes without error on the current system. This approach relies on understanding the architecture of your system and downloading the correct precompiled binary. The uname -m command lists the current system architecture. uname -m cd $RNA_HOME/student_tools/ curl -s https://cloud.biohpc.swmed.edu/index.php/s/oTtGWbWjaxsQ2Ho/download &gt; hisat2-2.2.1-Linux_x86_64.zip unzip hisat2-2.2.1-Linux_x86_64.zip cd hisat2-2.2.1 ./hisat2 -h StringTie Installation type: download a precompiled binary. Citation: PMID: 25690850. The stringtie reference guided transcript assembly and abundance estimation tool is installed below by simply downloading an archive with wget, unpacking the archive with tar, and executing stringtie to confirm it runs without error on our system. cd $RNA_HOME/student_tools/ wget http://ccb.jhu.edu/software/stringtie/dl/stringtie-2.2.1.tar.gz tar -xzvf stringtie-2.2.1.tar.gz cd stringtie-2.2.1 make release ./stringtie -h gffcompare Installation type: download a precompiled binary. Citation: PMID: 25690850. The gffcompare tool for comparing transcript annotations is installed below by simply downloading an archive with wget, unpacking it with tar, and executing gffcompare to ensure it runs without error on our system. cd $RNA_HOME/student_tools/ wget http://ccb.jhu.edu/software/stringtie/dl/gffcompare-0.12.6.Linux_x86_64.tar.gz tar -xzvf gffcompare-0.12.6.Linux_x86_64.tar.gz cd gffcompare-0.12.6.Linux_x86_64/ ./gffcompare htseq-count Installation type: pip install. Citation: PMID: 25260700. The htseq-count read counting tools is a python package that can be installed using pip. pip3 install --user HTSeq TopHat Installation type: dowload a precompiled binary. Citation: PMID: 19289445. Note, this tool is currently only installed for the gtf_to_fasta tool used in kallisto section. cd $RNA_HOME/student_tools/ wget http://genomedata.org/rnaseq-tutorial/tophat-2.1.1.Linux_x86_64.tar.gz tar -zxvf tophat-2.1.1.Linux_x86_64.tar.gz cd tophat-2.1.1.Linux_x86_64/ ./gtf_to_fasta kallisto Installation type: download a precompiled binary. Citation: PMID: 27043002. The kallisto alignment free expression estimation tool is installed below simply by downloading an archive with wget, unpacking the archive with tar, and testing the binary to ensure it runs on our system. cd $RNA_HOME/student_tools/ wget https://github.com/pachterlab/kallisto/releases/download/v0.44.0/kallisto_linux-v0.44.0.tar.gz tar -zxvf kallisto_linux-v0.44.0.tar.gz cd kallisto_linux-v0.44.0/ ./kallisto FastQC Installation type: download precompiled binary. Citation: s-andrews/FastQC. cd $RNA_HOME/student_tools/ wget https://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.12.1.zip unzip fastqc_v0.12.1.zip cd FastQC/ chmod 755 fastqc ./fastqc --help Fastp Installation type: download precompiled binary. Citation: PMID: 30423086 cd $RNA_HOME/student_tools/ mkdir fastp cd fastp wget http://opengene.org/fastp/fastp chmod a+x ./fastp ./fastp MultiQC Installation type: use pip. Citation: PMID: 27312411. Multiqc, a tool for assembling QC reports is a python package that can be installed using the python package manager pip. pip3 install multiqc export PATH=/home/ubuntu/.local/bin:$PATH multiqc --help Picard Installation type: download java jar file. Citation: broadinstitute/picard. Picard is a rich tool kit for BAM file manipulation that is installed below simply by downloading a jar file. The jar file is tested using Java, a dependency that must also be installed (it should already be present in many systems). cd $RNA_HOME/student_tools/ wget https://github.com/broadinstitute/picard/releases/download/2.26.4/picard.jar -O picard.jar java -jar $RNA_HOME/student_tools/picard.jar RegTools Installation type: compile from source code using cmake and make. Citation: bioRXiv: 10.1101/436634v2. cd $RNA_HOME/student_tools/ git clone https://github.com/griffithlab/regtools cd regtools/ mkdir build cd build/ cmake .. make ./regtools RSeQC Installation type: use pip. Citation: PMID: 22743226. pip3 install RSeQC read_GC.py bedops Installation type: download precompiled binary. Citation: PMID: 22576172. cd $RNA_HOME/student_tools/ mkdir bedops_linux_x86_64-v2.4.41 cd bedops_linux_x86_64-v2.4.41 wget -c https://github.com/bedops/bedops/releases/download/v2.4.41/bedops_linux_x86_64-v2.4.41.tar.bz2 tar -jxvf bedops_linux_x86_64-v2.4.41.tar.bz2 ./bin/bedops gtfToGenePred Installation type: download precompiled binary. cd $RNA_HOME/student_tools/ mkdir gtfToGenePred cd gtfToGenePred wget -c http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/gtfToGenePred chmod a+x gtfToGenePred ./gtfToGenePred genePredToBed Installation type: download precompiled binary. cd $RNA_HOME/student_tools/ mkdir genePredToBed cd genePredToBed wget -c http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/genePredToBed chmod a+x genePredToBed ./genePredToBed how_are_we_stranded_here pip3 install git+https://github.com/kcotto/how_are_we_stranded_here.git check_strandedness Install Cell Ranger Must register to get download link, modify command below to match downloaded tar cd $RNA_HOME/student_tools/ wget `download_link` tar -xzvf cellranger-7.2.0.tar.gz Install R #sudo apt-get remove r-base-core #wget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo gpg --dearmor -o /usr/share/keyrings/r-project.gpg #echo &quot;deb [signed-by=/usr/share/keyrings/r-project.gpg] https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/&quot; | sudo tee -a /etc/apt/sources.list.d/r-project.list #sudo apt update #sudo apt install --no-install-recommends r-base Note, if X11 libraries are not available you may need to use --with-x=no during config, on a regular linux system you would not use this option. Also, linking the R-patched bin directory into your PATH may cause weird things to happen, such as man pages or git log to not display. This can be circumvented by directly linking the R* executables (R, RScript, RCmd, etc.) into a PATH directory. R Libraries Installation type: add new base R libraries to an R installation. For this tutorial we require: devtools dplyr gplots ggplot2 launch R (enter R at linux command prompt) and type the following at an R command prompt. NOTE: This has been pre-installed for you, so these commands can be skipped. #R #install.packages(c(&quot;devtools&quot;,&quot;dplyr&quot;,&quot;gplots&quot;,&quot;ggplot2&quot;),repos=&quot;http://cran.us.r-project.org&quot;) #quit(save=&quot;no&quot;) Bioconductor Installation type: add bioconductor libraries to an R installation. Citation: PMID: 15461798. For this tutorial we require: genefilter ballgown. Citation: PMID: 25748911. edgeR. Citation: PMID: 19910308. GenomicRanges rhdf5 biomaRt. Citation: PMID: 21930506. launch R (enter R at linux command prompt) and type the following at an R command prompt. If prompted, type “a” to update all old packages. NOTE: This has been pre-installed for you, so these commands can be skipped. #R #source(&quot;http://bioconductor.org/biocLite.R&quot;) #biocLite(c(&quot;genefilter&quot;,&quot;ballgown&quot;,&quot;edgeR&quot;,&quot;GenomicRanges&quot;,&quot;rhdf5&quot;,&quot;biomaRt&quot;)) #quit(save=&quot;no&quot;) Sleuth Installation type: R package installation from a git repository. Citation: PMID: 28581496. #R #install.packages(&quot;devtools&quot;) #devtools::install_github(&quot;pachterlab/sleuth&quot;) #quit(save=&quot;no&quot;) PRACTICAL EXERCISE 1 - Software Installation Assignment: Install bedtools on your own. Make sure you install it in your tools folder. Download, unpack, compile, and test the bedtools software. Citation: PMID: 20110278. cd $RNA_HOME/student_tools/ Hint: google “bedtools” to find the source code Hint: there is a README file that will give you hints on how to install Hint: If your install has worked you should be able to run bedtools as follows: $RNA_HOME/student_tools/bedtools2/bin/bedtools Questions What happens when you run bedtools without any options? Where can you find detailed documentation on how to use bedtools? How many general categories of analysis can you perform with bedtools? What are they? Solution: When you are ready you can check your approach against the Solutions Add locally installed tools to your PATH [OPTIONAL] To use the locally installed version of each tool without having to specify complete paths, you could add the install directory of each tool to your ‘$PATH’ variable and set some other environment variables: PATH=$RNA_HOME/student_tools/genePredToBed:$RNA_HOME/student_tools/gtfToGenePred:$RNA_HOME/student_tools/bedops_linux_x86_64-v2.4.41/bin:$RNA_HOME/student_tools/samtools-1.18:$RNA_HOME/student_tools/bam-readcount/bin:$RNA_HOME/student_tools/hisat2-2.2.1:$RNA_HOME/student_tools/stringtie-2.2.1:$RNA_HOME/student_tools/gffcompare-0.12.6.Linux_x86_64:$RNA_HOME/student_tools/tophat-2.1.1.Linux_x86_64:$RNA_HOME/student_tools/kallisto_linux-v0.44.0:$RNA_HOME/student_tools/FastQC:$RNA_HOME/student_tools/fastp:$RNA_HOME/student_tools/regtools/build:/home/ubuntu/bin/bedtools2/bin:/home/ubuntu/.local/bin:$PATH echo $PATH export PICARD=$RNA_HOME/student_tools/picard.jar You can make these changes permanent by adding the above lines to your .bashrc file use a text editor to open your bashrc file. For example: vi ~/.bashrc Vi instructions Using your cursor, navigate down to the “export PATH” commands at the end of the file. Delete the line starting with PATH using the vi command “dd”. Press the “i” key to enter insert mode. Go to an empty line with you cursor and copy paste the new RNA_HOME and PATH commands into the file Press the “esc” key to exit insert mode. Press the “:” key to enter command mode. Type “wq” to save and quit vi If you would like to learn more about how to use vi, try this tutorial/game: VIM Adventures NOTE: If you are worried your .bashrc is messed up you can redownload as follows: cd ~ wget http://genomedata.org/rnaseq-tutorial/bashrc_copy mv bashrc_copy ~/.bashrc source ~/.bashrc Installing tools from official ubuntu packages [OPTIONAL] Some useful tools are available as official ubuntu packages. These can be installed using the linux package management system apt. Most bioinformatic tools (especially the latest versions) are not available as official packages. Nevertheless, here is how you would update your apt library, upgrade existing packages, and install an Ubuntu tool called tree. #sudo apt-get update #sudo apt-get upgrade #sudo apt-get install tree #tree Installing tools by Docker image Some tools have complex dependencies that are difficult to reproduce across systems or make work in the same environment with tools that require different versions of the same dependencies. Container systems such as Docker and Singularity allow you to isolate a tool’s environment giving you almost complete control over dependency issues. For this reason, many tool developers have started to distribute their tools as docker images. Many of these are placed in container image repositories such as DockerHub. Here is an example tool installation using docker. Install samtools: docker pull biocontainers/samtools:v1.9-4-deb_cv1 docker run -t biocontainers/samtools:v1.9-4-deb_cv1 samtools --help Install pvactools for personalized cancer vaccine designs: #docker pull griffithlab/pvactools:latest #docker run -t griffithlab/pvactools:latest pvacseq --help Installing tools by Docker image (using Singularity) Some systems do not allow docker to be run for various reasons. Sometimes singularity is used instead. The equivalent to the above but using singularity looks like the following: #singularity pull docker://griffithlab/pvactools:latest #singularity run docker://griffithlab/pvactools:latest pvacseq -h Note that if you encounter errors with /tmp space usage or would like to control where singularity stores its temp files, you can set the environment variables: #export SINGULARITY_CACHEDIR=/media/workspace/.singularity #export TMPDIR=/media/workspace/temp "],["module-1.html", "Module 1 Lecture Labs", " Module 1 Lecture Labs Module 1 Labs Module 1 - Key concepts Review central dogma, RNA sequencing, RNAseq study design, library construction strategies, biological vs technical replicates, alignment strategies, etc. Module 1 - Learning objectives Introduction to the theory and practice of RNA sequencing (RNA-seq) analysis Rationale for sequencing RNA Challenges specific to RNA-seq General goals and themes of RNA-seq analysis work flows Common technical questions related to RNA-seq analysis Getting help outside of this course Introduction to the RNA-seq hands on tutorial Lecture Introduction to RNA sequencing lecture FASTA/FASTQ/GTF formats mini lecture Indexing mini lecture FASTA/FASTQ/GTF mini lecture If you would like a refresher on common file formats such as FASTA, FASTQ, and GTF files, we have made a mini lecture briefly covering these. Obtain a reference genome from Ensembl, iGenomes, NCBI or UCSC. In this example analysis we will use the human GRCh38 version of the genome from Ensembl. Furthermore, we are actually going to perform the analysis using only a single chromosome (chr22) and the ERCC spike-in to make it run faster. First we will create the necessary working directory. cd $RNA_HOME echo $RNA_REFS_DIR mkdir -p $RNA_REFS_DIR The complete data from which these files were obtained can be found at: ftp://ftp.ensembl.org/pub/release-86/fasta/homo_sapiens/dna/. You could use wget to download the Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz file, then unzip/untar. We have prepared this simplified reference for you. It contains chr22 (and ERCC transcript) fasta files in both a single combined file and individual files. Download the reference genome file to the rnaseq working directory cd $RNA_REFS_DIR wget http://genomedata.org/rnaseq-tutorial/fasta/GRCh38/chr22_with_ERCC92.fa ls View the first 10 lines of this file. Why does it look like this? head chr22_with_ERCC92.fa How many lines and characters are in this file? How long is this chromosome (in bases and Mbp)? wc chr22_with_ERCC92.fa View 10 lines from approximately the middle of this file. What is the significance of the upper and lower case characters? head -n 425000 chr22_with_ERCC92.fa | tail What is the count of each base in the entire reference genome file (skipping the header lines for each sequence)? cat chr22_with_ERCC92.fa | grep -v &quot;&gt;&quot; | perl -ne &#39;chomp $_; $bases{$_}++ for split //; if (eof){print &quot;$_ $bases{$_}\\n&quot; for sort keys %bases}&#39; Note: Instead of the above, you might consider getting reference genomes and associated annotations from UCSC. e.g., UCSC GRCh38 download. Wherever you get them from, remember that the names of your reference sequences (chromosomes) must those matched in your annotation gtf files (described in the next section). View a list of all sequences in our reference genome fasta file. grep &quot;&gt;&quot; chr22_with_ERCC92.fa Note on complex commands and scripting in Unix Take a closer look at the command above that counts the occurrence of each nucleotide base in our chr22 reference sequence. Note that for even a seemingly simple question, commands can become quite complex. In that approach, a combination of Unix commands, pipes, and the scripting language Perl are used to answer the question. In bioinformatics, generally this kind of scripting comes up before too long, because you have an analysis question that is so specific there is no out of the box tool available. Or an existing tool will give perform a much more complex and involved analysis than needed to answer a very focused question. In Unix there are usually many ways to solve the same problem. Perl as a language has mostly fallen out of favor. This kind of simple text parsing problem is one area it perhaps still remains relevant. Let’s benchmark the run time of the previous approach and constrast with several alternatives that do not rely on Perl. Each of the following gives exactly the same answer. time is used to measure the run time of each alternative. Each starts by using cat to dump the file to standard out and then using grep to remove the header lines starting with “&gt;”. Each ends with column -t to make the output line up consistently. #1. The Perl approach. This command removes the end of line character with chomp, then it splits each line into an array of individual characters, amd it creates a data structure called a hash to store counts of each letter on each line. Once the end of the file is reached it prints out the contents of this data structure in order. time cat chr22_with_ERCC92.fa | grep -v &quot;&gt;&quot; | perl -ne &#39;chomp $_; $bases{$_}++ for split //; if (eof){print &quot;$bases{$_} $_\\n&quot; for sort keys %bases}&#39; | column -t #2. The Awk approach. Awk is an alternative scripting language include in most linux distributions. This command is conceptually very similar to the Perl approach but with a different syntax. A for loop is used to iterate over each character until the end (&quot;NF&quot;) is reached. Again the counts for each letter are stored in a simple data structure and once the end of the file is reach the results are printed. time cat chr22_with_ERCC92.fa | grep -v &quot;&gt;&quot; | awk &#39;{for (i=1; i&lt;=NF; i++){a[$i]++}}END{for (i in a){print a[i], i}}&#39; FS= - | sort -k 2 | column -t #3. The Sed approach. Sed is an alternative scripting language. &quot;tr&quot; is used to remove newline characters. Then sed is used simply to split each character onto its own line, effectively creating a file with millions of lines. Then unix sort and uniq are used to produce counts of each unique character, and sort is used to order the results consistently with the previous approaches. time cat chr22_with_ERCC92.fa | grep -v &quot;&gt;&quot; | tr -d &#39;\\n&#39; | sed &#39;s/\\(.\\)/\\1\\n/g&#39; - | sort | uniq -c | sort -k 2 | column -t #4. The grep appoach. The &quot;-o&quot; option of grep splits each match onto a line which we then use to get a count. The &quot;-i&quot; option makes the matching work for upper/lower case. The &quot;-P&quot; option allows us to use Perl style regular expressions with Greg. time cat chr22_with_ERCC92.fa | grep -v &quot;&gt;&quot; | grep -i -o -P &quot;a|c|g|t|y|n&quot; | sort | uniq -c #5. Finally, the simplest/shortest approach that leverages the unix fold command to split each character onto its own line as in the Sed example. time cat chr22_with_ERCC92.fa | grep -v &quot;&gt;&quot; | fold -w1 | sort | uniq -c | column -t Which method is fastest? Why are the first two approaches so much faster than the others? PRACTICAL EXERCISE 2 (ADVANCED) Assignment: Use a commandline scripting approach of your choice to further examine our chr22 reference genome file and answer the following questions. Questions: - How many bases on chromosome 22 correspond to repetitive elements? - What is the percentage of the whole length? - How many occurences of the EcoRI (GAATTC) restriction site are present in the chromosome 22 sequence? Hint: Each question can be tackled using approaches similar to those above, using the file ‘chr22_with_ERCC92.fa’ as a starting point. Hint: To make things simpler, first produce a file with only the chr22 sequence. Hint: Remember that repetitive elements in the sequence are represented in lower case Solution: When you are ready you can check your approach against the Solutions. FASTA/FASTQ/GTF mini lecture If you would like a refresher on common file formats such as FASTA, FASTQ, and GTF files, we have made a mini lecture briefly covering these. Obtain Known Gene/Transcript Annotations In this tutorial we will use annotations obtained from Ensembl (Homo_sapiens.GRCh38.86.gtf.gz) for chromosome 22 only. For time reasons, these are prepared for you and made available on your AWS instance. But you should get familiar with sources of gene annotations for RNA-seq analysis. Copy the gene annotation files to the working directory. echo $RNA_REFS_DIR cd $RNA_REFS_DIR wget http://genomedata.org/rnaseq-tutorial/annotations/GRCh38/chr22_with_ERCC92.gtf Take a look at the contents of the .gtf file. Press q to exit the less display. echo $RNA_REF_GTF less -p start_codon -S $RNA_REF_GTF Note how the -S option makes it easier to veiw this file with less. Make the formatting a bit nicer still: cat chr22_with_ERCC92.gtf | column -t | less -p exon -S How many unique gene IDs are in the .gtf file? We can use a perl command-line command to find out: perl -ne &#39;if ($_ =~ /(gene_id\\s\\&quot;ENSG\\w+\\&quot;)/){print &quot;$1\\n&quot;}&#39; $RNA_REF_GTF | sort | uniq | wc -l Using perl -ne '' will execute the code between single quotes, on the .gtf file, line-by-line. The $_ variable holds the contents of each line. The 'if ($_ =~//)' is a pattern-matching command which will look for the pattern “gene_id” followed by a space followed by “ENSG” and one or more word characters (indicated by \\w+) surrounded by double quotes. The pattern to be matched is enclosed in parentheses. This allows us to print it out from the special variable $1. The output of this perl command will be a long list of ENSG Ids. By piping to sort, then uniq, then word count we can count the unique number of genes in the file. We can also use grep to find this same information. cat chr22_with_ERCC92.gtf | grep -w gene | wc -l grep -w gene is telling grep to do an exact match for the string ‘gene’. This means that it will return lines that are of the feature type gene. Now view the structure of a single transcript in GTF format. Press q to exit the less display when you are done. grep ENST00000342247 $RNA_REF_GTF | less -p &quot;exon\\s&quot; -S To learn more, see: http://perldoc.perl.org/perlre.html#Regular-Expressions http://www.perl.com/pub/2004/08/09/commandline.html Definitions: Reference genome - The nucleotide sequence of the chromosomes of a species. Genes are the functional units of a reference genome and gene annotations describe the structure of transcripts expressed from those gene loci. Gene annotations - Descriptions of gene/transcript models for a genome. A transcript model consists of the coordinates of the exons of a transcript on a reference genome. Additional information such as the strand the transcript is generated from, gene name, coding portion of the transcript, alternate transcript start sites, and other information may be provided. GTF (.gtf) file - A common file format referred to as Gene Transfer Format used to store gene and transcript annotation information. You can learn more about this format here: http://genome.ucsc.edu/FAQ/FAQformat#format4 The Purpose of Gene Annotations (.gtf file) When running the HISAT2/StringTie/Ballgown pipeline, known gene/transcript annotations are used for several purposes: During the HISAT2 index creation step, annotations may be provided to create local indexes to represent transcripts as well as a global index for the entire reference genome. This allows for faster mapping and better mapping across exon boundaries and splice sites. If an alignment still can not be found it will attempt to determine if the read corresponds to a novel exon-exon junction. See the Indexing section and the HISAT2 publication for more details. During the StringTie step, a .gtf file can be used to specify transcript models to guide the assembly process and limit expression estimates to predefined transcripts using the -G and -e options together. The -e option will give you one expression estimate for each of the transcripts in your .gtf file, giving you a ‘microarray like’ expression result. During the StringTie step, if the -G option is specified without the -e option the .gtf file is used only to ‘guide’ the assembly of transcripts. Instead of assuming only the known transcript models are correct, the resulting expression estimates will correspond to both known and novel/predicted transcripts. During the StringTie and gffcompare steps, a .gtf file is used to determine the transcripts that will be examined for differential expression using Ballgown. These may be known transcripts that you download from a public source, or a .gtf of transcripts predicted by StringTie from the read data in an earlier step. Sources for obtaining gene annotation files formatted for HISAT2/StringTie/Ballgown There are many possible sources of .gtf gene/transcript annotation files. For example, from Ensembl, UCSC, RefSeq, etc. Several options and related instructions for obtaining the gene annotation files are provided below. I. ENSEMBL FTP SITE Based on Ensembl annotations only. Available for many species. http://useast.ensembl.org/info/data/ftp/index.html II. UCSC TABLE BROWSER Based on UCSC annotations or several other possible annotation sources collected by UCSC. You might chose this option if you want to have a lot of flexibility in the annotations you obtain. e.g. to grab only the transcripts from chromosome 22 as in the following example: Open the following in your browser: http://genome.ucsc.edu/ Select ‘Tools’ and then ‘Table Browser’ at the top of the page. Select ‘Mammal’, ‘Human’, and ‘Dec. 2013 (GRCh38/hg38)’ from the first row of drop down menus. Select ‘Genes and Gene Predictions’ and ‘GENCODE v29’ from the second row of drop down menus. To limit your selection to only chromosome 22, select the ‘position’ option beside ‘region’, enter ‘chr22’ in the ‘position’ box. Select ‘GTF - gene transfer format’ for output format and enter ‘UCSC_Genes.gtf’ for output file. Hit the ‘get output’ button and save the file. Make note of its location In addition to the .gtf file you may find uses for some extra files providing alternatively formatted or additional information on the same transcripts. For example: How to get a Gene bed file: Change the output format to ‘BED - browser extensible data’. Change the output file to ‘UCSC_Genes.bed’, and hit the ‘get output’ button. Make sure ‘Whole Gene’ is selected, hit the ‘get BED’ button, and save the file. How to get an Exon bed file: Go back one page in your browser and change the output file to ‘UCSC_Exons.bed’, then hit the ‘get output’ button again. Select ‘Exons plus’, enter 0 in the adjacent box, hit the ‘get BED’ button, and save the file. How to get gene symbols and descriptions for all UCSC genes: Again go back one page in your browser and change the ‘output format’ to ‘selected fields from primary and related tables’. Change the output file to ‘UCSC_Names.txt’, and hit the ‘get output’ button. Make sure ‘chrom’ is selected near the top of the page. Under ‘Linked Tables’ make sure ‘kgXref’ is selected, and then hit ‘Allow Selection From Checked Tables’. This will link the table and give you access to its fields. Under ‘hg38.kgXref fields’ select: ‘kgID’, ‘geneSymbol’, ‘description’. Hit the ‘get output’ button and save the file. To get annotations for the whole genome, make sure ‘genome’ is selected beside ‘region’. By default, the files downloaded above will be compressed. To decompress, use ‘gunzip filename’ in linux. III. HISAT2 Precomputed Genome Index HISAT2 has prebuilt reference genome index files for both DNA and RNA alignment. Various versions of the index files include SNPs and/or transcript splice sites. Versions of both the Ensembl and UCSC genomes for human build 38 are linked from the main HISAT2 page: https://ccb.jhu.edu/software/hisat2/index.shtml Or those same files are directly available from their FTP site: ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/ Important notes: On chromosome naming conventions: In order for your RNA-seq analysis to work, the chromosome names in your .gtf file must match those in your reference genome (i.e. your reference genome fasta file). If you get a StringTie result where all transcripts have an expression value of 0, you may have overlooked this. Unfortunately, Ensembl, NCBI, and UCSC can not agree on how to name the chromosomes in many species, so this problem may come up often. You can avoid this by getting a complete reference genome and gene annotation package from the same source (e.g., Ensembl) to maintain consistency. On reference genome builds: Your annotations must correspond to the same reference genome build as your reference genome fasta file. e.g., both correspond to UCSC human build ‘hg38’, NCBI human build ‘GRCh38’, etc. Even if both your reference genome and annotations are from UCSC or Ensembl they could still correspond to different versions of that genome. This would cause problems in any RNA-seq pipeline. A more detailed discussion of commonly used version of the human reference genome can be found in a companion workshop PMBIO Reference Genomes. Indexing mini lecture If you want a refresher on indexing, we have made an indexing mini lecture available. Create a HISAT2 index Create a HISAT2 index for chr22 and the ERCC spike-in sequences. HISAT2 can incorporate exons and splice sites into the index file for alignment. First create a splice site file, then an exon file. Finally make the aligner FM index. To learn more about how the HISAT2 indexing strategy is distinct from other next gen aligners refer to the HISAT publication. cd $RNA_REFS_DIR hisat2_extract_splice_sites.py $RNA_REF_GTF &gt; $RNA_REFS_DIR/splicesites.tsv hisat2_extract_exons.py $RNA_REF_GTF &gt; $RNA_REFS_DIR/exons.tsv hisat2-build -p 4 --ss $RNA_REFS_DIR/splicesites.tsv --exon $RNA_REFS_DIR/exons.tsv $RNA_REF_FASTA $RNA_REF_INDEX ls Perform a visual survey on the contents of your refs directory. What is the source/purpose of each file. [OPTIONAL] To create an index for all chromosomes instead of just chr22 you would do something like the following: WARNING: In order to index the entire human genome, HISAT2 requires 160GB of RAM. Your AWS instance size will run out of RAM. #hisat2_extract_splice_sites.py Homo_sapiens.GRCh38.86.gtf &gt; splicesites.tsv #hisat2_extract_exons.py Homo_sapiens.GRCh38.86.gtf &gt; exons.tsv #hisat2-build -p 4 --ss splicesites.tsv --exon exons.tsv Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa Homo_sapiens.GRCh38.dna_sm.primary_assembly Obtain RNA-seq test data. The test data consists of two commercially available RNA samples: Universal Human Reference (UHR) and Human Brain Reference (HBR). The UHR is total RNA isolated from a diverse set of 10 cancer cell lines (breast, liver, cervix, testis, brain, skin, fatty tissue, histocyte, macrophage, T cell, B cell). The HBR is total RNA isolated from the brains of 23 Caucasians, male and female, of varying age but mostly 60-80 years old. In addition, a spike-in control was used. Specifically we added an aliquot of the ERCC ExFold RNA Spike-In Control Mixes to each sample. The spike-in consists of 92 transcripts that are present in known concentrations across a wide abundance range (from very few copies to many copies). This range allows us to test the degree to which the RNA-seq assay (including all laboratory and analysis steps) accurately reflects the relative abundance of transcript species within a sample. There are two ‘mixes’ of these transcripts to allow an assessment of differential expression output between samples if you put one mix in each of your two comparisons. In our case, Mix1 was added to the UHR sample, and Mix2 was added to the HBR sample. We also have 3 complete experimental replicates for each sample. This allows us to assess the technical variability of our overall process of producing RNA-seq data in the lab. For all libraries we prepared low-throughput (Set A) TruSeq Stranded Total RNA Sample Prep Kit libraries with Ribo-Zero Gold to remove both cytoplasmic and mitochondrial rRNA. Triplicate, indexed libraries were made starting with 100ng Agilent/Strategene Universal Human Reference total RNA and 100ng Ambion Human Brain Reference total RNA. The Universal Human Reference replicates received 2 ul of 1:1000 ERCC Mix 1. The Human Brain Reference replicates received 1:1000 ERCC Mix 2. The libraries were quantified with KAPA Library Quantification qPCR and adjusted to the appropriate concentration for sequencing. The triplicate, indexed libraries were then pooled prior to sequencing. Each pool of three replicate libraries were sequenced across 2 lanes of a HiSeq 2000 using paired-end sequence chemistry with 100bp read lengths. So to summarize we have: UHR + ERCC Spike-In Mix1, Replicate 1 UHR + ERCC Spike-In Mix1, Replicate 2 UHR + ERCC Spike-In Mix1, Replicate 3 HBR + ERCC Spike-In Mix2, Replicate 1 HBR + ERCC Spike-In Mix2, Replicate 2 HBR + ERCC Spike-In Mix2, Replicate 3 Each data set has a corresponding pair of FASTQ files (read 1 and read 2 of paired end reads). echo $RNA_DATA_DIR mkdir -p $RNA_DATA_DIR cd $RNA_DATA_DIR wget http://genomedata.org/rnaseq-tutorial/HBR_UHR_ERCC_ds_5pc.tar Unpack the test data using tar. You should see 6 sets of paired end fastq files. One for each of our sample replicates above. We have 6 pairs (12 files) because in fastq format, read 1 and read 2 of a each read pair (fragment) are stored in separate files. tar -xvf HBR_UHR_ERCC_ds_5pc.tar ls Enter the data directory and view the first two read records of a file (in fastq format each read corresponds to 4 lines of data) The reads are paired-end 101-mers generated on an Illumina HiSeq instrument. The test data has been pre-filtered for reads that appear to map to chromosome 22. Lets copy the raw input data to our tutorial working directory. zcat UHR_Rep1_ERCC-Mix1_Build37-ErccTranscripts-chr22.read1.fastq.gz | head -n 8 Identify the following components of each read: read name, read sequence, and quality string How many reads are there in the first library? Decompress file on the fly with ‘zcat’, pipe into ‘grep’, search for the read name prefix and pipe into ‘wc’ to do a word count (‘-l’ gives lines) zcat UHR_Rep1_ERCC-Mix1_Build37-ErccTranscripts-chr22.read1.fastq.gz | grep -P &quot;^\\@HWI&quot; | wc -l Determining the strandedness of RNA-seq data (Optional) In order to determine strandedness, we will be using check_strandedness(docker image). In order use this tool, there are a few steps we need to get our inputs ready, specifically creating a fasta of our GTF file. To create a transcripts FASTA file from our reference transcriptome in GTF format we need to get our transcript information into BED12 format. To get to that format we will convert GTF -&gt; GenePred -&gt; BED12. The GenePred format is just an intermediate that we create because we did not find a tool that would convert straight from GTF to BED12. Once we have our transcriptome information (the position of exons for each transcript on each chromosome) we can use bedtools getfasta to splice the exon sequences from the chromosome sequence together into a full length transcript sequence. cd $RNA_HOME/refs/ # Convert our reference transcriptome GTF to genePred format gtfToGenePred chr22_with_ERCC92.gtf chr22_with_ERCC92.genePred # Convert the genPred format to bed12 format genePredToBed chr22_with_ERCC92.genePred chr22_with_ERCC92.bed12 # Use bedtools to create fasta from GTF bedtools getfasta -fi chr22_with_ERCC92.fa -bed chr22_with_ERCC92.bed12 -s -split -name -fo chr22_ERCC92_transcripts.fa Use less to view the file chr22_ERCC92_transcripts.fa. Note that this file has messy transcript names. Use the following hairball perl one-liner to tidy up the header line for each fasta sequence. cd $RNA_HOME/refs cat chr22_ERCC92_transcripts.fa | perl -ne &#39;if($_ =~/^\\&gt;\\S+\\:\\:(ERCC\\-\\d+)\\:.*/){print &quot;&gt;$1\\n&quot;}elsif ($_ =~/^\\&gt;(\\S+)\\:\\:.*/){print &quot;&gt;$1\\n&quot;}else{print $_}&#39; &gt; chr22_ERCC92_transcripts.clean.fa View the resulting ‘clean’ file using less chr22_ERCC92_transcripts.clean.fa (use ‘q’ to exit). View the end of this file using tail chr22_ERCC92_transcripts.clean.fa. Note that we have one fasta record for each Ensembl transcript on chromosome 22 and we have an additional fasta record for each ERCC spike-in sequence. We also need to reformat our GTF file slightly. Rows that correspond to genes are missing the “transcript_id” field. We are going to add in this field but leave it blank for these rows using the following command. cd $RNA_HOME/refs awk &#39;{ if ($0 ~ &quot;transcript_id&quot;) print $0; else print $0&quot; transcript_id \\&quot;\\&quot;;&quot;; }&#39; chr22_with_ERCC92.gtf &gt; chr22_with_ERCC92_tidy.gtf Now that we have created our input files, we can now run the check_strandedness tool on some of our instrument data. Note: we are using a docker image for this tool. docker run -v /home/ubuntu/workspace/rnaseq:/docker_workspace mgibio/checkstrandedness:latest check_strandedness --gtf /docker_workspace/refs/chr22_with_ERCC92_tidy.gtf --transcripts /docker_workspace/refs/chr22_ERCC92_transcripts.clean.fa --reads_1 /docker_workspace/data/HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read1.fastq.gz --reads_2 /docker_workspace/data/HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read2.fastq.gz docker run is how you initialize a docker container to run a command -v is the parameter used to mount your workspace so that the docker container can see the files that you’re working with. In the example above, /home/ubuntu/workspace/rnaseq from the EC2 instance has been mounted as /docker_workspace within the docker container. mgibio/checkstrandedness is the docker container name. The :latest refers to the specific tag and release of the docker container. The output of this command should look like so: Fraction of reads failed to determine: 0.1123 Fraction of reads explained by &quot;1++,1--,2+-,2-+&quot;: 0.0155 Fraction of reads explained by &quot;1+-,1-+,2++,2--&quot;: 0.8722 Over 75% of reads explained by &quot;1+-,1-+,2++,2--&quot; Data is likely RF/fr-firststrand Using this table, we can see if this is what we expect. Note that since the UHR and HBR data were generated with the TruSeq Stranded Kit, as mentioned above, the correct strand setting for kallisto is --rf-stranded, which is what check_strandedness confirms. Similarly when we run HISAT we will use --rna-strandness RF, when we run StringTie we will use --rf, and when we run htseq-count we will use --stranded reverse. PRACTICAL EXERCISE 3 Assignment: Download an additional dataset and unpack it. This data will be used in future practical exercises. Hint: Do this in a separate working directory called ‘practice’ and create sub-directories for organization (data, alignments, etc). In this exercise you will download an archive of publicly available read data from here: http://genomedata.org/rnaseq-tutorial/practical.tar The practice dataset includes 3 replicates of data from the HCC1395 breast cancer cell line and 3 replicates of data from HCC1395BL matched lymphoblastoid line. So, this will be a tumor vs normal (cell line) comparison. The reads are paired-end 151-mers generated on an Illumina HiSeq instrument from TruSeq Stranded Total RNA Libraries. The test data has been pre-filtered for reads that appear to map to chromosome 22. Questions How many data files were contained in the ‘practical.tar’ archive? What commonly used sequence data file format are they? In the first read of the hcc1395, normal, replicate 1, read 1 file, what was the physical location of the read on the flow cell (i.e. lane, tile, x, y)? In the first read of this same file, how many ‘T’ bases are there? Solution: When you are ready you can check your approach against the Solutions. NOTE: The complete RAW HCC1395 data sets can be found here: http://genomedata.org/pmbio-workshop/fastqs/all/ If you use this data, please cite our paper: Citation "],["module-2.html", "Module 2 Lecture Labs", " Module 2 Lecture Labs Module 2 Labs Module 2 - Key concepts Splice-aware alignment, SAM/BAM format, SAM flags, CIGAR strings, SAM sorting, etc. Module 2 - Learning objectives RNA-seq alignment challenges and common questions Alignment strategies HISAT2 Introduction to the BAM and BED formats Basic manipulation of BAMs Visualization of RNA-seq alignments in IGV Alignment QC Assessment BAM read counting and determination of variant allele expression status Lectures Introduction to alignment mini lecture Alignment/Assembly/kmer mini lecture SAM/BAM/BED formats mini lecture Introduction to IGV lecture Alignment QC mini lecture [OPTIONAL] Use Fastp to trim sequence adapter from the read FASTQ files and also perform basic data quality cleanup. The output of this step will be trimmed and filtered FASTQ files for each data set. Refer to the Fastp project and manual for a more detailed explanation: https://github.com/OpenGene/fastp Fastp basic usage: fastp -i in.R1.fq.gz -I in.R2.fq.gz -o out.R1.fq.gz -O out.R2.fq.gz The -i and -I parameters specify input R1 and R2 data files (raw data) The -o and -O parameters specify output R1 and R2 data files (trimmed and quality filtered) Extra options specified below: ‘-l 25’ the minimum read length allowed after trimming is 25bp ‘–adapter_fasta’ the path to the adapter FASTA file containing adapter sequences to trim ‘–trim_front1 13’ trim a fixed number (13 in this case) of bases off the left end of read1 ‘–trim_front2 13’ trim a fixed number (13 in this case) of bases off the left end of read2 ‘–json’ the path to store a log file in JSON file format ‘–html’ the path to store a web report file ‘2&gt;’ use to store the information that would be printed to the screen into a file instead Read trimming with Fastp First, set up some directories for output echo $RNA_DATA_TRIM_DIR mkdir -p $RNA_DATA_TRIM_DIR Download necessary Illumina adapter sequence files. echo $RNA_REFS_DIR mkdir -p $RNA_REFS_DIR cd $RNA_REFS_DIR wget http://genomedata.org/rnaseq-tutorial/illumina_multiplex.fa Use fastp to remove illumina adapter sequences (if any), trim the first 13 bases of each read, and perform default read quality filtering to remove reads that are too short, have too many low quality bases or have too many N’s. cd $RNA_HOME export S1=UHR_Rep1_ERCC-Mix1_Build37-ErccTranscripts-chr22 fastp -i $RNA_DATA_DIR/$S1.read1.fastq.gz -I $RNA_DATA_DIR/$S1.read2.fastq.gz -o $RNA_DATA_TRIM_DIR/$S1.read1.fastq.gz -O $RNA_DATA_TRIM_DIR/$S1.read2.fastq.gz -l 25 --adapter_fasta $RNA_REFS_DIR/illumina_multiplex.fa --trim_front1 13 --trim_front2 13 --json $RNA_DATA_TRIM_DIR/$S1.fastp.json --html $RNA_DATA_TRIM_DIR/$S1.fastp.html 2&gt;$RNA_DATA_TRIM_DIR/$S1.fastp.log export S2=UHR_Rep2_ERCC-Mix1_Build37-ErccTranscripts-chr22 fastp -i $RNA_DATA_DIR/$S2.read1.fastq.gz -I $RNA_DATA_DIR/$S2.read2.fastq.gz -o $RNA_DATA_TRIM_DIR/$S2.read1.fastq.gz -O $RNA_DATA_TRIM_DIR/$S2.read2.fastq.gz -l 25 --adapter_fasta $RNA_REFS_DIR/illumina_multiplex.fa --trim_front1 13 --trim_front2 13 --json $RNA_DATA_TRIM_DIR/$S2.fastp.json --html $RNA_DATA_TRIM_DIR/$S2.fastp.html 2&gt;$RNA_DATA_TRIM_DIR/$S2.fastp.log export S3=UHR_Rep3_ERCC-Mix1_Build37-ErccTranscripts-chr22 fastp -i $RNA_DATA_DIR/$S3.read1.fastq.gz -I $RNA_DATA_DIR/$S3.read2.fastq.gz -o $RNA_DATA_TRIM_DIR/$S3.read1.fastq.gz -O $RNA_DATA_TRIM_DIR/$S3.read2.fastq.gz -l 25 --adapter_fasta $RNA_REFS_DIR/illumina_multiplex.fa --trim_front1 13 --trim_front2 13 --json $RNA_DATA_TRIM_DIR/$S3.fastp.json --html $RNA_DATA_TRIM_DIR/$S3.fastp.html 2&gt;$RNA_DATA_TRIM_DIR/$S3.fastp.log export S4=HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22 fastp -i $RNA_DATA_DIR/$S4.read1.fastq.gz -I $RNA_DATA_DIR/$S4.read2.fastq.gz -o $RNA_DATA_TRIM_DIR/$S4.read1.fastq.gz -O $RNA_DATA_TRIM_DIR/$S4.read2.fastq.gz -l 25 --adapter_fasta $RNA_REFS_DIR/illumina_multiplex.fa --trim_front1 13 --trim_front2 13 --json $RNA_DATA_TRIM_DIR/$S4.fastp.json --html $RNA_DATA_TRIM_DIR/$S4.fastp.html 2&gt;$RNA_DATA_TRIM_DIR/$S4.fastp.log export S5=HBR_Rep2_ERCC-Mix2_Build37-ErccTranscripts-chr22 fastp -i $RNA_DATA_DIR/$S5.read1.fastq.gz -I $RNA_DATA_DIR/$S5.read2.fastq.gz -o $RNA_DATA_TRIM_DIR/$S5.read1.fastq.gz -O $RNA_DATA_TRIM_DIR/$S5.read2.fastq.gz -l 25 --adapter_fasta $RNA_REFS_DIR/illumina_multiplex.fa --trim_front1 13 --trim_front2 13 --json $RNA_DATA_TRIM_DIR/$S5.fastp.json --html $RNA_DATA_TRIM_DIR/$S5.fastp.html 2&gt;$RNA_DATA_TRIM_DIR/$S5.fastp.log export S6=HBR_Rep3_ERCC-Mix2_Build37-ErccTranscripts-chr22 fastp -i $RNA_DATA_DIR/$S6.read1.fastq.gz -I $RNA_DATA_DIR/$S6.read2.fastq.gz -o $RNA_DATA_TRIM_DIR/$S6.read1.fastq.gz -O $RNA_DATA_TRIM_DIR/$S6.read2.fastq.gz -l 25 --adapter_fasta $RNA_REFS_DIR/illumina_multiplex.fa --trim_front1 13 --trim_front2 13 --json $RNA_DATA_TRIM_DIR/$S6.fastp.json --html $RNA_DATA_TRIM_DIR/$S6.fastp.html 2&gt;$RNA_DATA_TRIM_DIR/$S6.fastp.log Use FastQC and multiqc to compare the impact of trimming Optional exercise: Compare the FastQC reports for fastq files before and after trimming. All fastqc reports can be generated on the commandline. cd $RNA_DATA_TRIM_DIR fastqc *.fastq.gz multiqc ./ The resulting html reports can be viewed by navigating to: http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/data/ http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/data/trimmed/ Clean up Move the fastqc and fastp results into sub-directories to keep things tidy cd $RNA_DATA_TRIM_DIR mkdir fastqc mv *_fastqc* fastqc mkdir fastp mv *fastp.* fastp PRACTICAL EXERCISE 5 Assignment: Using the approach above, trim the reads for both normal and tumor samples that you downloaded for the previous practical exercise. NOTE: try dropping the hard left trim option used above (‘–trim_front1 13’ and ‘–trim_front2 13’). Once you have trimmed the reads, compare a pre- and post- trimming FastQ file using the FastQC and multiqc tools. Hint: These files should have been downloaded to $RNA_HOME/practice/data/. Questions Answer these questions by examining the FastQC reports: After trimming, what is the range of read lengths observed for hcc1395 normal replicate 1, read 1? Which sections of the FastQC report are most informative for observing the effect of trimming? In the ‘Per base sequence content section’, what pattern do you see? What could explain this pattern? Solution: When you are ready you can check your approach against the Solutions. Alignment mini lecture If you would like a refresher on alignment, we have created an alignment mini lecture. We have also provided a mini lectures describing the differences between alignment, assembly, and pseudoalignment and describing sam, bam, and bed file formats. HISAT2 alignment Perform alignments with HISAT2 to the genome and transcriptome. First, begin by making the appropriate output directory for our alignment results. echo $RNA_ALIGN_DIR mkdir -p $RNA_ALIGN_DIR cd $RNA_ALIGN_DIR HISAT2 uses a graph-based alignment and has succeeded HISAT and TOPHAT2. The output of this step will be a SAM/BAM file for each data set. Refer to HISAT2 manual for a more detailed explanation: http://daehwankimlab.github.io/hisat2/manual/ HISAT2 basic usage: #hisat2 [options]* -x &lt;ht2-idx&gt; {-1 &lt;m1&gt; -2 &lt;m2&gt; | -U &lt;r&gt; | --sra-acc &lt;SRA accession number&gt;} [-S &lt;sam&gt;] Extra options specified below: ‘-p 4’ tells HISAT2 to use 4 CPUs for bowtie alignments. ‘–rna-strandness RF’ specifies strandness of RNAseq library. We will specify RF since the TruSeq strand-specific library was used to make these libraries. See here for options. ‘–rg-id $ID’ specifies a read group ID that is a unique identifier. ‘–rg SM:$SAMPLE_NAME’ specifies a read group sample name. This together with rg-id will allow you to determine which reads came from which sample in the merged bam later on. ‘–rg LB:$LIBRARY_NAME’ specifies a read group library name. This together with rg-id will allow you to determine which reads came from which library in the merged bam later on. ‘–rg PL:ILLUMINA’ specifies a read group sequencing platform. ‘–rg PU:$PLATFORM_UNIT’ specifies a read group sequencing platform unit. Typically this consists of FLOWCELL-BARCODE.LANE ‘–dta’ Reports alignments tailored for transcript assemblers. ‘-x /path/to/hisat2/index’ The HISAT2 index filename prefix (minus the trailing .X.ht2) built earlier including splice sites and exons. ‘-1 /path/to/read1.fastq.gz’ The read 1 FASTQ file, optionally gzip(.gz) or bzip2(.bz2) compressed. ‘-2 /path/to/read2.fastq.gz’ The read 2 FASTQ file, optionally gzip(.gz) or bzip2(.bz2) compressed. ‘-S /path/to/output.sam’ The output SAM format text file of alignments. hisat2 -p 4 --rg-id=UHR_Rep1 --rg SM:UHR --rg LB:UHR_Rep1_ERCC-Mix1 --rg PL:ILLUMINA --rg PU:CXX1234-ACTGAC.1 -x $RNA_REF_INDEX --dta --rna-strandness RF -1 $RNA_DATA_DIR/UHR_Rep1_ERCC-Mix1_Build37-ErccTranscripts-chr22.read1.fastq.gz -2 $RNA_DATA_DIR/UHR_Rep1_ERCC-Mix1_Build37-ErccTranscripts-chr22.read2.fastq.gz -S ./UHR_Rep1.sam hisat2 -p 4 --rg-id=UHR_Rep2 --rg SM:UHR --rg LB:UHR_Rep2_ERCC-Mix1 --rg PL:ILLUMINA --rg PU:CXX1234-TGACAC.1 -x $RNA_REF_INDEX --dta --rna-strandness RF -1 $RNA_DATA_DIR/UHR_Rep2_ERCC-Mix1_Build37-ErccTranscripts-chr22.read1.fastq.gz -2 $RNA_DATA_DIR/UHR_Rep2_ERCC-Mix1_Build37-ErccTranscripts-chr22.read2.fastq.gz -S ./UHR_Rep2.sam hisat2 -p 4 --rg-id=UHR_Rep3 --rg SM:UHR --rg LB:UHR_Rep3_ERCC-Mix1 --rg PL:ILLUMINA --rg PU:CXX1234-CTGACA.1 -x $RNA_REF_INDEX --dta --rna-strandness RF -1 $RNA_DATA_DIR/UHR_Rep3_ERCC-Mix1_Build37-ErccTranscripts-chr22.read1.fastq.gz -2 $RNA_DATA_DIR/UHR_Rep3_ERCC-Mix1_Build37-ErccTranscripts-chr22.read2.fastq.gz -S ./UHR_Rep3.sam hisat2 -p 4 --rg-id=HBR_Rep1 --rg SM:HBR --rg LB:HBR_Rep1_ERCC-Mix2 --rg PL:ILLUMINA --rg PU:CXX1234-TGACAC.1 -x $RNA_REF_INDEX --dta --rna-strandness RF -1 $RNA_DATA_DIR/HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read1.fastq.gz -2 $RNA_DATA_DIR/HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read2.fastq.gz -S ./HBR_Rep1.sam hisat2 -p 4 --rg-id=HBR_Rep2 --rg SM:HBR --rg LB:HBR_Rep2_ERCC-Mix2 --rg PL:ILLUMINA --rg PU:CXX1234-GACACT.1 -x $RNA_REF_INDEX --dta --rna-strandness RF -1 $RNA_DATA_DIR/HBR_Rep2_ERCC-Mix2_Build37-ErccTranscripts-chr22.read1.fastq.gz -2 $RNA_DATA_DIR/HBR_Rep2_ERCC-Mix2_Build37-ErccTranscripts-chr22.read2.fastq.gz -S ./HBR_Rep2.sam hisat2 -p 4 --rg-id=HBR_Rep3 --rg SM:HBR --rg LB:HBR_Rep3_ERCC-Mix2 --rg PL:ILLUMINA --rg PU:CXX1234-ACACTG.1 -x $RNA_REF_INDEX --dta --rna-strandness RF -1 $RNA_DATA_DIR/HBR_Rep3_ERCC-Mix2_Build37-ErccTranscripts-chr22.read1.fastq.gz -2 $RNA_DATA_DIR/HBR_Rep3_ERCC-Mix2_Build37-ErccTranscripts-chr22.read2.fastq.gz -S ./HBR_Rep3.sam Note: in the above alignments, we are treating each library as an independent data set. If you had multiple lanes of data for a single library, you could align them all together in one HISAT2 command. Similarly you might combine technical replicates into a single alignment run (perhaps after examining them and removing outliers…). To combine multiple lanes, you would provide all the read1 files as a comma separated list for the ‘-1’ input argument, and then all read2 files as a comma separated list for the ‘-2’ input argument, (where both lists have the same order) : You can also use samtools merge to combine bam files after alignment. This is the approach we will take. HISAT2 Alignment Summary HISAT2 generates a summary of the alignments printed to the terminal. Notice the number of total reads, reads aligned and various metrics regarding how the reads aligned to the reference. SAM to BAM Conversion Convert HISAT2 sam files to bam files and sort by aligned position samtools sort -@ 4 -o UHR_Rep1.bam UHR_Rep1.sam samtools sort -@ 4 -o UHR_Rep2.bam UHR_Rep2.sam samtools sort -@ 4 -o UHR_Rep3.bam UHR_Rep3.sam samtools sort -@ 4 -o HBR_Rep1.bam HBR_Rep1.sam samtools sort -@ 4 -o HBR_Rep2.bam HBR_Rep2.sam samtools sort -@ 4 -o HBR_Rep3.bam HBR_Rep3.sam Merge HISAT2 BAM files Make a single BAM file combining all UHR data and another for all HBR data. Note: This could be done in several ways such as ‘samtools merge’, ‘bamtools merge’, or using picard-tools (see below). We chose the third method because it did the best job at merging the bam header information. NOTE: sambamba also retains header info. cd $RNA_HOME/alignments/hisat2 java -Xmx2g -jar $PICARD MergeSamFiles -OUTPUT UHR.bam -INPUT UHR_Rep1.bam -INPUT UHR_Rep2.bam -INPUT UHR_Rep3.bam java -Xmx2g -jar $PICARD MergeSamFiles -OUTPUT HBR.bam -INPUT HBR_Rep1.bam -INPUT HBR_Rep2.bam -INPUT HBR_Rep3.bam Count the alignment (BAM) files to make sure all were created successfully (you should have 8 total) ls -l *.bam | wc -l ls -l *.bam PRACTICAL EXERCISE 6 Assignment: Perform some alignments on additional read data sets. Align the reads using the skills you learned above. Try using the HISAT2 aligner. Also practice converting SAM to BAM files, and merging BAM files. Hint: Do this analysis on the additional data and in the separate working directory called ‘practice’ that you created in Practical Exercise 3. Questions What is the difference between a .sam and .bam file? If you sorted the resulting BAM file as we did above, is the result sorted by read name? Or position? Which columns of the BAM file can be viewed to determine the style of sorting? What command can you use to view only the BAM header? Solution: When you are ready you can check your approach against the Solutions. Introduction Description of the lab Welcome to the lab for Genome Visualization! This lab will introduce you to the Integrative Genomics Viewer, one of the most popular visualization tools for High Throughput Sequencing (HTS) data. Lecture files that accompany this tutorial: IGV Lecture - Brief IGV Lecture - Long, from Broad Institute After this lab, you will be able to: Visualize a variety of genomic data Quickly navigate around the genome Visualize read alignments Validate SNP/SNV calls and structural re-arrangements by eye Things to know before you start: The lab may take between 1-2 hours, depending on your familiarity with genome browsing. Do not worry if you do not complete the lab. It will remain available to review later. There are a few thought-provoking Questions or Notes pertaining to sections of the lab. These are optional, and may take more time, but are meant to help you better understand the visualizations you are seeing. These questions will be denoted by boxes, as follows: Question(s): `Thought-provoking question goes here.`` Requirements Integrative Genomics Viewer Ability to run Java Note that while most tutorials in this course are performed on the cloud, IGV will always be run on your local machine Note a version of this tutorial can also be performed directly in your web browser at sandbox.bio IGV Intro. Compatibility This tutorial was most recently updated for IGV v2.16.2, which is available on the IGV Download page. It is recommended that you use this version. Most other recent versions will work but their may be slight differences. Data Set for IGV We will be using publicly available Illumina sequence data from the HCC1143 cell line. The HCC1143 cell line was generated from a 52 year old caucasian woman with breast cancer. Additional information on this cell line can be found here: HCC1143 (tumor, TNM stage IIA, grade 3, primary ductal carcinoma) and HCC1143/BL (matched normal EBV transformed lymphoblast cell line). Sequence read alignments generated from a cell line HCC1143 that have been filtered to this region: Chromosome 21: 19,000,000-20,000,000 HCC1143.normal.21.19M-20M.bam HCC1143.normal.21.19M-20M.bam.bai Visualization Part 1: Getting familiar with IGV We will be visualizing read alignments using IGV, a popular visualization tool for HTS data. First, lets familiarize ourselves with it. Get familiar with the interface Load a Genome and some Data Tracks By default, IGV loads the Human GRCh38/hg38 reference genome. If you work with another version of the human genome, or another organism altogether, you can change the genome by clicking the drop down menu in the upper-left. For this lab, we will be using Human GRCh37/hg19. We will also load additional tracks from Server using (File -&gt; Load from Server...): Ensembl Genes (or your favourite source of gene annotations) GC Percentage dbSNP 1.4.7 Load hg19 genome and additional data tracks Load hg19 genome and additional data tracks Navigation You should see listing of chromosomes in this reference genome. Choose 1, for chromosome 1. Chromosome chooser Chromosome chooser Navigate to chr1:10,000-11,000 by entering this into the location field (in the top-left corner of the interface) and clicking Go. This shows a window of chromosome 1 that is 1,000 base pairs wide and beginning at position 10,000. Navigition using Location text field. Sequence displayed as thin coloured rectangles. Navigition using Location text field. Sequence displayed as thin coloured rectangles. IGV displays the sequence of letters in a genome as a sequence of colours (e.g. A = green, C = blue, etc.). This makes repetitive sequences, like the ones found at the start of this region, easy to identify. Zoom in a bit more using the + button to see the individual bases of the reference genome sequence. You can navigate to a gene of interest by typing it in the same box the genomic coordinates are in and pressing Enter/Return. Try it for your favourite gene, or BRCA1 if you can not decide. Gene model Gene model Genes are represented as lines and boxes. Lines represent intronic regions, and boxes represent exonic regions. The arrows indicate the direction/strand of transcription for the gene. When an exon box become narrower in height, this indicates a UTR. When loaded, tracks are stacked on top of each other. You can identify which track is which by consulting the label to the left of each track. Region Lists Sometimes, it is really useful to save where you are, or to load regions of interest. For this purpose, there is a Region Navigator in IGV. To access it, click Regions &gt; Region Navigator. While you browse around the genome, you can save some bookmarks by pressing the Add button at any time. Bookmarks in IGV Bookmarks in IGV Loading Read Alignments We will be using the breast cancer cell line HCC1143 to visualize alignments. For speed, only a small portion of chr21 will be loaded (19M:20M). HCC1143 Alignments to hg19: HCC1143.normal.21.19M-20M.bam HCC1143.normal.21.19M-20M.bam.bai Copy the files to your local drive, and in IGV choose File &gt; Load from File..., select the bam file, and click OK. Note that the bam and index files must be in the same directory for IGV to load these properly. Load BAM track from File Load BAM track from File Visualizing read alignments Navigate to a narrow window on chromosome 21: chr21:19,480,041-19,480,386. To start our exploration, right click on the read alignment track, and select the following options: Sort alignments by -&gt; start location Group alignments by -&gt; pair orientation Experiment with the various settings by right clicking the read alignment track and toggling the options. Think about which would be best for specific tasks (e.g. quality control, SNP calling, CNV finding). Changing how read alignments are sorted, grouped, and colored Changing how read alignments are sorted, grouped, and colored You will see reads represented by grey or white bars stacked on top of each other, where they were aligned to the reference genome. The reads are pointed to indicate their orientation (i.e. the strand on which they are mapped). Mouse over any read and notice that a lot of information is available. To toggle read display from hover to click, select the yellow box and change the setting. Changing how read information is shown (i.e. on hover, click, never) Changing how read information is shown (i.e. on hover, click, never) Once you select a read, you will learn what many of these metrics mean, and how to use them to assess the quality of your datasets. At each base that the read sequence mismatches the reference, the colour of the base represents the letter that exists in the read (using the same colour legend used for displaying the reference). Viewing read information for a single aligned read Viewing read information for a single aligned read Visualization Part 2: Inspecting SNPs, SNVs, and SVs In this section we will be looking in detail at 8 positions in the genome, and determining whether they represent real events or artifacts. Two neighbouring SNPs Navigate to region chr21:19,479,237-19,479,814 Note two heterozygous variants, one corresponds to a known dbSNP (G/T on the right) the other does not (C/T on the left) Zoom in and center on the C/T SNV on the left, sort by base (window chr21:19,479,321 is the SNV position) Sort alignments by base Color alignments by read strand Example1. Good quality SNVs/SNPs Example1. Good quality SNVs/SNPs Notes: High base qualities in all reads except one (where the alt allele is the last base of the read) Good mapping quality of reads, no strand bias, allele frequency consistent with heterozygous mutation Question(s): * What does *Shade base by quality* do? How might this be helpful? * How does Color by *read strand* help? Homopolymer region with indel Navigate to position chr21:19,518,412-19,518,497 Example 2a Group alignments by read strand Center on the A within the homopolymer run (chr21:19,518,470), and Sort alignments by -&gt; base Example 2a Example 2b Center on the one base deletion (chr21:19,518,452), and Sort alignments by -&gt; base Example 2b Notes: The alt allele is either a deletion or insertion of one or two Ts The remaining bases are mismatched, because the alignment is now out of sync Coverage by GC Navigate to position chr21:19,611,925-19,631,555. Note that the range contains areas where coverage drops to zero in a few places. Example 3 Use Collapsed view Color alignments by -&gt; insert size and pair orientation Group alignments by -&gt; none Load GC track (if not already loaded above) See concordance of coverage with GC content Example 3 Question: * Why are there blue and red reads throughout the alignments? Heterozygous SNPs on different alleles Navigate to region chr21:19,666,833-19,667,007 Example 4 Sort by base (at position chr21:19,666,901) Example 4 Note: There is no linkage between alleles for these two SNPs because reads covering both only contain one or the other Low mapping quality Navigate to region chr21:19,800,320-19,818,162 Load repeat track (File -&gt; Load from server...) Load repeats Load repeats Example 5 Example 5 Notes: Mapping quality plunges in all reads (white instead of grey). Once we load repeat elements, we see that there are two LINE elements that cause this. Homozygous deletion Navigate to region chr21:19,324,469-19,331,468 Example 6 Turn on View as Pairs and Expanded view Use Color alignments by -&gt; insert size and pair orientation Sort reads by insert size Click on a red read pair to pull up information on alignments Example 6 Notes: Typical insert size of read pair in the vicinity: 350bp Insert size of red read pairs: 2,875bp This corresponds to a homozygous deletion of 2.5kb Mis-alignment Navigate to region chr21:19,102,154-19,103,108 Example 7 Example 7 Notes: This is a position where AluY element causes mis-alignment. Misaligned reads have mismatches to the reference and well-aligned reads have partners on other chromosomes where additional ALuY elements are encoded. Zoom out until you can clearly see the contrast between the difficult alignment region (corresponding to an AluY) and regions with clean alignments on either side Translocation Navigate to region chr21:19,089,694-19,095,362 Example 8 Expanded view Group alignments by -&gt; pair orientation Color alignments by -&gt; insert size and pair orientation Example 8 Notes: Many reads with mismatches to reference Read pairs in RL pattern (instead of LR pattern) Region is flanked by reads with poor mapping quality (white instead of grey) Presence of reads with pairs on other chromosomes (coloured reads at the bottom when scrolling down) Visualization Part 3: Automating Tasks in IGV We can use the Tools menu to invoke running a batch script. Batch scripts are described on the IGV website: Batch file requirements: https://www.broadinstitute.org/igv/batch Commands recognized in a batch script: https://software.broadinstitute.org/software/igv/PortCommands We also need to provide sample attribute file as described here: https://software.broadinstitute.org/software/igv/SampleInformation Download the batch script and the attribute file for our dataset: Batch script: Run_batch_IGV_snapshots.txt Attribute file: Igv_HCC1143_attributes.txt Hint: You can use the curl -L -O with the above URLs to download the files using the terminal! Now run the file from the Tools menu: Automation Automation Notes: This script will navigate automatically to each location in the lab A screenshot will be taken and saved to the screenshots directory specified Contributors/acknowledgements Malachi Griffith, Sorana Morrissy, Jim Robinson, Ben Ainscough, Jason Walker, Obi Griffith, Kartik Singhal RNA-seq_Flowchart3 Before we can view our alignments in the IGV browser we need to index our BAM files. We will use samtools index for this purpose. For convenience later, index all bam files. Indexing BAM files with samtools echo $RNA_ALIGN_DIR cd $RNA_ALIGN_DIR samtools index -M *.bam # flag -M interprets all filename arguments as files to be indexed, allowing multiple files to be indexed at the same time. To index individual file, use &#39;samtools index input.bam&#39; # Note that we could have created and run a samtools index command for all files ending in .bam using the following construct: # find *.bam -exec echo samtools index {} \\; | sh Optional: Try to create an index file for one of your bam files using a samtools docker image rather than the locally installed version of samtools. Below is an example docker run command. cp HBR.bam /tmp/ docker run -v /tmp:/docker_workspace biocontainers/samtools:v1.9-4-deb_cv1 samtools index /docker_workspace/HBR.bam ls /tmp/HBR.bam* docker run is how you initialize a docker container to run a command -v is the parameter used to mount your workspace so that the docker container can see the files that you’re working with. In the example above, /tmp from the EC2 instance has been mounted as /docker_workspace within the docker container. biocontainers/samtools is the docker container name. The :v1.9-4-deb_cv1 refers to the specific tag and release of the docker container. In the next step we will visualize these alignment BAM files using IGV. Now that our BAM files have been indexed with samtools we can load them and explore the RNA-seq alignments using the Integrative Genomics Viewer (IGV). The exercise below assumes that you have IGV installed on your local computer. If you are unable to get IGV to run locally you may also consider a web based version of IGV that runs in your browser. The interface of the IGV Web App is different from the local install, and is missing a few features, but is conceptually very similar. To access it simply visit: IGV Web App. Visualize alignments with IGV Start IGV on your computer/laptop. Load the UHR.bam &amp; HBR.bam files in IGV. If you’re using AWS, you can load the necessary files in IGV directly from your web accessible amazon workspace (see below) using ‘File’ -&gt; ‘Load from URL’. Make sure you select the appropriate reference genome build in IGV (top left corner of IGV): in this case hg38. AWS links to bam files UHR hisat2 alignment: http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/alignments/hisat2/UHR.bam HBR hisat2 alignment: http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/alignments/hisat2/HBR.bam Links to cached version of these bam files If for some reason you do not have access to the BAM files from running through this course you can download and use these cached versions instead: UHR hisat2 alignment: UHR.bam (UHR.bam.bai) HBR hisat2 alignment: HBR.bam (HBR.bam.bai) You may wish to customize the track names as you load them in to keep them straight. Do this by right-clicking on the alignment track and choosing ‘Rename Track’. Go to an example gene locus on chr22: e.g. EIF3L, NDUFA6, and RBX1 have nice coverage e.g. SULT4A1 and GTSE1 are differentially expressed. Are they up-regulated or down-regulated in the brain (HBR) compared to cancer cell lines (UHR)? Mouse over some reads and use the read group (RG) flag to determine which replicate the reads come from. What other details can you learn about each read and its alignment to the reference genome. Exercise Try to find a variant position in the RNAseq data: HINT: DDX17 is a highly expressed gene with several variants in its 3 prime UTR. Other highly expressed genes you might explore are: NUP50, CYB5R3, and EIF3L (all have at least one transcribed variant). Are these variants previously known (e.g., present in dbSNP)? How should we interpret the allele frequency of each variant? Remember that we have rather unusual samples here in that they are actually pooled RNAs corresponding to multiple individuals (genotypes). Take note of the genomic position of your variant. We will need this later. IGV visualization example (DDX17 3 prime region) IGV-DDX17 PRACTICAL EXERCISE 7 Assignment: Index your bam files from Practical Exercise 6 and visualize in IGV. Hint: As before, it may be simplest to just index and visualize the combined/merged bam files HCC1395_normal.bam and HCC1395_tumor.bam. If this works, you should have two BAM files that can be loaded into IGV from the following location on your cloud instance: http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/practice/alignments/hisat2/ Links to cached version of the practical exercise bam files If for some reason you do not have access to the BAM files from running through this course you can download and use these cached versions instead: HCC1395-normal hisat2 alignment: HCC1395-normal.bam (HCC1395-normal.bam.bai) HCC1395-tumor hisat2 alignment: HCC1395-tumor.bam (HCC1395-tumor.bam.bai) Questions Load your merged normal and tumor BAM files into IGV. Navigate to this location on chromosome 22: ‘chr22:38,466,394-38,508,115’. What do you see here? How would you describe the direction of transcription for the two genes? Does the reported strand for the reads aligned to each of these genes appear to make sense? How do you modify IGV settings to see the strand clearly? How can we modify IGV to color reads by Read Group? How many read groups are there for each sample (tumor &amp; normal)? What are your read group names for the tumor sample? What are the options for visualizing splicing or alternative splicing patterns in IGV? Navigate to this location on chromosome 22: ‘chr22:40,363,200-40,367,500’. What splicing event do you see? Solution: When you are ready you can check your approach against the Solutions. In this section we will demonstrate how to assess expression of specific variant alleles in the RNA-seq BAM using tools designed to interrogate read alignments and sequence base identities at particular positions. BAM Read Counting Using one of the variant positions identified above, count the number of supporting reference and variant reads. First, use samtools mpileup to visualize a region of alignment with a variant. cd $RNA_HOME mkdir bam_readcount cd bam_readcount Create faidx indexed reference sequence file for use with mpileup echo $RNA_REF_FASTA samtools faidx $RNA_REF_FASTA Run samtools mpileup on a region of interest samtools mpileup -f $RNA_REF_FASTA -r 22:18918457-18918467 $RNA_ALIGN_DIR/UHR.bam $RNA_ALIGN_DIR/HBR.bam Each line consists of chromosome, 1-based coordinate, reference base, the number of reads covering the site, read bases and base qualities. At the read base column, a dot stands for a match to the reference base on the forward strand, a comma for a match on the reverse strand, ACGTN for a mismatch on the forward strand and acgtn for a mismatch on the reverse strand. A pattern \\+[0-9]+[ACGTNacgtn]+ indicates there is an insertion between this reference position and the next reference position. The length of the insertion is given by the integer in the pattern, followed by the inserted sequence. See samtools pileup/mpileup documentation for more explanation of the output: http://samtools.sourceforge.net/pileup.shtml http://samtools.sourceforge.net/mpileup.shtml Now, use bam-readcount to count reference and variant bases at a specific position. First, create a bed file with some positions of interest (we will create a file called snvs.bed using the echo command). It will contain a single line specifying a variant position on chr22 e.g.: 22:38483683-38483683 Create the bed file echo &quot;22 38483683 38483683&quot; echo &quot;22 38483683 38483683&quot; &gt; snvs.bed Run bam-readcount on this list for the tumor and normal merged bam files bam-readcount -l snvs.bed -f $RNA_REF_FASTA $RNA_ALIGN_DIR/UHR.bam 2&gt;/dev/null bam-readcount -l snvs.bed -f $RNA_REF_FASTA $RNA_ALIGN_DIR/HBR.bam 2&gt;/dev/null Now, run it again, but ignore stderr and redirect stdout to a file: bam-readcount -l snvs.bed -f $RNA_REF_FASTA $RNA_ALIGN_DIR/UHR.bam 2&gt;/dev/null 1&gt;UHR_bam-readcounts.txt bam-readcount -l snvs.bed -f $RNA_REF_FASTA $RNA_ALIGN_DIR/HBR.bam 2&gt;/dev/null 1&gt;HBR_bam-readcounts.txt From this output you could parse the read counts for each base cat UHR_bam-readcounts.txt | perl -ne &#39;@data=split(&quot;\\t&quot;, $_); @Adata=split(&quot;:&quot;, $data[5]); @Cdata=split(&quot;:&quot;, $data[6]); @Gdata=split(&quot;:&quot;, $data[7]); @Tdata=split(&quot;:&quot;, $data[8]); print &quot;UHR Counts\\t$data[0]\\t$data[1]\\tA: $Adata[1]\\tC: $Cdata[1]\\tT: $Tdata[1]\\tG: $Gdata[1]\\n&quot;;&#39; cat HBR_bam-readcounts.txt | perl -ne &#39;@data=split(&quot;\\t&quot;, $_); @Adata=split(&quot;:&quot;, $data[5]); @Cdata=split(&quot;:&quot;, $data[6]); @Gdata=split(&quot;:&quot;, $data[7]); @Tdata=split(&quot;:&quot;, $data[8]); print &quot;HBR Counts\\t$data[0]\\t$data[1]\\tA: $Adata[1]\\tC: $Cdata[1]\\tT: $Tdata[1]\\tG: $Gdata[1]\\n&quot;;&#39; If reading perl code isn’t your favorite thing to do, here’s a bam-readcount tutorial that uses python to parse output from bam-readcount to identify a Omicron SARS-CoV-2 variant of concern from raw sequence data. PRACTICAL EXERCISE 7 Assignment: Index your bam files from Practical Exercise 6 and visualize in IGV. Hint: As before, it may be simplest to just index and visualize the combined/merged bam files HCC1395_normal.bam and HCC1395_tumor.bam. If this works, you should have two BAM files that can be loaded into IGV from the following location on your cloud instance: http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/practice/alignments/hisat2/ Questions Load your merged normal and tumor BAM files into IGV. Navigate to this location on chromosome 22: ‘chr22:38,466,394-38,508,115’. What do you see here? How would you describe the direction of transcription for the two genes? Does the reported strand for the reads aligned to each of these genes appear to make sense? How do you modify IGV settings to see the strand clearly? How can we modify IGV to color reads by Read Group? How many read groups are there for each sample (tumor &amp; normal)? What are your read group names for the tumor sample? What are the options for visualizing splicing or alternative splicing patterns in IGV? Navigate to this location on chromosome 22: ‘chr22:40,363,200-40,367,500’. What splicing event do you see? Solution: When you are ready you can check your approach against the Solutions. Alignment QC mini lecture If you would like a refresher on alignment QC, we have made a mini lecture briefly covering the topic. Use samtools and FastQC to evaluate the alignments Use samtools view to see the format of a SAM/BAM alignment file cd $RNA_ALIGN_DIR samtools view -H UHR.bam samtools view UHR.bam | head samtools view UHR.bam | head | column -t | less -S Try filtering the BAM file to require or exclude certain flags. This can be done with samtools view -f -F options -f INT required flag -F INT filtering flag “Samtools flags explained” http://broadinstitute.github.io/picard/explain-flags.html Try requiring that alignments are ‘paired’ and ‘mapped in a proper pair’ (=3). Also filter out alignments that are ‘unmapped’, the ‘mate is unmapped’, and ‘not primary alignment’ (=268) samtools view -f 3 -F 268 UHR.bam | head | column -t | less -S Now require that the alignments be only for ‘PCR or optical duplicate’. How many reads meet this criteria? Why? samtools view -f 1024 UHR.bam | head Use samtools flagstat to get a basic summary of an alignment. What percent of reads are mapped? Is this realistic? Why? cd $RNA_ALIGN_DIR mkdir flagstat samtools flagstat HBR_Rep1.bam &gt; flagstat/HBR_Rep1.bam.flagstat samtools flagstat HBR_Rep2.bam &gt; flagstat/HBR_Rep2.bam.flagstat samtools flagstat HBR_Rep3.bam &gt; flagstat/HBR_Rep3.bam.flagstat samtools flagstat UHR_Rep1.bam &gt; flagstat/UHR_Rep1.bam.flagstat samtools flagstat UHR_Rep2.bam &gt; flagstat/UHR_Rep2.bam.flagstat samtools flagstat UHR_Rep3.bam &gt; flagstat/UHR_Rep3.bam.flagstat # Note that we could have created and run a samtools flagstat command for all files ending in *Rep*.bam using the following construct: # find *Rep*.bam -exec echo samtools flagstat {} \\&gt; flagstat/{}.flagstat \\; | sh # View an example cat flagstat/UHR_Rep1.bam.flagstat Details of the SAM/BAM format can be found here: http://samtools.sourceforge.net/SAM1.pdf Create versions of our BAM files with only the chromosome 22 alignments Note that our alignments contain those for the spiked in ERCC control sequences. For some QC analyses, these sequences complicate interpretation because they are not like human genes (e.g. no introns or UTRs). To allow us flexibility for the QC analysis we will create a version of each BAM file that only has the chromosome 22 alignments. cd $RNA_ALIGN_DIR mkdir chr22_only_bams find *Rep*.bam -exec echo samtools view -b {} 22 -o chr22_only_bams/{} \\; | sh samtools index -M chr22_only_bams/*.bam Using FastQC You can use FastQC to perform basic QC of your BAM file (See Pre-alignment QC). This will give you output very similar to when you ran FastQC on your fastq files. cd $RNA_ALIGN_DIR fastqc UHR_Rep1.bam UHR_Rep2.bam UHR_Rep3.bam HBR_Rep1.bam HBR_Rep2.bam HBR_Rep3.bam mkdir fastqc mv *fastqc.html fastqc/ mv *fastqc.zip fastqc/ Using Picard You can use Picard to generate RNA-seq specific quality metrics and figures In this section we need to create some additional formats of our reference transcriptome files. Picard uses a “sequence dictionary” file for many commands (simply a list of reference sequences and their sizes) We will also filter our transcriptome GTF to one with only ribosomal features, convert it to BED format and then to IntervalList format. This is all done to get the IntervalList format needed for Picard CollectRnaSeqMetrics We will also create a version of our whole transcriptome GTF in the RefFlat format needed for Picard CollectRnaSeqMetrics. To get to the RefFlat format we will convert GTF to GenePredExt format and then simplify this to RefFlat. # Generating the necessary input files for picard CollectRnaSeqMetrics cd $RNA_HOME/refs # Create a .dict file for our reference java -jar $PICARD CreateSequenceDictionary -R chr22_with_ERCC92.fa -O chr22_with_ERCC92.dict # Create a bed file of the location of ribosomal sequences in our reference (first extract them from the GTF then convert to BED format) # Note that here we pull all the &quot;rrna&quot; transcripts from the GTF. This is a good strategy for the whole transcriptome ... # ... but on chr22 there is very little &quot;rrna&quot; content, leading to 0 coverage for all samples, so we are also adding a single protein coding ribosomal gene &quot;RRP7A&quot; (normally we would not do this) # Note the convert2bed command will convert our GTF to BED format # &quot;&lt;&quot; is used to feed the GTF file into the tool. &quot;&gt;2/dev/null&quot; is used to throw away a harmless warning. &quot;1&gt;&quot; is use to save our result to a file grep --color=none -i -P &quot;rrna|rrp7a&quot; chr22_with_ERCC92.gtf &gt; ref_ribosome.gtf convert2bed --input=gtf --output=bed &lt; ref_ribosome.gtf 2&gt;/dev/null 1&gt;ref_ribosome.bed # Create interval list file for the location of just the ribosomal sequences in our reference java -jar $PICARD BedToIntervalList -I ref_ribosome.bed -O ref_ribosome.interval_list -SD chr22_with_ERCC92.dict # Create a genePred file for our whole reference transcriptome gtfToGenePred -genePredExt chr22_with_ERCC92.gtf chr22_with_ERCC92.genePredExt # Reformat this genePred file to first add the Ensembl gene ID column to the beginning of the dataframe using &quot;awk&quot;, and then subset it down to the first 11 columns using &quot;cut&quot;. cat chr22_with_ERCC92.genePredExt | awk &#39;{print $12&quot;\\t&quot;$0}&#39; | cut -d$&#39;\\t&#39; -f1-11 &gt; chr22_with_ERCC92.refFlat.txt # Use the &quot;find&quot; command to run &quot;picard CollectRnaSeqMetrics&quot; on all 6 BAM files. # The basic structure of this kind of automation is: find &lt;search pattern&gt; -exec command {} \\; # The &quot;{}&quot; will insert the file found by the &quot;find&quot; command using &lt;search pattern&gt;. &quot;\\;&quot; indicates the end of the command. cd $RNA_HOME/alignments/hisat2/ mkdir picard find *Rep*.bam -exec echo java -jar $PICARD CollectRnaSeqMetrics I={} O=picard/{}.RNA_Metrics REF_FLAT=$RNA_HOME/refs/chr22_with_ERCC92.refFlat.txt STRAND=SECOND_READ_TRANSCRIPTION_STRAND RIBOSOMAL_INTERVALS=$RNA_HOME/refs/ref_ribosome.interval_list \\; | sh RSeQC [optional] Background: RSeQC is a tool that can be used to generate QC reports for RNA-seq. For more information, please check: RSeQC Tool Homepage Files needed: Aligned bam files Index file for each bam file. A transcript bed file (in bed12 format). cd $RNA_HOME/refs/ # Convert GTF to genePred gtfToGenePred chr22_with_ERCC92.gtf chr22_with_ERCC92.genePred # Convert genePred to BED12 genePredToBed chr22_with_ERCC92.genePred chr22_with_ERCC92.bed12 # Create a version of the BED12 with the ERCC92 sequences removed (because they confuse the QC analysis that looks at how many reads are coding, UTR, intronic, etc. grep -v ERCC chr22_with_ERCC92.bed12 &gt; chr22_without_ERCC92.bed12 cd $RNA_ALIGN_DIR mkdir rseqc geneBody_coverage.py -i chr22_only_bams/UHR_Rep1.bam,chr22_only_bams/UHR_Rep2.bam,chr22_only_bams/UHR_Rep3.bam -r $RNA_HOME/refs/chr22_without_ERCC92.bed12 -o rseqc/UHR geneBody_coverage.py -i chr22_only_bams/HBR_Rep1.bam,chr22_only_bams/HBR_Rep2.bam,chr22_only_bams/HBR_Rep3.bam -r $RNA_HOME/refs/chr22_without_ERCC92.bed12 -o rseqc/HBR # Calculate the inner distance of RNA-seq fragments. # RNA fragment # _________________||_________________ # | | # | | # ||||||||||------------------|||||||||| # read_1 inner_distance read_2 # # fragment size = read_1 + inner_distance + read_2 find *Rep*.bam -exec echo inner_distance.py -i {} -r $RNA_HOME/refs/chr22_without_ERCC92.bed12 -o rseqc/{} \\; | sh # Annotate exon-exon junctions observed in RNA-seq alignments compared to know exon-exon junctions cd $RNA_ALIGN_DIR/chr22_only_bams find *Rep*.bam -exec echo junction_annotation.py -i {} -r $RNA_HOME/refs/chr22_without_ERCC92.bed12 -o ../rseqc/{} \\; | sh # Perform a saturation analysis using only exon-exon junction mapping reads find *Rep*.bam -exec echo junction_saturation.py -i {} -r $RNA_HOME/refs/chr22_without_ERCC92.bed12 -o ../rseqc/{} \\; | sh # Determine the distribution of reads with respect to the parts of transcripts they align to (e.g. 5&#39; UTR, CDS, 3&#39;UTR, intron, etc.) find *Rep*.bam -exec echo read_distribution.py -i {} -r $RNA_HOME/refs/chr22_without_ERCC92.bed12 \\&gt; ../rseqc/{}.read_dist.txt \\; | sh # Calculate the RNA fragment sizes and produce statistics for each transcript cd $RNA_ALIGN_DIR find *Rep*.bam -exec echo RNA_fragment_size.py -i {} -r $RNA_HOME/refs/chr22_without_ERCC92.bed12 \\&gt; rseqc/{}.frag_size.txt \\; | sh # Summarizing mapping statistics of each BAM file find *Rep*.bam -exec echo bam_stat.py -i {} \\&gt; rseqc/{}.bam_stat.txt \\; | sh rm -f log.txt MultiQC We will now use multiQC to compile a QC report from all the QC tools above. cd $RNA_ALIGN_DIR multiqc ./ MultiQC screenshot MultiQC View a pre-generated MultiQC report for full bam files View a multiQC on QC reports from non-downsampled bam files: mkdir $RNA_ALIGN_DIR/example_QC cd $RNA_ALIGN_DIR/example_QC wget http://genomedata.org/rnaseq-tutorial/multiqc_report.html Below is a brief description of each of the samples included in the multiQC report. Name Sample type Sample 1 Brain metastasis Sample 2 Melanoma xenograft Sample 3 Melanoma cell line Sample 4 Melanoma Sample 5 Small Cell Lung Cancer FFPE Sample 6 Brain metastasis The goal of the following team assignment is for students to gain hands-on experience by working on recently published RNA-seq data and apply the concepts they have learned up to RNA alignment. To complete this assignment, students will need to review commands we performed in earlier sections. Background on Dataset used In this assignment, we will be using subsets of the GSE136366 dataset (Roczniak-Ferguson A, Ferguson SM. Pleiotropic requirements for human TDP-43 in the regulation of cell and organelle homeostasis. Life Sci Alliance 2019 Oct;2(5). PMID: 31527135). This dataset consists of 6 RNA sequencing files of human cells that either express or lack the TDP-43 protein. Experimental Details - The libraries are prepared as paired end. - The samples are sequenced on an Illumina HiSeq 2500. - Each read is 63 bp long - The data are RF/fr-firststrand stranded (dUTP) - The source dataset is located here: GSE136366 - 3 samples are from TDP-43 Knockout HeLa cells and 3 samples wherein a wildtype TDP-43 transgene was re-expressed. - For this exercise we will be using different subsets of the reads: - Team A: chr11 - Team B: chr12 - Team C: chr17 - Team D: chr19 - Team E: chr6 - The files are named based on their SRR id’s, and obey the following key: - SRR10045016 = KO sample 1 - SRR10045017 = KO sample 2 - SRR10045018 = KO sample 3 - SRR10045019 = Rescue sample 1 - SRR10045020 = Rescue sample 2 - SRR10045021 = Rescue sample 3 Part I - Obtaining the dataset &amp; reference files Goals: Obtain the files necessary for data processing Review reference and annotation file formats Review sequence FASTQ format As mentioned previously, we have subsetted the 6 RNA-seq samples into 5 different chromosome regions. Each team can download their corresponding dataset using the following commands. cd $RNA_HOME/ mkdir -p team_exercise/untrimmed cd team_exercise/untrimmed # Fill in the &quot;XX&quot; below with your team&#39;s letter (A, B, C...) wget -c http://genomedata.org/seq-tec-workshop/read_data/rna_alignment-de_exercise/dataset_XX/dataset.tar.gz tar -xzvf dataset.tar.gz Additionally, teams will need to create a separate directory and download the corresponding reference files needed for RNA alignment &amp; further expression analysis. Don’t forget to modify the below commands to use your team’s chromosome. mkdir -p $RNA_HOME/team_exercise/references cd $RNA_HOME/team_exercise/references ## Adapter trimming wget -c http://genomedata.org/seq-tec-workshop/references/RNA/illumina_multiplex.fa ## Reference fasta corresponding to your team&#39;s assigned chromosome (e.g. chr6) wget -c http://genomedata.org/seq-tec-workshop/references/RNA/chrXX.fa ## Obtain annotated reference gtf file corresponding to your team&#39;s assigned chromosome (e.g. chr6) wget -c http://genomedata.org/seq-tec-workshop/references/RNA/chrXX_Homo_sapiens.GRCh38.95.gtf Part II - Data Preprocessing (QC &amp; Trimming) Goals: Perform adapter trimming on your data and also pre-trim 5 bases from end (right) of reads Perform QC on your data with fastqc and multiqc before and after trimming your data Q1. What is the average percentage of reads that are trimmed? Q2. How do you expect the sequence length distribution to look prior to and after trimming? Is your answer confirmed by the multiqc report results? Q3. Are there any metrics where the sample(s) failed? Part III - Alignment Goals: Create HISAT2 index files for your chromosome Review HISAT2 alignment options Perform alignments Obtain an alignment summary Sort and convert your alignments into compressed BAM format A useful option to add to the end of your commands is 2&gt;, which redirects the stderr from any command into a specific file. This can be used to redirect your stderr into a summary file, and can be used as follows: my_alignment_command 2&gt; alignment_metrics.txt. The advantage of this is being able to view the alignment metrics later on. Q4. What were the percentages of reads that aligned to the reference for each sample? Q5. By compressing your sam format to bam, approximately how much space is saved (fold change in size)? Part IV - Post-alignment QC &amp; IGV Visualization Goals: Perform post-alignment QC analysis using fastqc and multiqc Merge bam files (one for each condition) for easier visualization in IGV Index the bam files Explore the alignments using IGV Q6. How does the information from your post-alignment QC report differ from pre-alignment QC? Q7. IGV: Can you identify certain exons that have significantly more/less coverage in one of your KO/RESCUE samples compared to the other? What is happening here? Q8. IGV: Can you identify regions where the RNAseq reads are mapping to unexpected regions? What do you think is the reason for this phenomenon? Q9. IGV: Can you identify a gene region that has RNA sequencing support for multiple isoforms? Presenting Your Results At the end of this team exercise, groups will present findings from their QC reports and IGV analysis to the class for specific questions listed below. Team A: Present IGV findings regarding question 9. Team B: Present multiqc report on pre- and post-alignment qc files (question 6). Team C: Present IGV findings regarding question 7. Team D: Present IGV findings regarding question 8. Team E: Present multiqc report on pre- and post-trimming qc files (Data Preprocessing section). "],["module-3.html", "Module 3 Lecture Labs", " Module 3 Lecture Labs Module 3 - Key concepts Expression estimation, FPKM, TPM, StringTie overview, BallGown overview, multiple testing correction, etc. Module 3 - Learning objectives Expression estimation for known genes and transcripts FPKM/TPM expression estimates vs. raw counts Differential expression methods Downstream interpretation of expression and differential estimates Lectures Abundance Estimations lecture HTSEQ lecture Differential expression lecture Expression mini lecture If you would like a refresher on expression and abundance estimations, we have made a mini lecture. Use Stringtie to generate expression estimates from the SAM/BAM files generated by HISAT2 in the previous module Note on de novo transcript discovery and differential expression using Stringtie: In this module, we will run Stringtie in ‘reference only’ mode. For simplicity and to reduce run time, it is sometimes useful to perform expression analysis with only known transcript models. However, Stringtie can predict the transcripts present in each library instead (by dropping the ‘-G’ option in stringtie commands as described in the next module). Stringtie will then assign arbitrary transcript IDs to each transcript assembled from the data and estimate expression for those transcripts. One complication with this method is that in each library a different set of transcripts is likely to be predicted for each library. There may be a lot of similarities but the number of transcripts and their exact structure will differ in the output files for each library. Before you can compare across libraries you therefore need to determine which transcripts correspond to each other across the libraries. Stringtie provides a merge command to combine predicted transcript GTF files from across different libraries Once you have a merged GTF file you can run Stringtie again with this instead of the known transcripts GTF file we used above Stringtie also provides ‘gffcompare’ to compare predicted transcripts to known transcripts Refer to the Stringtie manual for a more detailed explanation: https://ccb.jhu.edu/software/stringtie/index.shtml?t=manual Stringtie basic usage: stringtie &lt;aligned_reads.bam&gt; [options]* Extra options specified below: ‘–rf’ tells StringTie that our data is stranded and to use the correct strand specific mode (i.e. assume a stranded library fr-firststrand). ‘-p 4’ tells StringTie to use 4 CPUs ‘-G ’ reference annotation to use for guiding the assembly process (GTF/GFF3) ‘-e’ only estimate the abundance of given reference transcripts (requires -G) ‘-B’ enable output of Ballgown table files which will be created in the same directory as the output GTF (requires -G, -o recommended) ‘-o’ output path/file name for the assembled transcripts GTF (default: stdout) ‘-A’ output path/file name for gene abundance estimates cd $RNA_HOME/ mkdir -p expression/stringtie/ref_only/ cd expression/stringtie/ref_only/ stringtie --rf -p 4 -G $RNA_REF_GTF -e -B -o HBR_Rep1/transcripts.gtf -A HBR_Rep1/gene_abundances.tsv $RNA_ALIGN_DIR/HBR_Rep1.bam stringtie --rf -p 4 -G $RNA_REF_GTF -e -B -o HBR_Rep2/transcripts.gtf -A HBR_Rep2/gene_abundances.tsv $RNA_ALIGN_DIR/HBR_Rep2.bam stringtie --rf -p 4 -G $RNA_REF_GTF -e -B -o HBR_Rep3/transcripts.gtf -A HBR_Rep3/gene_abundances.tsv $RNA_ALIGN_DIR/HBR_Rep3.bam stringtie --rf -p 4 -G $RNA_REF_GTF -e -B -o UHR_Rep1/transcripts.gtf -A UHR_Rep1/gene_abundances.tsv $RNA_ALIGN_DIR/UHR_Rep1.bam stringtie --rf -p 4 -G $RNA_REF_GTF -e -B -o UHR_Rep2/transcripts.gtf -A UHR_Rep2/gene_abundances.tsv $RNA_ALIGN_DIR/UHR_Rep2.bam stringtie --rf -p 4 -G $RNA_REF_GTF -e -B -o UHR_Rep3/transcripts.gtf -A UHR_Rep3/gene_abundances.tsv $RNA_ALIGN_DIR/UHR_Rep3.bam What does the raw output from Stringtie look like? For details on the Stringtie output files refer to Stringtie manual (outputs section) less -S UHR_Rep1/transcripts.gtf View transcript records only and improve formatting grep -v &quot;^#&quot; UHR_Rep1/transcripts.gtf | grep -w &quot;transcript&quot; | column -t | less -S Limit the view to transcript records and their expression values (FPKM and TPM values) awk &#39;{if ($3==&quot;transcript&quot;) print}&#39; UHR_Rep1/transcripts.gtf | cut -f 1,4,9 | less -S Press ‘q’ to exit the ‘less’ display Gene and transcript level expression values can also be viewed in these two files: column -t UHR_Rep1/t_data.ctab | less -S less -S -x20 UHR_Rep1/gene_abundances.tsv Create a tidy expression matrix files for the StringTie results. This will be done at both the gene and transcript level and also will take into account the various expression measures produced: coverage, FPKM, and TPM. cd $RNA_HOME/expression/stringtie/ref_only/ wget https://raw.githubusercontent.com/griffithlab/rnabio.org/master/assets/scripts/stringtie_expression_matrix.pl chmod +x stringtie_expression_matrix.pl ./stringtie_expression_matrix.pl --expression_metric=TPM --result_dirs=&#39;HBR_Rep1,HBR_Rep2,HBR_Rep3,UHR_Rep1,UHR_Rep2,UHR_Rep3&#39; --transcript_matrix_file=transcript_tpm_all_samples.tsv --gene_matrix_file=gene_tpm_all_samples.tsv ./stringtie_expression_matrix.pl --expression_metric=FPKM --result_dirs=&#39;HBR_Rep1,HBR_Rep2,HBR_Rep3,UHR_Rep1,UHR_Rep2,UHR_Rep3&#39; --transcript_matrix_file=transcript_fpkm_all_samples.tsv --gene_matrix_file=gene_fpkm_all_samples.tsv ./stringtie_expression_matrix.pl --expression_metric=Coverage --result_dirs=&#39;HBR_Rep1,HBR_Rep2,HBR_Rep3,UHR_Rep1,UHR_Rep2,UHR_Rep3&#39; --transcript_matrix_file=transcript_coverage_all_samples.tsv --gene_matrix_file=gene_coverage_all_samples.tsv column -t transcript_tpm_all_samples.tsv | less -S column -t gene_tpm_all_samples.tsv | less -S Later we will use these files to perform various comparisons of expression estimation tools (e.g. stringtie, kallisto, raw counts) and metrics (e.g. FPKM vs TPM). PRACTICAL EXERCISE 8 Assignment: Use StringTie to Calculate transcript-level expression estimates for the alignments (bam files) you created in Practical Exercise 6. Hint: You should have six commands for 3 replicates each of tumor and normal samples. Solution: When you are ready you can check your approach against the Solutions RNA-seq_Flowchart4 Mini-lecture For more on the differences between abundance estimates like FPKM and count data with HTSeq-count, see this mini lecture. HTSEQ-COUNT Run htseq-count on alignments instead to produce raw counts instead of FPKM/TPM values for differential expression analysis Refer to the HTSeq documentation for a more detailed explanation: https://htseq.readthedocs.io/en/release_0.11.1/count.html htseq-count basic usage: htseq-count [options] &lt;sam_file&gt; &lt;gff_file&gt; Extra options specified below: ‘–format’ specify the input file format one of BAM or SAM. Since we have BAM format files, select ‘bam’ for this option. ‘–order’ provide the expected sort order of the input file. Previously we generated position sorted BAM files so use ‘pos’. ‘–mode’ determines how to deal with reads that overlap more than one feature. We believe the ‘intersection-strict’ mode is best. ‘–stranded’ specifies whether data is stranded or not. The TruSeq strand-specific RNA libraries suggest the ‘reverse’ option for this parameter. ‘–minaqual’ will skip all reads with alignment quality lower than the given minimum value ‘–type’ specifies the feature type (3rd column in GFF file) to be used. (default, suitable for RNA-Seq and Ensembl GTF files: exon) ‘–idattr’ The feature ID used to identify the counts in the output table. The default, suitable for RNA-SEq and Ensembl GTF files, is gene_id. Run htseq-count and calculate gene-level counts: cd $RNA_HOME/ mkdir -p expression/htseq_counts cd expression/htseq_counts htseq-count --format bam --order pos --mode intersection-strict --stranded reverse --minaqual 1 --type exon --idattr gene_id $RNA_ALIGN_DIR/UHR_Rep1.bam $RNA_REF_GTF &gt; UHR_Rep1_gene.tsv htseq-count --format bam --order pos --mode intersection-strict --stranded reverse --minaqual 1 --type exon --idattr gene_id $RNA_ALIGN_DIR/UHR_Rep2.bam $RNA_REF_GTF &gt; UHR_Rep2_gene.tsv htseq-count --format bam --order pos --mode intersection-strict --stranded reverse --minaqual 1 --type exon --idattr gene_id $RNA_ALIGN_DIR/UHR_Rep3.bam $RNA_REF_GTF &gt; UHR_Rep3_gene.tsv htseq-count --format bam --order pos --mode intersection-strict --stranded reverse --minaqual 1 --type exon --idattr gene_id $RNA_ALIGN_DIR/HBR_Rep1.bam $RNA_REF_GTF &gt; HBR_Rep1_gene.tsv htseq-count --format bam --order pos --mode intersection-strict --stranded reverse --minaqual 1 --type exon --idattr gene_id $RNA_ALIGN_DIR/HBR_Rep2.bam $RNA_REF_GTF &gt; HBR_Rep2_gene.tsv htseq-count --format bam --order pos --mode intersection-strict --stranded reverse --minaqual 1 --type exon --idattr gene_id $RNA_ALIGN_DIR/HBR_Rep3.bam $RNA_REF_GTF &gt; HBR_Rep3_gene.tsv Merge results files into a single matrix for use in edgeR. The following joins the results for each replicate together, adds a header, reformats the result as a tab delimited file, and shows you the first 10 lines of the resulting file : cd $RNA_HOME/expression/htseq_counts/ join UHR_Rep1_gene.tsv UHR_Rep2_gene.tsv | join - UHR_Rep3_gene.tsv | join - HBR_Rep1_gene.tsv | join - HBR_Rep2_gene.tsv | join - HBR_Rep3_gene.tsv &gt; gene_read_counts_table_all.tsv echo &quot;GeneID UHR_Rep1 UHR_Rep2 UHR_Rep3 HBR_Rep1 HBR_Rep2 HBR_Rep3&quot; &gt; header.txt cat header.txt gene_read_counts_table_all.tsv | grep -v &quot;__&quot; | awk -v OFS=&quot;\\t&quot; &#39;$1=$1&#39; &gt; gene_read_counts_table_all_final.tsv rm -f gene_read_counts_table_all.tsv header.txt head gene_read_counts_table_all_final.tsv | column -t -grep -v \"__\" is being used to filter out the summary lines at the end of the files that ht-seq count gives to summarize reads that had no feature, were ambiguous, did not align at all, did not align due to poor alignment quality, or the alignment was not unique. -awk -v OFS=\"\\t\" '$1=$1' is using awk to replace the single space characters that were in the concatenated version of our header.txt and gene_read_counts_table_all.tsv with a tab character. -v is used to reset the variable OFS, which stands for Output Field Separator. By default, this is a single space. By specifying OFS=\"\\t\", we are telling awk to replace the single space with a tab. The '$1=$1' tells awk to reevaluate the input using the new output variable. Prepare for DE analysis using htseq-count results Create a directory for the DEseq analysis based on the htseq-count results: cd $RNA_HOME/ mkdir -p de/htseq_counts cd de/htseq_counts Note that the htseq-count results provide counts for each gene but uses only the Ensembl Gene ID (e.g. ENSG00000054611). This is not very convenient for biological interpretation. This next step creates a mapping file that will help us translate from ENSG IDs to Symbols. It does this by parsing the GTF transcriptome file we got from Ensembl. That file contains both gene names and IDs. Unfortunately, this file is a bit complex to parse. Furthermore, it contains the ERCC transcripts, and these have their own naming convention which also complicates the parsing. # cut the 9th column with all the gene annotation information # delete all the double quotes from this string # use perl to search for the pattern &quot;gene_id&quot; or &quot;gene_name&quot; followed by space character and then some non-space characters. # the non-space characters are the actual gene ID or Name. Store these in variables $gid and $gname and then print them out # use sort and unique commands to produce a unique list of gene_name, gene_id combinations cut -f 9 $RNA_REF_GTF | tr -d &#39;&quot;&#39; | perl -ne &#39;chomp; if ($_ =~ /gene_id\\s+(\\S+);/){$gid = $1}; if ($_ =~ /gene_name\\s+(\\S+);/){$gname = $1}; print &quot;$gid\\t$gname\\n&quot;&#39; | sort | uniq &gt; ENSG_ID2Name.txt head ENSG_ID2Name.txt Determine the number of unique Ensembl Gene IDs and symbols. What does this tell you? #count unique gene ids cut -f 1 ENSG_ID2Name.txt | sort | uniq | wc -l #count unique gene names cut -f 2 ENSG_ID2Name.txt | sort | uniq | wc -l #show the most repeated gene names cut -f 2 ENSG_ID2Name.txt | sort | uniq -c | sort -r | head ERCC expression analysis Based on the above read counts, plot the linearity of the ERCC spike-in read counts observed in our RNA-seq data versus the expected concentration of the ERCC spike-in Mix. First download a file describing the expected concentrations and fold-change differences for the ERCC spike-in reagent. mkdir $RNA_HOME/expression/ercc_spikein_analysis/ cd $RNA_HOME/expression/ercc_spikein_analysis/ wget http://genomedata.org/rnaseq-tutorial/ERCC_Controls_Analysis.txt cat ERCC_Controls_Analysis.txt We will then merge our experimental RNA-seq read counts, determined for the ERCC transcripts, onto the table of expected concentrations. Finally, we will produce an x-y scatter plot that compares the expected and observed values. First, start an R session: R Now combine the ERCC expected concentration data with the observed RNA-seq expression values and produce x-y scatter plots that compare the expected and observed values for HTSEQ raw counts and StringTie TPM abundance estimates. library(&quot;ggplot2&quot;) library(&quot;data.table&quot;) #load in the reference/expected concentration and fold change values for each ERCC transcript ercc_ref = read.table(&quot;ERCC_Controls_Analysis.txt&quot;, header=TRUE, sep=&quot;\\t&quot;) names(ercc_ref) = c(&quot;id&quot;, &quot;ercc_id&quot;, &quot;subgroup&quot;, &quot;ref_conc_mix_1&quot;, &quot;ref_conc_mix_2&quot;, &quot;ref_fc_mix1_vs_mix2&quot;, &quot;ref_log2_mix1_vs_mix2&quot;) head(ercc_ref) dim(ercc_ref) #load the RNA-seq raw counts values for all samples and combined with the expected ERCC values rna_counts_file = &quot;~/workspace/rnaseq/expression/htseq_counts/gene_read_counts_table_all_final.tsv&quot;; rna_counts = read.table(rna_counts_file, header=TRUE, sep=&quot;\\t&quot;) dim(rna_counts) #combine the ERCC expected concentration information with the observed RNA-seq counts ercc_ref_counts = merge(x = ercc_ref, y = rna_counts, by.x = &quot;ercc_id&quot;, by.y = &quot;GeneID&quot;, all.x = TRUE) #convert UHR data to &quot;long&quot; format uhr_data = ercc_ref_counts[,c(&quot;ercc_id&quot;,&quot;subgroup&quot;,&quot;ref_conc_mix_1&quot;,&quot;UHR_Rep1&quot;,&quot;UHR_Rep2&quot;,&quot;UHR_Rep3&quot;)] uhr_data_long = melt(setDT(uhr_data), id.vars = c(&quot;ercc_id&quot;,&quot;subgroup&quot;,&quot;ref_conc_mix_1&quot;), variable.name = &quot;sample&quot;) uhr_data_long$mix = &quot;mix 1&quot; names(uhr_data_long) = c(&quot;ercc_id&quot;, &quot;subgroup&quot;, &quot;concentration&quot;, &quot;sample&quot;, &quot;count&quot;, &quot;mix&quot;) #convert HBR data to &quot;long&quot; format hbr_data = ercc_ref_counts[,c(&quot;ercc_id&quot;,&quot;subgroup&quot;,&quot;ref_conc_mix_2&quot;,&quot;HBR_Rep1&quot;,&quot;HBR_Rep2&quot;,&quot;HBR_Rep3&quot;)] hbr_data_long = melt(setDT(hbr_data), id.vars = c(&quot;ercc_id&quot;,&quot;subgroup&quot;,&quot;ref_conc_mix_2&quot;), variable.name = &quot;sample&quot;) hbr_data_long$mix = &quot;mix 2&quot; names(hbr_data_long) = c(&quot;ercc_id&quot;, &quot;subgroup&quot;, &quot;concentration&quot;, &quot;sample&quot;, &quot;count&quot;, &quot;mix&quot;) #rejoin the UHR and HBR tpm data ercc_ref_counts_long &lt;- rbind(uhr_data_long, hbr_data_long) head(ercc_ref_counts_long) dim(ercc_ref_counts_long) #fit a linear model and calculate correlation between expected concentations and observed TPM values min_nonzero_count = min(ercc_ref_counts_long$count[ercc_ref_counts_long$count &gt; 0]) ercc_ref_counts_long$log_count = log2(ercc_ref_counts_long$count + min_nonzero_count) min_nonzero_conc = min(ercc_ref_counts_long$concentration[ercc_ref_counts_long$concentration &gt; 0]) ercc_ref_counts_long$log_concentration= log2(ercc_ref_counts_long$concentration + min_nonzero_conc) count_model &lt;- lm(log_count ~ log_concentration, data=ercc_ref_counts_long) count_r_squared = summary(count_model)[[&quot;r.squared&quot;]] count_slope = coef(count_model)[&quot;log_concentration&quot;] p1 = ggplot(ercc_ref_counts_long, aes(x=log_concentration, y=log_count)) p1 = p1 + geom_point(aes(shape=mix, color=sample)) p1 = p1 + geom_smooth(method=lm) p1 = p1 + annotate(&quot;text&quot;, 10, 5, label=paste(&quot;R^2 =&quot;, round(count_r_squared, digits=2), sep=&quot; &quot;)) p1 = p1 + annotate(&quot;text&quot;, 10, 4, label=paste(&quot;Slope =&quot;, round(count_slope, digits=2), sep=&quot; &quot;)) p1 = p1 + xlab(&quot;Log2 (expected concentration [amol/uL] + min non-zero value)&quot;) + ylab(&quot;Log2 (observed count + min non-zero value)&quot;) pdf(&quot;ERCC_Count_Expression_vs_SpikeInConcentration.pdf&quot;) print(p1) dev.off() #load the RNA-seq TPM values for all samples and combine with expected ERCC values rna_tpms_file = &quot;~/workspace/rnaseq/expression/stringtie/ref_only/gene_tpm_all_samples.tsv&quot; rna_tpms = read.table(rna_tpms_file, header=TRUE, sep=&quot;\\t&quot;) dim(rna_tpms) #combine the ERCC expected concentration information with the observed RNA-seq TPM values ercc_ref_tpms = merge(x = ercc_ref, y = rna_tpms, by.x = &quot;ercc_id&quot;, by.y = &quot;Gene_ID&quot;, all.x = TRUE) dim(ercc_ref_tpms) #convert UHR data to &quot;long&quot; format uhr_data = ercc_ref_tpms[,c(&quot;ercc_id&quot;,&quot;subgroup&quot;,&quot;ref_conc_mix_1&quot;,&quot;UHR_Rep1&quot;,&quot;UHR_Rep2&quot;,&quot;UHR_Rep3&quot;)] uhr_data_long = melt(setDT(uhr_data), id.vars = c(&quot;ercc_id&quot;,&quot;subgroup&quot;,&quot;ref_conc_mix_1&quot;), variable.name = &quot;sample&quot;) uhr_data_long$mix = &quot;mix 1&quot; names(uhr_data_long) = c(&quot;ercc_id&quot;, &quot;subgroup&quot;, &quot;concentration&quot;, &quot;sample&quot;, &quot;tpm&quot;, &quot;mix&quot;) #convert HBR data to &quot;long&quot; format hbr_data = ercc_ref_tpms[,c(&quot;ercc_id&quot;,&quot;subgroup&quot;,&quot;ref_conc_mix_2&quot;,&quot;HBR_Rep1&quot;,&quot;HBR_Rep2&quot;,&quot;HBR_Rep3&quot;)] hbr_data_long = melt(setDT(hbr_data), id.vars = c(&quot;ercc_id&quot;,&quot;subgroup&quot;,&quot;ref_conc_mix_2&quot;), variable.name = &quot;sample&quot;) hbr_data_long$mix = &quot;mix 2&quot; names(hbr_data_long) = c(&quot;ercc_id&quot;, &quot;subgroup&quot;, &quot;concentration&quot;, &quot;sample&quot;, &quot;tpm&quot;, &quot;mix&quot;) #rejoin the UHR and HBR tpm data ercc_ref_tpms_long &lt;- rbind(uhr_data_long, hbr_data_long) head(ercc_ref_tpms_long) dim(ercc_ref_tpms_long) #fit a linear model and calculate correlation between expected concentations and observed TPM values min_nonzero_tpm = min(ercc_ref_tpms_long$tpm[ercc_ref_tpms_long$tpm &gt; 0]) ercc_ref_tpms_long$log_tpm = log2(ercc_ref_tpms_long$tpm + min_nonzero_tpm) min_nonzero_conc = min(ercc_ref_tpms_long$concentration[ercc_ref_tpms_long$concentration &gt; 0]) ercc_ref_tpms_long$log_concentration= log2(ercc_ref_tpms_long$concentration + min_nonzero_conc) tpm_model &lt;- lm(log_tpm ~ log_concentration, data=ercc_ref_tpms_long) tpm_r_squared = summary(tpm_model)[[&quot;r.squared&quot;]] tpm_slope = coef(tpm_model)[&quot;log_concentration&quot;] p2 = ggplot(ercc_ref_tpms_long, aes(x=log_concentration, y=log_tpm)) p2 = p2 + geom_point(aes(shape=mix, color=sample)) p2 = p2 + geom_smooth(method=lm) p2 = p2 + annotate(&quot;text&quot;, 10, 5, label=paste(&quot;R^2 =&quot;, round(tpm_r_squared, digits=2), sep=&quot; &quot;)) p2 = p2 + annotate(&quot;text&quot;, 10, 4, label=paste(&quot;Slope =&quot;, round(tpm_slope, digits=2), sep=&quot; &quot;)) p2 = p2 + xlab(&quot;Log2 (expected concentration [amol/uL] + min non-zero value)&quot;) + ylab(&quot;Log2 (observed TPM estimate + min non-zero value)&quot;) pdf(&quot;ERCC_TPM_Expression_vs_SpikeInConcentration.pdf&quot;) print(p2) dev.off() # Exit the R session quit(save=&quot;no&quot;) To view the resulting figures, navigate to the below URL replacing YOUR_IP_ADDRESS with your amazon instance IP address: $RNA_HOME/ercc_spikein_analysis/ http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/expression/ercc_spikein_analysis/ERCC_Count_Expression_vs_SpikeInConcentration.pdf http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/expression/ercc_spikein_analysis/ERCC_TPM_Expression_vs_SpikeInConcentration.pdf Which expression estimation (read counts or TPM values) are better representing the known/expected ERCC concentrations? Why? Some notes of interpretation In general the expression estimates for ERCC transcripts we are getting from our data are highly correlated with the expected concentrations for the ERCC spike-in reagent There are some ERRC transcripts that were not detected in our data at all (count and TPM of 0). These correspond to a range of expected concentrations in the spile-in reagent but they are all at the lower end. Essentially this indicates a sensitivity limitation. With our downsampled RNAseq data, we are failing to detect some of the less abundant spiked-in ERCC transcripts. This is probably hurting our R squared values slightly. We observed a wide range of observed expression values for ERCC transcripts in both mixes. Remember that both mixes have ERCCs at low, medium, high levels (spread over 5-6 orders of magnitude). But between the two mixes the ERCCs at each expected concentration are different. Details on the ERCC spike-in reagent Differential Expression mini lecture If you would like a brief refresher on differential expression analysis, please refer to the mini lecture. Ballgown DE Analysis Use Ballgown to compare the UHR and HBR conditions. Refer to the Ballgown manual for a more detailed explanation: https://www.bioconductor.org/packages/release/bioc/html/ballgown.html Create and change to ballgown ref-only results directory: mkdir -p $RNA_HOME/de/ballgown/ref_only/ cd $RNA_HOME/de/ballgown/ref_only/ Perform UHR vs. HBR comparison, using all replicates, for known (reference only mode) transcripts: First, start an R session: R Run the following R commands in your R session. # load the required libraries library(ballgown) library(genefilter) library(dplyr) library(devtools) # Create phenotype data needed for ballgown analysis ids = c(&quot;UHR_Rep1&quot;, &quot;UHR_Rep2&quot;, &quot;UHR_Rep3&quot;, &quot;HBR_Rep1&quot;, &quot;HBR_Rep2&quot;, &quot;HBR_Rep3&quot;) type = c(&quot;UHR&quot;, &quot;UHR&quot;, &quot;UHR&quot;, &quot;HBR&quot;, &quot;HBR&quot;, &quot;HBR&quot;) inputs = &quot;/home/ubuntu/workspace/rnaseq/expression/stringtie/ref_only/&quot; path = paste(inputs, ids, sep=&quot;&quot;) pheno_data = data.frame(ids, type, path) # Load ballgown data structure and save it to a variable &quot;bg&quot; bg = ballgown(samples = as.vector(pheno_data$path), pData = pheno_data) # Display a description of this object bg # Load all attributes including gene name bg_table = texpr(bg, &#39;all&#39;) bg_gene_names = unique(bg_table[, 9:10]) bg_transcript_names = unique(bg_table[, c(1, 6)]) # Save the ballgown object to a file for later use save(bg, file = &#39;bg.rda&#39;) # Pull the gene and transcript expression data frame from the ballgown object gene_expression = as.data.frame(gexpr(bg)) transcript_expression = as.data.frame(texpr(bg)) # Perform differential expression (DE) analysis with no filtering, at both gene and transcript level # Then add on transcript/gene names and sample level fpkm values for export results_transcripts = stattest(bg, feature = &quot;transcript&quot;, covariate = &quot;type&quot;, getFC = TRUE, meas = &quot;FPKM&quot;) results_transcripts = merge(results_transcripts, bg_transcript_names, by.x = c(&quot;id&quot;), by.y = c(&quot;t_id&quot;)) results_transcripts = merge(results_transcripts, transcript_expression, by.x = c(&quot;id&quot;), by.y = c(&quot;row.names&quot;)) results_genes = stattest(bg, feature = &quot;gene&quot;, covariate = &quot;type&quot;, getFC = TRUE, meas = &quot;FPKM&quot;) results_genes = merge(results_genes, bg_gene_names, by.x = c(&quot;id&quot;), by.y = c(&quot;gene_id&quot;)) results_genes = merge(results_genes, gene_expression, by.x = c(&quot;id&quot;), by.y = c(&quot;row.names&quot;)) # Save a tab delimited file for both the transcript and gene results write.table(results_transcripts, &quot;UHR_vs_HBR_transcript_results.tsv&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) write.table(results_genes, &quot;UHR_vs_HBR_gene_results.tsv&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) # Filter low-abundance genes. Here we remove all transcripts with a variance across the samples of less than one bg_filt = subset (bg, &quot;SparseArray::rowVars(texpr(bg)) &gt; 1&quot;, genomesubset = TRUE) # Load all attributes including gene name bg_filt_table = texpr(bg_filt , &#39;all&#39;) bg_filt_gene_names = unique(bg_filt_table[, 9:10]) bg_filt_transcript_names = unique(bg_filt_table[, c(1,6)]) # Perform DE analysis now using the filtered data results_transcripts = stattest(bg_filt, feature = &quot;transcript&quot;, covariate = &quot;type&quot;, getFC = TRUE, meas = &quot;FPKM&quot;) results_transcripts = merge(results_transcripts, bg_filt_transcript_names, by.x = c(&quot;id&quot;), by.y = c(&quot;t_id&quot;)) results_transcripts = merge(results_transcripts, transcript_expression, by.x = c(&quot;id&quot;), by.y = c(&quot;row.names&quot;)) results_genes = stattest(bg_filt, feature = &quot;gene&quot;, covariate = &quot;type&quot;, getFC = TRUE, meas = &quot;FPKM&quot;) results_genes = merge(results_genes, bg_filt_gene_names, by.x = c(&quot;id&quot;), by.y = c(&quot;gene_id&quot;)) results_genes = merge(results_genes, gene_expression, by.x = c(&quot;id&quot;), by.y = c(&quot;row.names&quot;)) # Output the filtered list of genes and transcripts and save to tab delimited files write.table(results_transcripts, &quot;UHR_vs_HBR_transcript_results_filtered.tsv&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) write.table(results_genes, &quot;UHR_vs_HBR_gene_results_filtered.tsv&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) # Identify the significant genes with p-value &lt; 0.05 sig_transcripts = subset(results_transcripts, results_transcripts$pval&lt;0.05) sig_genes = subset(results_genes, results_genes$pval&lt;0.05) # Output the significant gene results to a pair of tab delimited files write.table(sig_transcripts, &quot;UHR_vs_HBR_transcript_results_sig.tsv&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) write.table(sig_genes, &quot;UHR_vs_HBR_gene_results_sig.tsv&quot;, sep = &quot;\\t&quot;, quote = FALSE, row.names = FALSE) # Exit the R session quit(save = &quot;no&quot;) Once you have completed the Ballgown analysis in R, exit the R session and continue with the steps below. A copy of the above R code is located here. What does the raw output from Ballgown look like? head UHR_vs_HBR_gene_results.tsv How many genes are there on this chromosome? grep -v feature UHR_vs_HBR_gene_results.tsv | wc -l How many passed filter in UHR or HBR? grep -v feature UHR_vs_HBR_gene_results_filtered.tsv | wc -l How many differentially expressed genes were found on this chromosome (p-value &lt; 0.05)? grep -v feature UHR_vs_HBR_gene_results_sig.tsv | wc -l Display the top 20 DE genes. Look at some of those genes in IGV - do they make sense? In the following commands we use grep -v feature to remove lines that contain “feature”. Then we use sort to sort the data in various ways. The k option specifies that we want to sort on a particular column (3 in this case which has the DE fold change values). The n option tells sort to sort numerically. The r option tells sort to reverse the sort. grep -v feature UHR_vs_HBR_gene_results_sig.tsv | sort -rnk 3 | head -n 20 | column -t #Higher abundance in UHR grep -v feature UHR_vs_HBR_gene_results_sig.tsv | sort -nk 3 | head -n 20 | column -t #Higher abundance in HBR Save all genes with P&lt;0.05 to a new file. grep -v feature UHR_vs_HBR_gene_results_sig.tsv | cut -f 6 | sed &#39;s/\\&quot;//g&#39; &gt; DE_genes.txt head DE_genes.txt PRACTICAL EXERCISE 9 Assignment: Use Ballgown to identify differentially expressed genes from the StringTie expression estimates (i.e., Ballgown table files) which you created in Practical Exercise 8. Hint: Follow the example R code above. Hint: You will need to change how the pheno_data object is created to point to the correct sample ids, type, and path to your inputs (the StringTie results files). Hint: Make sure to save your ballgown data object to file (e.g., bg.rda) for use in subsequent practical exercises. Hint: You may wish to save both a complete list of genes with differential expression results as well as a subset which are filtered and pass a significance test Solution: When you are ready you can check your approach against the Solutions ERCC DE Analysis This section will compare the differential expression estimates obtained by the RNAseq analysis against the expected differential expression results for the ERCC spike-in RNAs (mix1-UHR vs mix2-HBR): First set up a directory to store the results of this analysis. mkdir $RNA_HOME/de/ercc_spikein_analysis/ cd $RNA_HOME/de/ercc_spikein_analysis/ wget http://genomedata.org/rnaseq-tutorial/ERCC_Controls_Analysis.txt cat ERCC_Controls_Analysis.txt Using R load the expected and observed ERCC DE results and produce a visualization. First, start an R session: R Work through the following R commands library(ggplot2) #load the ERCC expected fold change values for mix1 vs mix2 ercc_ref = read.table(&quot;ERCC_Controls_Analysis.txt&quot;, header=TRUE, sep=&quot;\\t&quot;) names(ercc_ref) = c(&quot;id&quot;, &quot;ercc_id&quot;, &quot;subgroup&quot;, &quot;ref_conc_mix_1&quot;, &quot;ref_conc_mix_2&quot;, &quot;ref_fc_mix1_vs_mix2&quot;, &quot;ref_log2_mix1_vs_mix2&quot;) head(ercc_ref) dim(ercc_ref) #load the observed fold change values determined by our RNA-seq analysis rna_de_file = &quot;~/workspace/rnaseq/de/ballgown/ref_only/UHR_vs_HBR_gene_results.tsv&quot;; rna_de = read.table(rna_de_file, header=TRUE, sep=&quot;\\t&quot;) tail(rna_de) dim(rna_de) #combine the expected and observed data into a single data table ercc_ref_de = merge(x = ercc_ref, y = rna_de, by.x = &quot;ercc_id&quot;, by.y = &quot;id&quot;, all.x = TRUE) head(ercc_ref_de) dim(ercc_ref_de) #convert fold change values to log2 scale ercc_ref_de$observed_log2_fc = log2(ercc_ref_de$fc) ercc_ref_de$expected_log2_fc = ercc_ref_de$ref_log2_mix1_vs_mix2 #fit a linear model and calculate R squared between the observed and expected fold change values model = lm(observed_log2_fc ~ expected_log2_fc, data=ercc_ref_de) r_squared = summary(model)[[&quot;r.squared&quot;]] #create a scatterplot to compare the observed and expected fold change values p = ggplot(ercc_ref_de, aes(x = expected_log2_fc, y = observed_log2_fc)) p = p + geom_point(aes(color = subgroup)) p = p + geom_smooth(method = lm) p = p + annotate(&quot;text&quot;, 1, 2, label=paste(&quot;R^2 =&quot;, r_squared, sep=&quot; &quot;)) p = p + xlab(&quot;Expected Fold Change (log2 scale)&quot;) p = p + ylab(&quot;Observed Fold Change in RNA-seq data (log2 scale)&quot;) #save the plot to a PDF pdf(&quot;ERCC_Ballgown-DE_vs_SpikeInDE.pdf&quot;) print(p) dev.off() # Exit the R session quit(save=&quot;no&quot;) View the results here: http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/de/ercc_spikein_analysis/ERCC_Ballgown-DE_vs_SpikeInDE.pdf Differential Expression mini lecture If you would like a brief refresher on differential expression analysis, please refer to the mini lecture. edgeR DE Analysis In this tutorial you will: Make use of the raw counts you generated previously using htseq-count edgeR is a bioconductor package designed specifically for differential expression of count-based RNA-seq data This is an alternative to using stringtie/ballgown to find differentially expressed genes First, create a directory for results: cd $RNA_HOME/ mkdir -p de/htseq_counts cd de/htseq_counts Note that the htseq-count results provide counts for each gene but uses only the Ensembl Gene ID (e.g. ENSG00000054611). This is not very convenient for biological interpretation. This next step creates a mapping file that will help us translate from ENSG IDs to Symbols. It does this by parsing the GTF transcriptome file we got from Ensembl. That file contains both gene names and IDs. Unfortunately, this file is a bit complex to parse. Furthermore, it contains the ERCC transcripts, and these have their own naming convention which also complicated the parsing. perl -ne &#39;if ($_ =~ /gene_id\\s\\&quot;(ENSG\\S+)\\&quot;\\;/) { $id = $1; $name = undef; if ($_ =~ /gene_name\\s\\&quot;(\\S+)&quot;\\;/) { $name = $1; }; }; if ($id &amp;&amp; $name) {print &quot;$id\\t$name\\n&quot;;} if ($_=~/gene_id\\s\\&quot;(ERCC\\S+)\\&quot;/){print &quot;$1\\t$1\\n&quot;;}&#39; $RNA_REF_GTF | sort | uniq &gt; ENSG_ID2Name.txt head ENSG_ID2Name.txt Determine the number of unique Ensembl Gene IDs and symbols. What does this tell you? #count unique gene ids cut -f 1 ENSG_ID2Name.txt | sort | uniq | wc -l #count unique gene names cut -f 2 ENSG_ID2Name.txt | sort | uniq | wc -l #show the most repeated gene names cut -f 2 ENSG_ID2Name.txt | sort | uniq -c | sort -r | head Launch R: R R code has been provided below. If you wish to have a script with all of the code, it can be found here. Run the R commands below. # set working directory where output will go working_dir = &quot;~/workspace/rnaseq/de/htseq_counts&quot; setwd(working_dir) # read in gene mapping mapping = read.table(&quot;~/workspace/rnaseq/de/htseq_counts/ENSG_ID2Name.txt&quot;, header = FALSE, stringsAsFactors = FALSE, row.names = 1) # read in count matrix rawdata = read.table(&quot;~/workspace/rnaseq/expression/htseq_counts/gene_read_counts_table_all_final.tsv&quot;, header = TRUE, stringsAsFactors = FALSE, row.names = 1) # Check dimensions dim(rawdata) # Require at least 1/6 of samples to have expressed count &gt;= 10 sample_cutoff = (1/6) count_cutoff = 10 #Define a function to calculate the fraction of values expressed above the count cutoff getFE = function(data,count_cutoff){ FE = (sum(data &gt;= count_cutoff) / length(data)) return(FE) } #Apply the function to all genes, and filter out genes not meeting the sample cutoff fraction_expressed = apply(rawdata, 1, getFE, count_cutoff) keep = which(fraction_expressed &gt;= sample_cutoff) rawdata = rawdata[keep, ] # Check dimensions again to see effect of filtering dim(rawdata) ################# # Running edgeR # ################# # load edgeR library(&quot;edgeR&quot;) # make class labels class = c(rep(&quot;UHR&quot;, 3), rep(&quot;HBR&quot;, 3)) # Get common gene names Gene = rownames(rawdata) Symbol = mapping[Gene, 1] gene_annotations = cbind(Gene, Symbol) # Make DGEList object y = DGEList(counts = rawdata, genes = gene_annotations, group = class) nrow(y) # TMM Normalization y = calcNormFactors(y) # Estimate dispersion y = estimateCommonDisp(y, verbose = TRUE) y = estimateTagwiseDisp(y) # Differential expression test et = exactTest(y) # Extract raw counts to add back onto DE results counts = getCounts(y) # Print top genes topTags(et) # Print number of up/down significant genes at FDR = 0.05 significance level summary(de &lt;- decideTests(et, adjust.method = &quot;BH&quot;, p = 0.05)) #Get output with BH-adjusted FDR values - all genes, any p-value, unsorted out = topTags(et, n = &quot;Inf&quot;, adjust.method = &quot;BH&quot;, sort.by = &quot;none&quot;, p.value = 1)$table #Add raw counts back onto results for convenience (make sure sort and total number of elements allows proper join) out2 = cbind(out, counts) #Limit to significantly DE genes out3 = out2[as.logical(de), ] # Order by p-value o = order(et$table$PValue[as.logical(de)], decreasing=FALSE) out4 = out3[o, ] # Save table write.table(out4, file = &quot;DE_genes.txt&quot;, quote = FALSE, row.names = FALSE, sep = &quot;\\t&quot;) #To exit R type the following quit(save = &quot;no&quot;) Once you have run the edgeR tutorial, compare the sigDE genes to those saved earlier from ballgown: head $RNA_HOME/de/ballgown/ref_only/DE_genes.txt head $RNA_HOME/de/htseq_counts/DE_genes.txt Pull out the gene IDs cd $RNA_HOME/de/ cut -f 1 $RNA_HOME/de/ballgown/ref_only/DE_genes.txt | sort | uniq &gt; ballgown_DE_gene_symbols.txt cut -f 2 $RNA_HOME/de/htseq_counts/DE_genes.txt | sort | uniq | grep -v Gene_Name &gt; htseq_counts_edgeR_DE_gene_symbols.txt Visualize overlap with a venn diagram. This can be done with simple web tools like: https://www.biovenn.nl/ http://bioinfogp.cnb.csic.es/tools/venny/ To get the two gene lists you could use cat to print out each list in your terminal and then copy/paste. cat ballgown_DE_gene_symbols.txt cat htseq_counts_edgeR_DE_gene_symbols.txt Alternatively you could view both lists in a web browser as you have done with other files. These two files should be here: http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/de/ballgown_DE_gene_symbols.txt http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/de/htseq_counts_edgeR_DE_gene_symbols.txt Example Venn Diagram (DE genes from StringTie/Ballgown vs HTSeq/EdgeR) {% include figure.html image=“/assets/module_3/venn-ballgown-vs-edger.png” width=“400” %} Differential Expression mini lecture If you would like a brief refresher on differential expression analysis, please refer to the mini lecture. DESeq2 DE Analysis In this tutorial you will: Make use of the raw counts you generated previously using htseq-count DESeq2 is a bioconductor package designed specifically for differential expression of count-based RNA-seq data This is an alternative to using stringtie/ballgown to find differentially expressed genes Setup First, create a directory for results. Then start R: cd $RNA_HOME/ mkdir -p de/deseq2 cd de/deseq2 R Once we start from R, the relevant packages should already be installed. We will load the libraries, set working directories, and read in the raw read counts data. Two pieces of information are required to perform analysis with DESeq2. A matrix of raw counts, such as was generated previously while running HTseq previously in this course. This is important as DESeq2 normalizes the data, correcting for differences in library size using using this type of data. DESeq2 also requires the experimental design which can be supplied as a data.frame, detailing the samples and conditions. # define working dir paths datadir = &quot;/home/ubuntu/workspace/rnaseq/expression/htseq_counts&quot; outdir = &quot;/home/ubuntu/workspace/rnaseq/de/deseq2&quot; # load R libraries we will use in this section library(DESeq2) library(data.table) library(ggplot2) # set working directory to data dir setwd(datadir) # read in the RNAseq read counts for each gene (produced by htseq-count) htseqCounts = fread(&quot;gene_read_counts_table_all_final.tsv&quot;) Format htseq counts data to work with DESeq2 DESeq2 has a number of options for data import and has a function to read HTseq output files directly. Here the most universal option is used, reading in raw counts from a matrix in simple TSV format (one row per gene, one column per sample). The HTseq count data that was read in above is stored as an object of class “data.table”, this can be verified with the class() function. Before use in this exercise it is required to convert this object to an appropriate matrix format with gene names as rows and samples as columns. It should be noted that while the replicate samples are technical replicates (i.e. the same library was sequenced), herein they are treated as biological replicates for illustrative purposes. DESeq2 does have a function to collapse technical replicates though. # view the class of the data class(htseqCounts) # convert the data.table to matrix format htseqCounts = as.matrix(htseqCounts) class(htseqCounts) # set the gene ID values to be the row names for the matrix rownames(htseqCounts) = htseqCounts[, &quot;GeneID&quot;] # now that the gene IDs are the row names, remove the redundant column that contains them htseqCounts = htseqCounts[, colnames(htseqCounts) != &quot;GeneID&quot;] # convert the count values from strings (with spaces) to integers, because originally the gene column contained characters, the entire matrix was set to character class(htseqCounts) = &quot;integer&quot; # view the first few lines of the gene count matrix head(htseqCounts) Filter raw counts Before running DESeq2 (or any differential expression analysis) it is useful to pre-filter data. There are computational benefits to doing this as the memory size of the objects within R will decrease and DESeq2 will have less data to work through and will be faster. By removing “low quality” data, it is also reduces the number of statistical tests that will be performed, which in turn reduces the impact of multiple test correction and can lead to more significant genes. The amount of pre-filtering is up to the analyst however, it should be done in an unbiased way. DESeq2 recommends removing any gene with less than 10 reads across all samples. Below, we filter a gene if at least 1 sample does not have at least 10 reads. Either way, mostly what is being removed here are genes with very little evidence for expression in any sample (in many cases gene with 0 counts in all samples). # run a filtering step # i.e. require that for every gene: at least 1 of 6 samples must have counts greater than 10 # get index of rows that meet this criterion and use that to subset the matrix # note the dimensions of the matrix before and after filtering with dim() # breaking apart the command below to understand it&#39;s outcome tail(htseqCounts) # look at the raw counts tail(htseqCounts &gt;= 10) # determine which cells have counts greater than 10 tail(rowSums(htseqCounts &gt;= 10)) # determine for which genes how many samples have counts greater than 10 tail(rowSums(htseqCounts &gt;= 10) &gt;= 1) # filter to those entries/genes for which at least one sample has counts greater than 10 tail(which(rowSums(htseqCounts &gt;= 10) &gt;= 1)) #obtain the index for the above filter criteria dim(htseqCounts) htseqCounts = htseqCounts[which(rowSums(htseqCounts &gt;= 10) &gt;= 1), ] dim(htseqCounts) Specifying the experimental design As mentioned above DESeq2 also needs to know the experimental design, that is which samples belong to which condition to test. The experimental design for the example dataset herein is quite simple as there are 6 samples with two conditions to compare (UHR vs HBR), as such we can just create the experimental design right within R. There is one important thing to note, DESeq2 does not check sample names, it expects that the column names in the counts matrix we created correspond exactly to the row names we specify in the experimental design. # construct a mapping of the meta data for our experiment (comparing UHR cell lines to HBR brain tissues) # this is defining the biological condition/label for each experimental replicate # create a simple one column dataframe to start metaData &lt;- data.frame(&quot;Condition&quot; = c(&quot;UHR&quot;, &quot;UHR&quot;, &quot;UHR&quot;, &quot;HBR&quot;, &quot;HBR&quot;, &quot;HBR&quot;)) # convert the &quot;Condition&quot; column to a factor data type # the arbitrary order of these factors will determine the direction of log2 fold-changes for the genes (i.e. up or down regulated) metaData$Condition = factor(metaData$Condition, levels = c(&quot;HBR&quot;, &quot;UHR&quot;)) # set the row names of the metaData dataframe to be the names of our sample replicates from the read counts matrix rownames(metaData) = colnames(htseqCounts) # view the metadata dataframe head(metaData) # check that names of htseq count columns match the names of the meta data rows # use the &quot;all&quot; function which tests whether an entire logical vector is TRUE all(rownames(metaData) == colnames(htseqCounts)) Construct the DESeq2 object piecing all the data together With all the data properly formatted it is now possible to combine all the information required to run differental expression in one object. This object will hold the input data, and intermediary calculations. It is also where the condition to test is specified. # make deseq2 data sets # here we are setting up our experiment by supplying: (1) the gene counts matrix, (2) the sample/replicate for each column, and (3) the biological conditions we wish to compare. # this is a simple example that works for many experiments but these can also get more complex # for example, including designs with multiple variables such as &quot;~ group + condition&quot;, # and designs with interactions such as &quot;~ genotype + treatment + genotype:treatment&quot;. dds = DESeqDataSetFromMatrix(countData = htseqCounts, colData = metaData, design = ~Condition) # the design formula above is often a point of confussion, it is useful to put in words what is happening, when we specify &quot;design = ~Condition&quot; we are saying # regress gene expression on condition, or put another way model gene expression on condition # gene expression is the response variable and condition is the explanatory variable # you can put words to formulas using this [cheat sheet](https://www.econometrics.blog/post/the-r-formula-cheatsheet/) Running DESeq2 With all the data now in place, DESeq2 can be run. Calling DESeq2 will perform the following actions: - Estimation of size factors. i.e. accounting for differences in sequencing depth (or library size) across samples. - Estimation of dispersion. i.e. estimate the biological variability (over and above the expected variation from sampling) in gene expression across biological replicates. This is needed to assess the significance of differences across conditions. Additional work is performed to correct for higher dispersion seen for genes with low expression. - Perform “independent filtering” to reduce the number of statistical tests performed (see ?results and this paper for details) - Negative Binomial GLM fitting and performing the Wald statistical test - Correct p values for multiple testing using the Benjamini and Hochberg method # run the DESeq2 analysis on the &quot;dds&quot; object dds = DESeq(dds) # view the first 5 lines of the DE results res = results(dds) head(res, 5) Log-fold change shrinkage It is good practice to shrink the log-fold change values, this does exactly what it sounds like, reducing the amount of log-fold change for genes where there are few counts which create huge variability that is not truly biological signal. Consider for example a gene for two samples, one sample has 1 read, and and one sample has 6 reads, that is a 6 fold change, that is likely not accurate. There are a number of algorithms that can be used to shrink log2 fold change, here we will use the apeglm algorithm, which does require the apeglm package to be installed. # shrink the log2 fold change estimates # shrinkage of effect size (log fold change estimates) is useful for visualization and ranking of genes # In simplistic terms, the goal of calculating &quot;dispersion estimates&quot; and &quot;shrinkage&quot; is also to account for the problem that # genes with low mean counts across replicates tend to have higher variability than those with higher mean counts. # Shrinkage attempts to correct for this. For a more detailed discussion of shrinkage refer to the DESeq2 vignette # first get the name of the coefficient (log fold change) to shrink resultsNames(dds) # now apply the shrinkage approach resLFC = lfcShrink(dds, coef = &quot;Condition_UHR_vs_HBR&quot;, type = &quot;apeglm&quot;) # make a copy of the shrinkage results to manipulate deGeneResult = resLFC # contrast the values before and after shrinkage # create a temporary, simplified data structure with the values before/after shrinkage, and create a new column called &quot;group&quot; with this label res_before = res res_before$group = &quot;before shrinkage&quot; res_after = deGeneResult res_after$group = &quot;after shrinkage&quot; res_combined = rbind(res_before[,c(&quot;log2FoldChange&quot;,&quot;group&quot;)], res_after[,c(&quot;log2FoldChange&quot;,&quot;group&quot;)]) # adjust the order so that the legend has &quot;before shrinkage&quot; listed first res_combined$group = factor(res_combined$group, levels = c(&quot;before shrinkage&quot;, &quot;after shrinkage&quot;)) # look at the fold change values head(res_before) head(res_after) p &lt;- ggplot(res_combined, aes(x = log2FoldChange, color = group)) + geom_density() + theme_bw() + scale_color_manual(values = c(&quot;before shrinkage&quot; = &quot;tomato4&quot;, &quot;after shrinkage&quot; = &quot;slategray&quot;)) + labs(color = &quot;Shrinkage status&quot;) ggsave(plot=p, filename = &quot;before_after_shrinkage.pdf&quot;, device=&quot;pdf&quot;, width=6, height=4, units=&quot;in&quot;) How did the results change before and after shinkage? What direction is each log2 fold change value moving? Note that for these data, the impact of shrinkage is very subtle but the pattern is that fold change values move towards 0. Annotate gene symbols onto the DE results DESeq2 was run with ensembl gene IDs as identifiers, this is not the most human friendly way to interpret results. Here gene symbols are merged onto the differential expressed gene list to make the results a bit more interpretable. # read in gene ID to name mappings (using &quot;fread&quot; an alternative to &quot;read.table&quot;) gene_id_mapping &lt;- fread(&quot;/home/ubuntu/workspace/rnaseq/de/htseq_counts/ENSG_ID2Name.txt&quot;, header = FALSE) # add names to the columns in the &quot;gene_id_mapping&quot; dataframe setnames(gene_id_mapping, c(&quot;ensemblID&quot;, &quot;Symbol&quot;)) # view the first few lines of the gene ID to name mappings head(gene_id_mapping) # merge on gene names deGeneResult$ensemblID = rownames(deGeneResult) deGeneResult = as.data.table(deGeneResult) deGeneResult = merge(deGeneResult, gene_id_mapping, by = &quot;ensemblID&quot;, all.x = TRUE) # merge the original raw count values onto this final dataframe to aid interpretation original_counts = as.data.frame(htseqCounts) original_counts[,&quot;ensemblID&quot;] = rownames(htseqCounts) deGeneResult = merge(deGeneResult, original_counts, by = &#39;ensemblID&#39;, all.x = TRUE) # view the final merged dataframe # based on the raw counts and fold change values what does a negative fold change mean with respect to our two conditions HBR and UHR? head(deGeneResult) Data manipulation With the DE analysis complete it is useful to view and filter the data frames to only the relevant genes. Here some basic data manipulation is performed, filtering to significant genes at specific thresholds. # view the top genes according to adjusted p-value deGeneResult[order(deGeneResult$padj), ] # view the top genes according to fold change deGeneResult[order(deGeneResult$log2FoldChange), ] # determine the number of up/down significant genes at FDR &lt; 0.05 significance level dim(deGeneResult)[1] # number of genes tested dim(deGeneResult[deGeneResult$padj &lt; 0.05])[1] #number of significant genes # order the DE results by adjusted p-value deGeneResultSorted = deGeneResult[order(deGeneResult$padj), ] # create a filtered data frame that limits to only the significant DE genes (adjusted p.value &lt; 0.05) deGeneResultSignificant = deGeneResultSorted[deGeneResultSorted$padj &lt; 0.05] Save results to files The data generated is now written out as tab separated files. Some of the DESeq2 objects are also saved as serialized R (RDS) objects which can be read back into R later for visualization. # set the working directory to the output dir where we will store any results files setwd(outdir) # save the final DE result (all genes) to an output file fwrite(deGeneResultSorted, file=&quot;DE_all_genes_DESeq2.tsv&quot;, sep=&quot;\\t&quot;) # save the final DE result (significant genes only) to an output file fwrite(deGeneResultSignificant, file=&quot;DE_sig_genes_DESeq2.tsv&quot;, sep=&quot;\\t&quot;) # save the DESeq2 objects for the data visualization section saveRDS(dds, &quot;dds.rds&quot;) saveRDS(res, &quot;res.rds&quot;) saveRDS(resLFC, &quot;resLFC.rds&quot;) Briefly examine the top over-expressed genes For both conditions (HBR and UHR) lets take a look at the top n genes but this time according to fold-change instead of p-value. # use the dplyr library to manipulate the dataframe library(dplyr) # create a new copy of the data frame, sorted by log2 fold change deGeneResultSortedFoldchange = arrange(deGeneResultSignificant, log2FoldChange) # create a convenient data structure with just the top n genes from each condition top_bottom = bind_rows( head(deGeneResultSortedFoldchange, 10) %&gt;% mutate(Set = &quot;Bottom 10&quot;), tail(deGeneResultSortedFoldchange, 10) %&gt;% mutate(Set = &quot;Top 10&quot;) ) # visualize data for the top n genes. Simplify the output a bit print(top_bottom[,c(&quot;log2FoldChange&quot;,&quot;padj&quot;,&quot;Symbol&quot;,&quot;UHR_Rep1&quot;,&quot;UHR_Rep2&quot;,&quot;UHR_Rep3&quot;,&quot;HBR_Rep1&quot;,&quot;HBR_Rep2&quot;,&quot;HBR_Rep3&quot;,&quot;Set&quot;)]) #To exit R type the following quit(save = &quot;no&quot;) Perform some preliminary exploration of DE genes using webtools Download the file: outdir/DE_sig_genes_DESeq2.tsv. Open this spreadsheet, sort on “log2FoldChange” column and find the top 100 significant genes with higher expression in HBR (brain). Also download the file: outdir/DE_all_genes_DESeq2.tsv (to be used as a list of background genes or where we want the fold-change value for every gene). Try querying with the top 100 HBR over-expressed genes using: g:Profiler Try querying with the top 100 HBR over-expressed genes using: TissueEnrich. Use the Tissue Enrichment tool. This tool also requires a Background Gene List. Use all genes in DE_all_genes_DESeq2.tsv for this purpose. You can also manually explore some individual genes over-expressed in UHR with the Tissue-Specific Genes tool. For example, try PRAME and SERPIND1, two of the top UHR genes. g:Profiler example result {% include figure.html image=“/assets/module_3/Gprofiler-example.png” width=“1200” %} TissueEnrich summary for top 100 HBR over-expressed genes {% include figure.html image=“/assets/module_3/TissueEnrich-HBR-Genes-1.png” width=“1200” %} TissueEnrich result for Cerebral Cortex tissue {% include figure.html image=“/assets/module_3/TissueEnrich-HBR-Genes-2.png” width=“1200” %} TissueEnrich example for UHR over-expressed gene: PRAME {% include figure.html image=“/assets/module_3/TissueEnrich-UHR-PRAME.png” width=“1200” %} TissueEnrich example for UHR over-expressed gene: SERPIND1 {% include figure.html image=“/assets/module_3/TissueEnrich-UHR-SERPIND1.png” width=“1200” %} Does all of this make sense when we think about the makeup of the HBR and UHR samples? Refer back to the description of the samples. In this section we will compare the DE gene lists obtained from different DE methods (e.g. Ballgown, EdgeR, DESeq2) Visualize overlap with a venn diagram. This can be done with simple web tools like: https://www.biovenn.nl/ http://bioinfogp.cnb.csic.es/tools/venny/ Once you have run the DESeq2 tutorial, compare the sigDE genes to those saved earlier from ballgown and/or edgeR: head $RNA_HOME/de/ballgown/ref_only/DE_genes.txt head $RNA_HOME/de/htseq_counts/DE_genes.txt head $RNA_HOME/de/deseq2/DE_sig_genes_DESeq2.tsv Pull out the gene IDs cd $RNA_HOME/de/ cut -f 1 $RNA_HOME/de/ballgown/ref_only/DE_genes.txt | sort | uniq &gt; ballgown_DE_gene_symbols.txt cut -f 2 $RNA_HOME/de/htseq_counts/DE_genes.txt | sort | uniq | grep -v Gene_Name &gt; htseq_counts_edgeR_DE_gene_symbols.txt cut -f 7 $RNA_HOME/de/deseq2/DE_sig_genes_DESeq2.tsv | sort | uniq | grep -v Symbol &gt; DESeq2_DE_gene_symbols.txt To get the two gene lists you could use cat to print out each list in your terminal and then copy/paste. cat ballgown_DE_gene_symbols.txt cat htseq_counts_edgeR_DE_gene_symbols.txt cat DESeq2_DE_gene_symbols.txt Alternatively you could view both lists in a web browser as you have done with other files. These two files should be here: http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/de/ballgown_DE_gene_symbols.txt http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/de/DESeq2_DE_gene_symbols.txt http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/de/htseq_counts_edgeR_DE_gene_symbols.txt Example Venn Diagram (Two-way comparison: DE genes from StringTie/Ballgown vs HTSeq/DESeq2) {% include figure.html image=“/assets/module_3/venn-ballgown-vs-deseq2.png” width=“400” %} Example Venn Diagram (Three-way comparison: DE genes from StringTie/Ballgown vs HTSeq/DESeq2 vs HTSeq/EdgeR) {% include figure.html image=“/assets/module_3/venn-ballgown-vs-deseq2-vs-edger.png” width=“500” %} Ballgown DE Visualization Navigate to the correct directory and then launch R: cd $RNA_HOME/de/ballgown/ref_only R A separate R tutorial file has been provided below. Run the R commands detailed in the R script. All results are directed to pdf file(s). The output pdf files can be viewed in your browser at the following urls. Note, you must replace YOUR_PUBLIC_IPv4_ADDRESS with your own amazon instance IP (e.g., 101.0.1.101)). http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/de/ballgown/ref_only/Tutorial_Part2_ballgown_output.pdf First you’ll need to load the libraries needed for this analysis and define a path for the output PDF to be written. #load libraries library(ballgown) library(genefilter) library(dplyr) library(devtools) # set the working directory setwd(&quot;~/workspace/rnaseq/de/ballgown/ref_only&quot;) Next we’ll load our data into R. # Define the conditions being compared for use later condition = c(&quot;UHR&quot;, &quot;UHR&quot;, &quot;UHR&quot;, &quot;HBR&quot;, &quot;HBR&quot;, &quot;HBR&quot;) # Load the ballgown object from file load(&quot;bg.rda&quot;) # The load command, loads an R object from a file into memory in our R session. # You can use ls() to view the names of variables that have been loaded ls() # Print a summary of the ballgown object bg # Load gene names for lookup later in the tutorial bg_table = texpr(bg, &quot;all&quot;) bg_gene_names = unique(bg_table[, 9:10]) # Pull the gene and transcript expression data frame from the ballgown object gene_expression = as.data.frame(gexpr(bg)) transcript_expression = as.data.frame(texpr(bg)) #View expression values for the transcripts of a particular gene symbol of chromosome 22. e.g. &#39;TST&#39; #First determine the transcript_ids in the data.frame that match &#39;TST&#39;, aka. ENSG00000128311, then display only those rows of the data.frame i = bg_table[, &quot;gene_name&quot;] == &quot;TST&quot; bg_table[i,] # Display the transcript ID for a single row of data ballgown::transcriptNames(bg)[2763] # Display the gene name for a single row of data ballgown::geneNames(bg)[2763] #What if we want to view values for a list of genes of interest all at once? genes_of_interest = c(&quot;TST&quot;, &quot;MMP11&quot;, &quot;LGALS2&quot;, &quot;ISX&quot;) i = bg_table[, &quot;gene_name&quot;] %in% genes_of_interest bg_table[i,] # Load the transcript to gene index from the ballgown object transcript_gene_table = indexes(bg)$t2g head(transcript_gene_table) #Each row of data represents a transcript. Many of these transcripts represent the same gene. Determine the numbers of transcripts and unique genes length(unique(transcript_gene_table[, &quot;t_id&quot;])) #Transcript count length(unique(transcript_gene_table[, &quot;g_id&quot;])) #Unique Gene count # Extract FPKM values from the &#39;bg&#39; object fpkm = texpr(bg, meas = &quot;FPKM&quot;) # View the last several rows of the FPKM table tail(fpkm) # Transform the FPKM values by adding 1 and convert to a log2 scale fpkm = log2(fpkm + 1) # View the last several rows of the transformed FPKM table tail(fpkm) Now we’ll start to generate figures with the following R code. #### Plot #1 - the number of transcripts per gene. #Many genes will have only 1 transcript, some genes will have several transcripts #Use the &#39;table()&#39; command to count the number of times each gene symbol occurs (i.e. the # of transcripts that have each gene symbol) #Then use the &#39;hist&#39; command to create a histogram of these counts #How many genes have 1 transcript? More than one transcript? What is the maximum number of transcripts for a single gene? pdf(file=&quot;TranscriptCountDistribution.pdf&quot;) counts=table(transcript_gene_table[, &quot;g_id&quot;]) c_one = length(which(counts == 1)) c_more_than_one = length(which(counts &gt; 1)) c_max = max(counts) hist(counts, breaks = 50, col = &quot;bisque4&quot;, xlab = &quot;Transcripts per gene&quot;, main = &quot;Distribution of transcript count per gene&quot;) legend_text = c(paste(&quot;Genes with one transcript =&quot;, c_one), paste(&quot;Genes with more than one transcript =&quot;, c_more_than_one), paste(&quot;Max transcripts for single gene = &quot;, c_max)) legend(&quot;topright&quot;, legend_text, lty = NULL) dev.off() #### Plot #2 - the distribution of transcript sizes as a histogram #In this analysis we supplied StringTie with transcript models so the lengths will be those of known transcripts #However, if we had used a de novo transcript discovery mode, this step would give us some idea of how well transcripts were being assembled #If we had a low coverage library, or other problems, we might get short &quot;transcripts&quot; that are actually only pieces of real transcripts pdf(file = &quot;TranscriptLengthDistribution.pdf&quot;) hist(bg_table$length, breaks = 50, xlab = &quot;Transcript length (bp)&quot;, main = &quot;Distribution of transcript lengths&quot;, col = &quot;steelblue&quot;) dev.off() #### Plot #3 - distribution of gene expression levels for each sample # Create boxplots to display summary statistics for the FPKM values for each sample # set color based on condition which is UHR vs. HBR # set labels perpendicular to axis (las=2) # set ylab to indicate that values are log2 transformed pdf(file = &quot;All_samples_FPKM_boxplots.pdf&quot;) boxplot(fpkm, col = as.numeric(as.factor(condition)) + 1,las = 2,ylab = &quot;log2(FPKM + 1)&quot;) dev.off() #### Plot 4 - BoxPlot comparing the expression of a single gene for all replicates of both conditions # set border color for each of the boxplots # set title (main) to gene : transcript # set x label to Type # set ylab to indicate that values are log2 transformed pdf(file = &quot;TST_ENST00000249042_boxplot.pdf&quot;) transcript = which(ballgown::transcriptNames(bg) == &quot;ENST00000249042&quot;)[[1]] boxplot(fpkm[transcript,] ~ condition, border = c(2, 3), main = paste(ballgown::geneNames(bg)[transcript],&quot;: &quot;, ballgown::transcriptNames(bg)[transcript]), pch = 19, xlab = &quot;Type&quot;, ylab = &quot;log2(FPKM+1)&quot;) # Add the FPKM values for each sample onto the plot # set plot symbol to solid circle, default is empty circle points(fpkm[transcript,] ~ jitter(c(2,2,2,1,1,1)), col = c(2,2,2,1,1,1)+1, pch = 16) dev.off() #### Plot 5 - Plot of transcript structures observed and expression level for UHR vs HBR with representative replicate pdf(file = &quot;TST_transcript_structures_expression.pdf&quot;) par(mfrow = c(2, 1)) plotTranscripts(ballgown::geneIDs(bg)[transcript], bg, main = c(&quot;TST in HBR&quot;), sample = c(&quot;HBR_Rep1&quot;), labelTranscripts = TRUE) plotTranscripts(ballgown::geneIDs(bg)[transcript], bg, main = c(&quot;TST in UHR&quot;), sample = c(&quot;UHR_Rep1&quot;), labelTranscripts = TRUE) dev.off() # Exit the R session quit(save = &quot;no&quot;) Remember that you can view the output graphs of this step on your instance by navigating to this location in a web browser window: http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/de/ballgown/ref_only/Tutorial_Part2_ballgown_output.pdf Differential Expression Visualization In this section we will be going over some basic visualizations of the DESeq2 results generated in the “Differential Expression with DESeq2” section of this course. Our goal is to quickly obtain some interpretable results using built-in visualization functions from DESeq2 or recommended packages. For a very extensive overview of DESeq2 and how to visualize and interpret the results, refer to the DESeq2 vignette. Setup Navigate to the correct directory and then launch R: cd $RNA_HOME/de/deseq2 R If it is not already in your R environment, load the DESeqDataSet object and the results table into the R environment. # set the working directory setwd(&quot;/home/ubuntu/workspace/rnaseq/de/deseq2&quot;) # view the contents of this directory dir() # load libs library(DESeq2) library(data.table) library(pheatmap) # Load in the DESeqDataSet object (http://genomedata.org/cri-workshop/deseq2/dds.rds) dds = readRDS(&quot;dds.rds&quot;) # Load in the results object before shrinkage (http://genomedata.org/cri-workshop/deseq2/res.rds) res = readRDS(&quot;res.rds&quot;) # Load in the results object after shrinkage (http://genomedata.org/cri-workshop/deseq2/resLFC.rds) resLFC = readRDS(&quot;resLFC.rds&quot;) # Load in the final results file with all sorted DE results (http://genomedata.org/cri-workshop/deseq2/DE_all_genes_DESeq2.tsv) deGeneResultSorted = fread(&quot;DE_all_genes_DESeq2.tsv&quot;) MA-plot before LFC shrinkage MA-plots were originally used to evaluate microarray expression data where M is the log ratio and A is the mean intensity for a gene (both based on scanned intensity measurements from the microarray). These types of plots are still usefull in RNAseq DE experiments with two conditions, as they can immediately give us information on the number of signficantly differentially expressed genes, the ratio of up vs down regulated genes, and any outliers. To interpret these plots it is important to keep a couple of things in mind. The Y axis (M) is the log2 fold change between the two conditions tested, a higher fold-change indicates greater difference between condition A and condition B. The X axis (A) is a measure of read alignment to a gene, so as you go higher on on the X axis you are looking at regions which have higher totals of aligned reads, in other words the gene is “more” expressed overall (with the caveat that gene length is not being taken into account by raw read counts here). Using the built-in plotMA function from DESeq2 we also see that the genes are color coded by a significance threshold (e.g., adjusted p-value &lt; 0.1). Genes with higher expression values and higher fold-changes are more often significant as one would expect. }) # use DESeq2 built in MA-plot function pdf(&quot;maplot_preShrink.pdf&quot;) plotMA(res, alpha = 0.1, ylim=c(-2, 2), cex=1.5, main = &quot;MA-plot before LFC shrinkage&quot;) dev.off() MA-plot after LFC shrinkage When we ran DESeq2 we obtained two results, one with and one without log-fold change shrinkage. When you have genes with low hits you can get some very large fold changes. For example 1 hit on a gene vs 6 hits on a gene is a 6x fold change. This high level of variance though is probably quantifying noise instead of real biology. Running plotMA on our results where we applied an algorithm for log fold change shrinkage we can see that this “effect” is somewhat controlled for. I do want to note that while shrinking LFC is part of a typical DE workflow there are cases where you would not want to perform this, namely when there is already low variation amongst samples (i.e. from technical replicates) as most shrinkage algorithms rely on some variability to build a prior distribution. # ma plot pdf(&quot;maplot_postShrink.pdf&quot;) plotMA(resLFC, alpha = 0.1, ylim = c(-2, 2), cex=1.5, main = &quot;MA-plot after LFC shrinkage&quot;) dev.off() The effect is very subtle here due to the focused nature of our dataset (chr22 genes only), but if you toggle between the two plots and look in the upper left and bottom left corners you can see some fold change values are moving closer to 0. Viewing individual gene counts between two conditions Often it may be useful to view the normalized counts for a gene amongst our samples. DESeq2 provides a built in function for that which works off of the dds object. Here we view SEPT3 which we can see in our DE output is significantly higher in the HBR cohort and PRAME which is significantly higher in the UHR cohort. This is useful as we can see the per-sample distribution of our corrected counts, we can immediately determine if there are any outliers within each group and investigate further if need be. # hint! you defined intgroup when creating the dds object, you can view the name by printing the dds objct in your R session # dds pdf(&quot;normalized_count_examples.pdf&quot;) # view SEPT3 normalized counts plotCounts(dds, gene = &quot;ENSG00000100167&quot;, intgroup = &quot;Condition&quot;, main = &quot;SEPT3&quot;) # view PRAME normalized counts plotCounts(dds, gene = &quot;ENSG00000185686&quot;, intgroup = &quot;Condition&quot;, main = &quot;PRAME&quot;) dev.off() Viewing pairwise sample clustering It may often be useful to view inter-sample relatedness. In other words, how similar or disimilar samples are to one another overall. While not part of the DESeq2 package, there is a convenient library that can easily construct a hierarchically clustered heatmap from our DESeq2 data. It should be noted that when doing a distance calculation using “raw count” data is not ideal, the count data should be transformed using vst() or rlog() which can be performed directly on the dds object. The reason for this is described in detail in the DESeq2 manuscript, suffice it to say that transforming gene variance to be more homoskedastic will make inferences of sample relatedness more interpretable. # note that we use rlog because we don&#39;t have a large number of genes, for a typical DE experiment with 1000&#39;s of genes use the vst() function rld &lt;- rlog(dds, blind = FALSE) # view the structure of this object rld # compute sample distances (the dist function uses the euclidean distance metric by default) # in this command we will pull the rlog transformed data (&quot;regularized&quot; log2 transformed, see ?rlog for details) using &quot;assay&quot; # then we transpose that data using t() # then we calculate distance values using dist() # the distance is calculated for each vector of sample gene values, in a pairwise fashion comparing all samples # view the first few lines of raw data head(assay(dds)) # see the rlog transformed data head(assay(rld)) # see the impact of transposing the matrix t(assay(rld))[1:6, 1:5] # see the distance values dist(t(assay(rld))) # put it all together and store the result sampleDists &lt;- dist(t(assay(rld))) # convert the distance result to a matrix sampleDistMatrix &lt;- as.matrix(sampleDists) # view the distance numbers directly in the pairwise distance matrix head(sampleDistMatrix) pdf(&quot;distance_sample_heatmap.pdf&quot;, width = 8, height = 8) # construct clustered heatmap, important to use the computed sample distances for clustering pheatmap(sampleDistMatrix, clustering_distance_rows = sampleDists, clustering_distance_cols = sampleDists) dev.off() Instead of a distance metric we could also use a similarity metric such as a Peason correlation There are many correlation and distance options: Correlation: “pearson”, “kendall”, “spearman” Distance: “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski” sampleCorrs = cor(assay(rld), method = &quot;pearson&quot;) sampleCorrMatrix = as.matrix(sampleCorrs) head(sampleCorrMatrix) pdf(&quot;similarity_sample_heatmap.pdf&quot;, width = 8, height = 8) pheatmap(sampleCorrMatrix) dev.off() Instead of boiling all the gene count data for each sample down to a distance metric you can get a similar sense of the pattern by just visualizing all the genes at once pdf(&quot;all_gene_heatmap.pdf&quot;, width = 10, height = 10) # because there are so many gene we choose not to display them pheatmap(mat = t(assay(rld)), show_colnames = FALSE) dev.off() quit(save=&quot;no&quot;) Supplementary R DE Visualization Occasionally you may wish to reformat and work with expression estimates in R in an ad hoc way. Here, we provide an optional/advanced tutorial on how to visualize your results for R and perform “old school” (non-ballgown, non-DESeq2) visualization of your data. In this tutorial you will: Learn basic R usage and commands (common plots, and data manipulation tasks) Examine the expression estimates Create an MDS plot to visualize the differences between/among replicates, library prep methods and UHR versus HBR Examine the differential expression estimates Visualize the expression estimates and highlight those genes that appear to be differentially expressed Ask how reproducible technical replicates are. Expression and differential expression files will be read into R. The R analysis will make use of the gene-level expression estimates from HISAT2/Stringtie (TPM values) and differential expression results from HISAT2/htseq-count/DESeq2 (fold-changes and p-values). Start RStudio, or launch a posit Cloud session, or if you are using AWS, navigate to the correct directory and then launch R: mkdir $RNA_HOME/de/visualization_advanced cd $RNA_HOME/de/visualization_advanced R First you’ll load your libraries and your data. #Load your libraries library(ggplot2) library(gplots) library(GenomicRanges) library(ggrepel) #Set a base working directory setwd(&quot;/home/ubuntu/workspace/rnaseq/de/visualization_advanced/&quot;) #Import expression results (TPM values) from the HISAT2/Stringtie pipeline (https://genomedata.org/cri-workshop/gene_tpm_all_samples.tsv) gene_expression = read.table(&quot;~/workspace/rnaseq/expression/stringtie/ref_only/gene_tpm_all_samples.tsv&quot;, header = TRUE, stringsAsFactors = FALSE, row.names = 1) #gene_expression = read.table(&quot;data/bulk_rna/gene_tpm_all_samples.tsv&quot;, header = TRUE, stringsAsFactors = FALSE, row.names = 1) #Import gene name mapping file (https://genomedata.org/cri-workshop/ENSG_ID2Name.txt) gene_names=read.table(&quot;~/workspace/rnaseq/de/htseq_counts/ENSG_ID2Name.txt&quot;, header = TRUE, stringsAsFactors = FALSE) #gene_names=read.table(&quot;data/bulk_rna/ENSG_ID2Name.txt&quot;, header = TRUE, stringsAsFactors = FALSE) colnames(gene_names) = c(&quot;gene_id&quot;, &quot;gene_name&quot;) #Import DE results from the HISAT2/htseq-count/DESeq2 pipeline (http://genomedata.org/cri-workshop/deseq2/DE_all_genes_DESeq2.tsv) results_genes = read.table(&quot;~/workspace/rnaseq/de/deseq2/DE_all_genes_DESeq2.tsv&quot;, sep = &quot;\\t&quot;, header = TRUE, stringsAsFactors = FALSE) #results_genes = read.table(&quot;outdir/DE_all_genes_DESeq2.tsv&quot;, sep = &quot;\\t&quot;, header = TRUE, stringsAsFactors = FALSE) #Set a directory for the output to go to # output_dir = &quot;/cloud/project/outdir/visualization_advanced/&quot; # if (!dir.exists(output_dir)) { # dir.create(output_dir, recursive = TRUE) # } # setwd(output_dir) Let’s briefly explore the imported data #### Working with &#39;dataframes&#39; #View the first five rows of data (all columns) in the gene_expression (Stringtie TPM) dataframe head(gene_expression) #View the column names colnames(gene_expression) #View the row names row.names(gene_expression) #Determine the dimensions of the dataframe. &#39;dim()&#39; will return the number of rows and columns dim(gene_expression) #Get the first 3 rows of data and a selection of columns gene_expression[1:3, c(1:3, 6)] #Do the same thing, but using the column names instead of numbers gene_expression[1:3, c(&quot;HBR_Rep1&quot;, &quot;HBR_Rep2&quot;, &quot;HBR_Rep3&quot;, &quot;UHR_Rep3&quot;)] #Now, exlore the differential expression (DESeq2 results) head(results_genes) dim(results_genes) #Assign some colors for use later. You can specify color by RGB, Hex code, or name #To get a list of color names: colours() data_colors = c(&quot;tomato1&quot;, &quot;tomato2&quot;, &quot;tomato3&quot;, &quot;royalblue1&quot;, &quot;royalblue2&quot;, &quot;royalblue3&quot;) The following code blocks are to generate various plots using the above data set. #### Plot #1 - View the range of values and general distribution of TPM values for all 6 libraries #Create boxplots for this purpose #Display on a log2 scale and set a minimum non-zero value to avoid log2(0) min_nonzero = 1 # Set the columns for finding TPM and create shorter names for figures data_columns = c(1:6) short_names = c(&quot;HBR_1&quot;, &quot;HBR_2&quot;, &quot;HBR_3&quot;, &quot;UHR_1&quot;, &quot;UHR_2&quot;, &quot;UHR_3&quot;) pdf(file = &quot;All_samples_TPM_boxplots.pdf&quot;) boxplot(log2(gene_expression[, data_columns] + min_nonzero), col = data_colors, names = short_names, las = 2, ylab = &quot;log2(TPM)&quot;, main = &quot;Distribution of TPMs for all 6 libraries&quot;) #Note that the bold horizontal line on each boxplot is the median dev.off() #### Plot #2 - plot a pair of replicates to assess reproducibility of technical replicates #Tranform the data by converting to log2 scale after adding an arbitrary small value to avoid log2(0) x = gene_expression[, &quot;UHR_Rep1&quot;] y = gene_expression[, &quot;UHR_Rep2&quot;] pdf(file = &quot;UHR_Rep1_vs_Rep2_scatter.pdf&quot;) plot(x = log2(x + min_nonzero), y = log2(y + min_nonzero), pch = 16, col = &quot;blue&quot;, cex = 0.25, xlab = &quot;TPM (UHR, Replicate 1)&quot;, ylab = &quot;TPM (UHR, Replicate 2)&quot;, main = &quot;Comparison of expression values for a pair of replicates&quot;) #Add a straight line of slope 1, and intercept 0 abline(a = 0, b = 1) #Calculate the correlation coefficient and display in a legend rs = cor(x, y)^2 legend(&quot;topleft&quot;, paste(&quot;R squared = &quot;, round(rs, digits = 3), sep = &quot;&quot;), lwd = 1, col = &quot;black&quot;) dev.off() #### Plot #3 - Scatter plots with a large number of data points can be misleading ... regenerate this figure as a density scatter plot pdf(file = &quot;UHR_Rep1_vs_Rep2_SmoothScatter.pdf&quot;) colors = colorRampPalette(c(&quot;white&quot;, &quot;blue&quot;, &quot;#007FFF&quot;, &quot;cyan&quot;,&quot;#7FFF7F&quot;, &quot;yellow&quot;, &quot;#FF7F00&quot;, &quot;red&quot;, &quot;#7F0000&quot;)) smoothScatter(x = log2(x + min_nonzero), y = log2(y + min_nonzero), xlab = &quot;TPM (UHR, Replicate 1)&quot;, ylab = &quot;TPM (UHR, Replicate 2)&quot;, main = &quot;Comparison of expression values for a pair of replicates&quot;, colramp = colors, nbin = 200) dev.off() #### Plot #4 - Scatter plots of all sets of replicates on a single plot #Create a function that generates an R plot. This function will take as input the two libraries to be compared and a plot name plotCor = function(lib1, lib2, name){ x = gene_expression[, lib1] y = gene_expression[, lib2] colors = colorRampPalette(c(&quot;white&quot;, &quot;blue&quot;, &quot;#007FFF&quot;, &quot;cyan&quot;, &quot;#7FFF7F&quot;, &quot;yellow&quot;, &quot;#FF7F00&quot;, &quot;red&quot;, &quot;#7F0000&quot;)) smoothScatter(x = log2(x + min_nonzero), y = log2(y + min_nonzero), xlab = lib1, ylab = lib2, main = name, colramp = colors, nbin = 275) abline(a = 0, b = 1) zero_count = length(which(x == 0)) + length(which(y == 0)) rs = cor(x, y, method = &quot;pearson&quot;)^2 legend_text = c(paste(&quot;R squared = &quot;, round(rs, digits = 3), sep=&quot;&quot;), paste(&quot;Zero count = &quot;, zero_count, sep = &quot;&quot;)) legend(&quot;topleft&quot;, legend_text, lwd = c(1, NA), col = &quot;black&quot;, bg = &quot;white&quot;, cex = 0.8) } #Now make a call to our custom function created above, once for each library comparison pdf(file = &quot;UHR_All_Reps_SmoothScatter.pdf&quot;) par(mfrow = c(1, 3)) plotCor(&quot;UHR_Rep1&quot;, &quot;UHR_Rep2&quot;, &quot;UHR_1 vs UHR_2&quot;) plotCor(&quot;UHR_Rep2&quot;, &quot;UHR_Rep3&quot;, &quot;UHR_2 vs UHR_3&quot;) plotCor(&quot;UHR_Rep1&quot;, &quot;UHR_Rep3&quot;, &quot;UHR_1 vs UHR_3&quot;) #### Compare the correlation between all replicates #Do we see the expected pattern for all eight libraries (i.e. replicates most similar, then tumor vs. normal)? #Calculate the TPM sum for all 6 libraries gene_expression[,&quot;sum&quot;] = apply(gene_expression[,data_columns], 1, sum) #Identify the genes with a grand sum TPM of at least 5 - we will filter out the genes with very low expression across the board i = which(gene_expression[,&quot;sum&quot;] &gt; 5) #Calculate the correlation between all pairs of data r = cor(gene_expression[i,data_columns], use = &quot;pairwise.complete.obs&quot;, method = &quot;pearson&quot;) #Print out these correlation values r dev.off() #### Plot #5 - Convert correlation to &#39;distance&#39;, and use &#39;multi-dimensional scaling&#39; to display the relative differences between libraries #This step calculates 2-dimensional coordinates to plot points for each library #Libraries with similar expression patterns (highly correlated to each other) should group together #What pattern do we expect to see, given the types of libraries we have (technical replicates, biologal replicates, tumor/normal)? pdf(file = &quot;UHR_vs_HBR_MDS.pdf&quot;) d = 1 - r mds = cmdscale(d, k = 2, eig = TRUE) par(mfrow = c(1,1)) plot(mds$points, type = &quot;n&quot;, xlab = &quot;&quot;, ylab = &quot;&quot;, main = &quot;MDS distance plot (all non-zero genes)&quot;, xlim = c(-0.12, 0.12), ylim = c(-0.12, 0.12)) points(mds$points[, 1], mds$points[, 2], col = &quot;grey&quot;, cex = 2, pch = 16) text(mds$points[, 1], mds$points[, 2], short_names, col = data_colors) dev.off() #### Plot #6 - View the distribution of differential expression values as a histogram #Display only those results that are significant according to DESeq2 (loaded above) pdf(file = &quot;UHR_vs_HBR_DE_FC_distribution.pdf&quot;) sig = which(results_genes$pvalue &lt; 0.05) hist(results_genes[sig, &quot;log2FoldChange&quot;], breaks = 50, col = &quot;seagreen&quot;, xlab = &quot;log2(Fold change) UHR vs HBR&quot;, main = &quot;Distribution of differential expression values&quot;) abline(v = -2, col = &quot;black&quot;, lwd = 2, lty = 2) abline(v = 2, col = &quot;black&quot;, lwd = 2, lty = 2) legend(&quot;topleft&quot;, &quot;Fold-change &gt; 2&quot;, lwd = 2, lty = 2) dev.off() #### Plot #7 - Display the mean expression values from UHR and HBR and mark those that are significantly differentially expressed pdf(file=&quot;UHR_vs_HBR_mean_TPM_scatter.pdf&quot;) gene_expression[, &quot;HBR_mean&quot;] = apply(gene_expression[,c(1:3)], 1, mean) gene_expression[, &quot;UHR_mean&quot;] = apply(gene_expression[,c(4:6)], 1, mean) x = log2(gene_expression[, &quot;UHR_mean&quot;] + min_nonzero) y = log2(gene_expression[, &quot;HBR_mean&quot;] + min_nonzero) plot(x = x, y = y, pch = 16, cex = 0.25, xlab = &quot;UHR TPM (log2)&quot;, ylab = &quot;HBR TPM (log2)&quot;, main = &quot;UHR vs HBR TPMs&quot;) abline(a = 0, b = 1) xsig = x[sig] ysig = y[sig] points(x = xsig, y = ysig, col = &quot;magenta&quot;, pch = 16, cex = 0.5) legend(&quot;topleft&quot;, &quot;Significant&quot;, col = &quot;magenta&quot;, pch = 16) #Get the gene symbols for the top N (according to corrected p-value) and display them on the plot topn = order(results_genes[sig,&quot;padj&quot;])[1:25] text(x[topn], y[topn], results_genes[topn, &quot;Symbol&quot;], col = &quot;black&quot;, cex = 0.75, srt = 45) dev.off() #### Plot #8 - Create a heatmap to vizualize expression differences between the six samples #Define custom dist and hclust functions for use with heatmaps mydist = function(c) {dist(c, method = &quot;euclidian&quot;)} myclust = function(c) {hclust(c, method = &quot;average&quot;)} #Create a subset of significant genes with p-value&lt;0.05 and log2 fold-change &gt;= 2 sigpi = which(results_genes[, &quot;pvalue&quot;] &lt; 0.05) sigp = results_genes[sigpi, ] sigfc = which(abs(sigp[, &quot;log2FoldChange&quot;]) &gt;= 2) sigDE = sigp[sigfc, ] pdf(file = &quot;UHR_vs_HBR_heatmap.pdf&quot;) main_title = &quot;sig DE Genes&quot; par(cex.main = 0.8) sigDE_genes = sigDE[, &quot;ensemblID&quot;] sigDE_genenames = sigDE[, &quot;Symbol&quot;] data = log2(as.matrix(gene_expression[as.vector(sigDE_genes), data_columns]) + 1) heatmap.2(data, hclustfun = myclust, distfun = mydist, na.rm = TRUE, scale = &quot;none&quot;, dendrogram = &quot;both&quot;, margins = c(10,4), Rowv = TRUE, Colv = TRUE, symbreaks = FALSE, key = TRUE, symkey = FALSE, density.info = &quot;none&quot;, trace = &quot;none&quot;, main = main_title, cexRow = 0.3, cexCol = 1, labRow = sigDE_genenames, col = rev(heat.colors(75))) dev.off() #### Plot #9 - Volcano plot # Set differential expression status for each gene - default all genes to &quot;no change&quot; results_genes$diffexpressed = &quot;No&quot; # if log2Foldchange &gt; 2 and pvalue &lt; 0.05, set as &quot;Up regulated&quot; results_genes$diffexpressed[results_genes$log2FoldChange &gt;= 2 &amp; results_genes$pvalue &lt; 0.05] = &quot;Higher in UHR&quot; # if log2Foldchange &lt; -2 and pvalue &lt; 0.05, set as &quot;Down regulated&quot; results_genes$diffexpressed[results_genes$log2FoldChange &lt;= -2 &amp; results_genes$pvalue &lt; 0.05] = &quot;Higher in HBR&quot; # write the gene names of those significantly upregulated/downregulated to a new column results_genes$gene_label = NA results_genes$gene_label[results_genes$diffexpressed != &quot;No&quot;] = results_genes$Symbol[results_genes$diffexpressed != &quot;No&quot;] pdf(file = &quot;UHR_vs_HBR_volcano.pdf&quot;) ggplot(data = results_genes[results_genes$diffexpressed != &quot;No&quot;,], aes(x = log2FoldChange, y = -log10(pvalue), label = gene_label, color = diffexpressed)) + xlab(&quot;log2Foldchange&quot;) + scale_color_manual(name = &quot;Differentially expressed&quot;, values=c(&quot;blue&quot;, &quot;red&quot;)) + geom_point() + theme_minimal() + geom_text_repel() + geom_vline(xintercept = c(-0.6, 0.6), col = &quot;red&quot;) + geom_hline(yintercept = -log10(0.05), col = &quot;red&quot;) + guides(colour = guide_legend(override.aes = list(size=5))) + geom_point(data = results_genes[results_genes$diffexpressed == &quot;No&quot;,], aes(x = log2FoldChange, y = -log10(pvalue)), colour = &quot;black&quot;) dev.off() #To exit R type: quit(save = &quot;no&quot;) The output file can be viewed in your browser at the following url. Note, you must replace YOUR_PUBLIC_IPv4_ADDRESS with your own amazon instance IP (e.g., 101.0.1.101)). http://YOUR_PUBLIC_IPv4_ADDRESS/rnaseq/de/ballgown/ref_only/Tutorial_Part3_Supplementary_R_output.pdf Visual comparison of example genes from the volcano plot One can manually explore interesting looking genes from the volcano plot. In this case our analysis involves comparison of RNA isolated from tissues of different types (HBR -&gt; brain tissue, UHR -&gt; a collection of cancer cell lines). So, in this analysis it might make sense to explore candidates in a tissue expression atlas such as GTEX. Looking at our gene plot, two example genes we could look at are: SEPT3 (significantly higher in HBR) and PRAME (significantly higher in UHR). Expression of SEPT3 across tissues according to GTEX Note that this gene appears to be highly expressed in brain tissues. Expression of PRAME across tissues according to GTEX Note that this gene appears to be almost uniquely expressed in testis tissue. Since one of the cell lines in the UHR sample is a testicular cancer cell line, this makes sense. PRACTICAL EXERCISE 10 (ADVANCED) Assignment: Use R to create a volcano plot for the differentially expressed genes you identified with Ballgown in Practical Exercise 9. Hint: Follow the example R code above. Hint: You could import the ballgown data object (e.g., bg.rda) that you should have saved in Practical Exercise 9 as a source of DE results. Solution: When you are ready you can check your approach against the Solutions In this section we will use the GAGE tool in R to test for significantly enriched sets of genes within those genes found to be significantly “up” and “down” in our UHR vs HBR differential gene expression analysis. Do we see enrichment for genes associated with brain related cell types and processes in the list of DE genes that have significant differential expression beween the UHR samples compared to the HBR samples? What is gage? The Generally Applicable Gene-set Enrichment tool (GAGE) is a popular bioconductor package used to perform gene-set enrichment and pathway analysis. The package works independent of sample sizes, experimental designs, assay platforms, and is applicable to both microarray and RNAseq data sets. In this section we will use GAGE and gene sets from the “Gene Ontology” (GO) and the MSigDB databases to perform pathway analysis. Now, we will start a docker session to run the analysis in this section docker run -it -v /home/ubuntu/workspace:/workspace cnithin7/bioc-custom:1.0 /bin/bash Launch R at the commandline, start RStudio, or launch a posit Cloud session: R Importing DE results for gage Before we perform the pathway analysis we need to read in our differential expression results from the previous DE analysis. # Define working dir paths and load in data datadir = &quot;/workspace/rnaseq/de/deseq2&quot; #datadir = &quot;/cloud/project/outdir/&quot; setwd(datadir) # Load in the DE results file with only significant genes (e.g., http://genomedata.org/cri-workshop/deseq2/DE_sig_genes_DESeq2.tsv) DE_genes = read.table(&quot;DE_sig_genes_DESeq2.tsv&quot;, sep = &quot;\\t&quot;, header = TRUE, stringsAsFactors = FALSE) output_dir = &quot;/workspace/rnaseq/de/deseq2/pathway/&quot; #output_dir = &quot;/cloud/project/outdir/pathway/&quot; if (!dir.exists(output_dir)) { dir.create(output_dir, recursive = TRUE) } setwd(output_dir) Now let’s go ahead and load GAGE and some other useful packages. library(AnnotationDbi) library(org.Hs.eg.db) library(GO.db) library(gage) Setting up gene set databases In order to perform our pathway analysis we need a list of pathways and their respective genes. There are many databases that contain collections of genes (or gene sets) that can be used to understand whether a set of mutated or differentially expressed genes are functionally related. Some of these resources include: GO, KEGG, MSigDB, and WikiPathways. For this exercise we are going to investigate GO and MSigDB. The GAGE package has a function for querying GO in real time: go.gsets(). This function takes a species as an argument and will return a list of gene sets and some helpful meta information for subsetting these lists. If you are unfamiliar with GO, it is helpful to know that GO terms are categorized into three gene ontologies: “Biological Process”, “Molecular Function”, and “Cellular Component”. This information will come in handy later in our exercise. GAGE does not provide a similar tool to investigate the gene sets available in MSigDB. Fortunately, MSigDB provides a download-able .gmt file for all gene sets. This format is easily read into GAGE using a function called readList(). If you check out MSigDB you will see that there are 8 unique gene set collections, each with slightly different features. For this exercise we will use the C8 - cell type signature gene sets collection, which is a collection of gene sets that contain cluster markers for cell types identified from single-cell sequencing studies of human tissue. # Set up go database go.hs = go.gsets(species = &quot;human&quot;) go.bp.gs = go.hs$go.sets[go.hs$go.subs$BP] go.mf.gs = go.hs$go.sets[go.hs$go.subs$MF] go.cc.gs = go.hs$go.sets[go.hs$go.subs$CC] # Here we will read in an MSigDB gene set that was selected for this exercise and saved to the course website. c8 = &quot;http://genomedata.org/rnaseq-tutorial/c8.all.v7.2.entrez.gmt&quot; all_cell_types = readList(c8) Annotating genes OK, so we have our differentially expressed genes and we have our gene sets. However, if you look at one of the objects containing the gene sets you’ll notice that each gene set contains a series of integers. These integers are Entrez gene identifiers. But do we have comparable information in our DE gene list? Right now, no. Our previous results use Ensembl IDs as gene identifiers. We will need to convert our gene identifiers to the format used in the GO and MSigDB gene sets before we can perform the pathway analysis. Fortunately, Bioconductor maintains genome wide annotation data for many species, you can view these species with the OrgDb bioc view. This makes converting the gene identifiers relatively straightforward, below we use the mapIds() function to query the OrganismDb object for the Entrez id based on the Ensembl id. Because there might not be a one-to-one relationship with these identifiers we also use multiVals=\"first\" to specify that only the first identifier should be returned. Another option would be to use multiVals=\"asNA\" to ignore one-to-many mappings. DE_genes$entrez = mapIds(org.Hs.eg.db, column = &quot;ENTREZID&quot;, keys = DE_genes$ensemblID, keytype = &quot;ENSEMBL&quot;, multiVals = &quot;first&quot;) Some clean-up and identifier mapping After completing the annotation above you will notice that some of our Ensembl gene IDs were not mapped to an Entrez gene ID. Why did this happen? Well, this is actually a complicated point and gets at some nuanced concepts of how to define and annotate a gene. The short answer is that we are using two different resources that have annotated the human genome and there are some differences in how these resources have completed this task. Therefore, it is expected that there are some discrepencies. In the next few steps we will clean up what we can by first removing the ERCC spike-in genes and then will use a different identifier for futher mapping. #Remove spike-in DE_genes_clean = DE_genes[!grepl(&quot;ERCC&quot;, DE_genes$ensemblID), ] ##Just so we know what we have removed ERCC_gene_count = nrow(DE_genes[grepl(&quot;ERCC&quot;, DE_genes$ensemblID), ]) ERCC_gene_count ###Deal with genes that we do not have an Entrez ID for missing_ensembl_key = DE_genes_clean[is.na(DE_genes_clean$entrez), ] DE_genes_clean = DE_genes_clean[!DE_genes_clean$ensemblID %in% missing_ensembl_key$ensemblID, ] ###Try mapping using a different key missing_ensembl_key$entrez = mapIds(org.Hs.eg.db, column = &quot;ENTREZID&quot;, keys = missing_ensembl_key$Symbol, keytype = &quot;SYMBOL&quot;, multiVal = &quot;first&quot;) #Remove remaining genes missing_ensembl_key_update = missing_ensembl_key[!is.na(missing_ensembl_key$entrez),] #Create a Final Gene list of all genes where we were able to find an Entrez ID (using two approaches) DE_genes_clean = rbind(DE_genes_clean, missing_ensembl_key_update) #Reduce to only the unique set of entrez genes in case different genes were mapped to the same entrez ID using the two approaches DE_genes_clean=DE_genes_clean[!duplicated(DE_genes_clean$entrez),] Final preparation of DESeq2 results for gage OK, last step. Let’s format the differential expression results into a format suitable for the GAGE package. Basically this means obtaining the log2 fold change values and assigning entrez gene identifiers to these values. # grab the log fold changes for everything De_gene.fc = DE_genes_clean$log2FoldChange # set the name for each row to be the Entrez Gene ID names(De_gene.fc) = DE_genes_clean$entrez Running pathway analysis We can now use the gage() function to obtain the significantly perturbed pathways from our differential expression experiment. Note on the abbreviations below: “bp” refers to biological process, “mf” refers to molecular function, and “cc” refers to cellular process. These are the three main categories of gene ontology terms/annotations that were mentioned above. #Run GAGE #go fc.go.bp.p = gage(De_gene.fc, gsets = go.bp.gs) fc.go.mf.p = gage(De_gene.fc, gsets = go.mf.gs) fc.go.cc.p = gage(De_gene.fc, gsets = go.cc.gs) #msigdb fc.c8.p = gage(De_gene.fc, gsets = all_cell_types) ###Convert to dataframes #Results for testing for GO terms which are up-regulated fc.go.bp.p.up = as.data.frame(fc.go.bp.p$greater) fc.go.mf.p.up = as.data.frame(fc.go.mf.p$greater) fc.go.cc.p.up = as.data.frame(fc.go.cc.p$greater) #Results for testing for GO terms which are down-regulated fc.go.bp.p.down = as.data.frame(fc.go.bp.p$less) fc.go.mf.p.down = as.data.frame(fc.go.mf.p$less) fc.go.cc.p.down = as.data.frame(fc.go.cc.p$less) #Results for testing for MSigDB C8 gene sets which are up-regulated fc.c8.p.up = as.data.frame(fc.c8.p$greater) #Results for testing for MSigDB C8 gene sets which are down-regulated fc.c8.p.down = as.data.frame(fc.c8.p$less) Explore significant results Alright, now we have results with accompanying p-values (yay!). What does “up-” or “down-regulated” mean here, in the context of our UHR vs HBR comparison? It may help to open and review the data in your DE_genes_DESeq2.tsv file. Look at the cellular process results from our GO analysis. Do the results match your expectation? #Try doing something like this to find some significant results: #View the top 20 significantly up- or down-regulated GO terms from the Cellular Component Ontology head(fc.go.cc.p.up[order(fc.go.cc.p.up$p.val),], n = 20) head(fc.go.cc.p.down[order(fc.go.cc.p.down$p.val),], n = 20) #You can do the same thing with your results from MSigDB head(fc.c8.p.up) head(fc.c8.p.down) #What if we want to know which specific genes from our DE gene result were found in a specific significant pathway? #For example, one significant pathway from fc.go.cc.p.down was &quot;GO:0045202 synapse&quot; with set.size = 22 genes. #Let&#39;s extract the postsynapse DE gene results synapse = DE_genes_clean[which(DE_genes_clean$entrez %in% go.cc.gs$`GO:0045202 synapse`),] #How many total synapse genes are there in GO? How many total DE genes? How many overlap? length(go.cc.gs$`GO:0045202 synapse`) length(DE_genes_clean$entrez) length(synapse$entrez) #Are the synapse DE genes consistently down-regulated? Let&#39;s print out a subset of columns from the DE result for synapse genes synapse[,c(&quot;Symbol&quot;, &quot;entrez&quot;, &quot;log2FoldChange&quot;, &quot;padj&quot;, &quot;UHR_Rep1&quot;, &quot;UHR_Rep2&quot;, &quot;UHR_Rep3&quot;, &quot;HBR_Rep1&quot;, &quot;HBR_Rep2&quot;, &quot;HBR_Rep3&quot;)] More exploration At this point, it will be helpful to move out of R and further explore our results locally. We will use an online tool to visualize how the GO terms we uncovered are related to each other. write.table(fc.go.cc.p.up, &quot;fc.go.cc.p.up.tsv&quot;, quote = FALSE, sep = &quot;\\t&quot;, col.names = TRUE, row.names = TRUE) write.table(fc.go.cc.p.down, &quot;fc.go.cc.p.down.tsv&quot;, quote = FALSE, sep = &quot;\\t&quot;, col.names = TRUE, row.names = TRUE) Visualize For this next step we will do a very brief introduction to visualizing our results. We will use a tool called GOView, which is part of the WEB-based Gene Set Ananlysis ToolKit (WebGestalt) suite of tools. Step One * Use a web browser to download your results For AWS: Navigate to the URL below replacing YOUR_IP_ADDRESS with your amazon instance IP address: http://YOUR_IP_ADDRESS/rnaseq/de/deseq2 Download the linked files by right clicking on the two saved result files: fc.go.cc.p.up.tsv and fc.go.cc.p.down.tsv. For posit Cloud: Navigate to the outdir folder in the ‘Files’ pane. Select fc.go.cc.p.up.tsv and fc.go.cc.p.down.tsv then ‘More’ -&gt; ‘Export…’. You may need to unzip the downloaded files. Open the result file in your text editor of choice. We like text wrangler. You should also be able to open the file in excel, google sheets, or another spreadsheet tool. This might help you visualize the data in rows and columns (NB: There might be a small amount of formatting necessary to get the header to line up properly). You can either create an input file using this file as a guide, or you can simply use your downloaded data to cut and paste your GO terms of interest directly into GOView. Step Two Navigate to the WEB-based Gene Set Analysis ToolKit (WebGestalt) Step Three Navigate to the GOView tool Then, input the GO terms you would like to explore into the GOView interface by following the steps described in the “Beginning an analysis” section of the webpage. We will walk through a sample analysis. Explore the outputs! Alternative Pathway analysis tools and strategies! At this point, to generate additional visualizations and gain more insight from our enrichment analysis, we can turn to two powerful functions in the clusterProfiler package: gseGO and enrichKEGG. These tools allow us to go beyond simply identifying enriched pathways and give us the ability to visualize and explore these pathways in a much more detailed way. First, to use gseGO and enrichKEGG effectively, we need a ranked list of DE genes based on their log2 fold change values. This ranked list allows us to analyze and visualize enrichment based on the degree of differential expression, rather than just a binary presence or absence in a pathway. # Create a named vector of log2 fold changes with Entrez IDs as names ranked_genes &lt;- setNames(DE_genes_clean$log2FoldChange, DE_genes_clean$entrez) # Sort the genes by log2 fold change ranked_genes &lt;- sort(ranked_genes, decreasing = TRUE) Using gseGO, we can analyze the ranked DE genes list to create classic GSEA enrichment plots. These plots help us see how gene expression levels are distributed across the pathways that were identified as significant in our initial analysis. By examining the ranking of gene expression within these pathways, we can get a clearer picture of how specific pathways are activated or suppressed in our data set. # Install a package missing from the template #if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) # install.packages(&quot;BiocManager&quot;, quiet = TRUE) #BiocManager::install(&quot;pathview&quot;, update = FALSE, ask = FALSE, quiet = TRUE) # Load relevant packages library(enrichplot) library(clusterProfiler) library(pathview) library(ggnewscale) library(ggplot2) gsea_res &lt;- gseGO( geneList = ranked_genes, # Ranked list of genes OrgDb = org.Hs.eg.db, # Specify organism database ont = &quot;CC&quot;, # Use &quot;BP&quot; for Biological Process, &quot;MF&quot; for Molecular Function, &quot;CC&quot; for Cellular Component keyType = &quot;ENTREZID&quot;, # Ensure your gene IDs match the key type in OrgDb pvalueCutoff = 0.05, # Set a p-value cutoff for significant pathways verbose = TRUE ) Generate the classic GSEA enrichment plot # Plot the enrichment plot for a specific GO term or pathway - Synapse gsea_plot &lt;- gseaplot2(gsea_res, geneSetID = &quot;GO:0045202&quot;, title = &quot;Enrichment Plot for Synapse&quot;) ggsave(&quot;gsea_go_synapse_plot.pdf&quot;, plot=gsea_plot, width = 8, height = 8) We can use additional visualizations, such as dot plots, ridge plots, and concept network plots, to gain further insights into the enriched pathways. # Dotplot for top GO pathways enriched with DE genes gsea_dot_plot &lt;- dotplot(gsea_res, showCategory = 30) + ggtitle(&quot;GSEA Dotplot - Top 30 GO Categories&quot;) ggsave(&quot;gsea_dot_plot.pdf&quot;, plot=gsea_dot_plot, width = 8, height = 8) #Ridgeplot for top GO pathways enriched with DE genes gsea_ridge_plot &lt;-ridgeplot(gsea_res) ggsave(&quot;gsea_ridge_plot.pdf&quot;, plot=gsea_ridge_plot, width = 8, height = 8) # Concept network plot to illustrate relationships between the top enriched GO terms and DE genes gsea_cnetplot &lt;- cnetplot(gsea_res, foldChange = ranked_genes, showCategory = 10) ggsave(&quot;gsea_cnetplot.pdf&quot;, plot=gsea_cnetplot, width = 8, height = 6) The enrichKEGG function can be used to visualize KEGG pathways, showing detailed diagrams with our DE genes highlighted. This approach is especially useful for understanding the biological roles of up- and down-regulated genes within specific metabolic or signaling pathways. By using the pathview package, we can generate pathway diagrams where each DE gene is displayed in its functional context and color-coded by expression level. This makes it easy to see which parts of a pathway are impacted and highlights any potential regulatory or metabolic shifts in a clear, intuitive format. We will start by downloading and installing the KEGG database and then run the enrichKEGG function. # Download KEGG DB file and install download.file(&#39;https://www.bioconductor.org/packages/3.11/data/annotation/src/contrib/KEGG.db_3.2.4.tar.gz&#39;, destfile=&#39;KEGG.db_3.2.4.tar.gz&#39;) install.packages(&quot;KEGG.db_3.2.4.tar.gz&quot;, repos = NULL, type = &quot;source&quot;) # Run enrichKEGG with local database option pathways &lt;- enrichKEGG(gene = names(ranked_genes), organism = &quot;hsa&quot;, keyType = &quot;kegg&quot;, use_internal_data=TRUE) head(pathways@result) Let’s choose one of the pathways above, for example hsa04010 - MAPK signaling pathway to visualize. # Define the KEGG pathway ID based on above, and run pathview (note this automatically generates and saves plots to your current directory) pathway_id &lt;- &quot;hsa04010&quot; # Replace with the KEGG pathway ID of interest pathview( gene.data = ranked_genes, # DE gene data with Entrez IDs pathway.id = pathway_id, # KEGG pathway ID species = &quot;hsa&quot;, # Species code for human limit = list(gene = c(-2, 2)), # Set color scale limits for log2 fold changes low = &quot;blue&quot;, # Color for down-regulated genes mid = &quot;white&quot;, # Color for neutral genes high = &quot;red&quot; # Color for up-regulated genes ) #To exit R type: quit(save = &quot;no&quot;) Leave the docker session exit In this section we will obtain a dataset to allow demonstration of batch correction using the ComBat-Seq tool in R (Bioconductor). Download and prepare some test data where some batch effects are expected For this exercise we will obtain public RNA-seq data from an extensive multi-platform comparison of sequencing platforms that also examined the impact of generating data at multiple sites, using polyA vs ribo-reduction for enrichment, and the impact of RNA degradation (PMID: 25150835): “Multi-platform and cross-methodological reproducibility of transcriptome profiling by RNA-seq in the ABRF Next-Generation Sequencing Study”. This publication used the same UHR (cancer cell lines) and HBR (brain tissue) samples we have been using throughout this course. To examine a strong batch effect, we will consider a DE analysis of UHR vs HBR where we compare Ribo-depleted (“Ribo”) and polyA-enriched (“Poly”) samples. The entire RNA-seq dataset PMID: 25150835 used for this module has been deposited in GEO. In GEO, these data are organized as a superseries: GSE46876 which has data for several sequencing platforms. The data from the Illumina Platform are part of this subseries: GSE48035. To do this analysis quickly, we will download pre-computed raw read counts for this dataset: GSE48035_ILMN.counts.txt.gz Set up a working directory and download the RNA-seq counts file needed for the following exercise as follows: cd $RNA_HOME mkdir batch_correction cd batch_correction wget http://genomedata.org/rnaseq-tutorial/batch_correction/GSE48035_ILMN.counts.txt.gz Create a simplified version of this file that has only the counts for the samples we wish to use for this analysis as follows: cd $RNA_HOME/batch_correction #remove all quotes from file zcat GSE48035_ILMN.counts.txt.gz | tr -d &#39;&quot;&#39; &gt; GSE48035_ILMN.counts.tmp.txt #create a fixed version of the header and store for later head -n 1 GSE48035_ILMN.counts.tmp.txt | perl -ne &#39;print &quot;Gene\\tChr\\t$_&quot;&#39; &gt; header.txt #split the chromosome and gene names on each line, sort the file by gene name perl -ne &#39;chomp; if ($_ =~ /^(chr\\w+)\\!(\\S+)(.*)/){print &quot;$2\\t$1$3\\n&quot;}else{print &quot;$_\\n&quot;}&#39; GSE48035_ILMN.counts.tmp.txt | sort &gt; GSE48035_ILMN.counts.tmp2.txt #remove the old header line grep -v --color=never ABRF GSE48035_ILMN.counts.tmp2.txt &gt; GSE48035_ILMN.counts.clean.txt #cut out only the columns for the UHR (A) and HBR (B) samples, replicates 1-4, and PolyA vs Enrichment cut -f 1-2,3-6,7-10,19-22,23-26 GSE48035_ILMN.counts.clean.txt &gt; GSE48035_ILMN.Counts.SampleSubset.txt cut -f 1-2,3-6,7-10,19-22,23-26 header.txt &gt; header.SampleSubset.txt #how many gene lines are we starting with? wc -l GSE48035_ILMN.Counts.SampleSubset.txt #cleanup intermediate files created above rm -f GSE48035_ILMN.counts.txt.gz GSE48035_ILMN.counts.tmp.txt GSE48035_ILMN.counts.tmp2.txt GSE48035_ILMN.counts.clean.txt header.txt Further limit these counts to those that correspond to known protein coding genes: cd $RNA_HOME/batch_correction #download complete Ensembl GTF file wget ftp://ftp.ensembl.org/pub/release-101/gtf/homo_sapiens/Homo_sapiens.GRCh38.101.gtf.gz #grab all the gene records, limit to gene with &quot;protein_coding&quot; biotype, create unique gene name list zcat Homo_sapiens.GRCh38.101.gtf.gz | grep -w gene | grep &quot;gene_biotype \\&quot;protein_coding\\&quot;&quot; | cut -f 9 | cut -d &quot;;&quot; -f 3 | tr -d &quot; gene_name &quot; | tr -d &#39;&quot;&#39; | sort | uniq &gt; Ensembl101_ProteinCodingGeneNames.txt #how many unique protein coding genes names does Ensembl have? wc -l Ensembl101_ProteinCodingGeneNames.txt #filter our gene count matrix down to only the protein coding genes join -j 1 -t $&#39;\\t&#39; Ensembl101_ProteinCodingGeneNames.txt GSE48035_ILMN.Counts.SampleSubset.txt | cat header.SampleSubset.txt - &gt; GSE48035_ILMN.Counts.SampleSubset.ProteinCodingGenes.tsv #how many lines of RNA-seq counts do we still have? wc -l GSE48035_ILMN.Counts.SampleSubset.ProteinCodingGenes.tsv #clean up rm -f header.SampleSubset.txt GSE48035_ILMN.Counts.SampleSubset.txt #take a look at the final filtered read count matrix to be used for the following analysis column -t GSE48035_ILMN.Counts.SampleSubset.ProteinCodingGenes.tsv | less -S Note that filtering gene lists by gene name as we have done above is generally not advised as we usually can’t guarantee that gene names from two different lists are compatible. Mapping between unique identifiers would be preferable. But for demonstrating the batch analysis below this should be fine… In this section we will use the ComBat-Seq tool in R (Bioconductor) to demonstrate the principles and application of batch correction. Due to the way our test data was generated (at a single center, at one time, with consistent methodology) we do NOT expect batch effects in these data. Therefore we will use a different (but highly related) dataset to demonstrate the impact of Batch correction in this module. Introduction to batch correction We highly recommend reading the entire ComBat-Seq manuscript by Yuqing Zhang, Giovanni Parmigiani, and W Evan Johnson. This manuscript does a beautiful job of briefly introducing the concept of batch correction and the differences between normalization and batch correction. If you find this exercise helpful in your research, please cite the ComBat-Seq paper (PMID: 33015620). In particular, this excerpt covers the basics: &gt; Genomic data are often produced in batches due to logistical or practical restrictions, but technical variation and differences across batches, often called batch effects, can cause significant heterogeneity across batches of data. Batch effects often result in discrepancies in the statistical distributions across data from different technical processing batches, and can have unfavorable impact on downstream biological analysis … Batch effects often cannot be fully addressed by normalization methods and procedures. The differences in the overall expression distribution of each sample across batch may be corrected by normalization methods, such as transforming the raw counts to (logarithms of) CPM, TPM or RPKM/FPKM, the trimmed mean of M values (TMM), or relative log expression (RLE). However, batch effects in composition, i.e. the level of expression of genes scaled by the total expression (coverage) in each sample, cannot be fully corrected with normalization. … While the overall distribution of samples may be normalized to the same level across batches, individual genes may still be affected by batch-level bias. Introduction to this demonstration of a batch correction approach For this exercise we have obtained public RNA-seq data from an extensive multi-platform comparison of sequencing platforms that also examined the impact of: (1) generating data at multiple sites, (2) using polyA vs ribo-reduction for enrichment, and (3) different levels of RNA degradation (PMID: 25150835): “Multi-platform and cross-methodological reproducibility of transcriptome profiling by RNA-seq in the ABRF Next-Generation Sequencing Study”. This publication used the same UHR (cancer cell lines) and HBR (brain tissue) samples we have been using throughout this course. To examine a strong batch effect, we will consider a DE analysis of UHR vs HBR where we compare Ribo-depleted (“Ribo”) and polyA-enriched (“Poly”) samples. Questions If we do DE analysis of UHR vs. HBR for replicates that are consistent with respect to Ribo-depletion or PolyA-enrichment, how does the result compare to when we mix the Ribo-depleted data and PolyA-enriched data together? If you do batch correction and redo these comparisons does it make the results more comparable? i.e. can we correct for the technical differences introduced by the library construction approach and see the same biological differences? Can we improve our statistical power by then benefitting from more samples? This is a bit contrived because there really are true biological differences expected for polyA vs. Ribo-depleted data. To counter this, we will limit the analysis to only know protein coding genes. For those genes we expect essentially the same biological answer when comparing UHR vs HBR expression patterns. This exercise is also a bit simplistic in the sense that we have perfectly balanced conditions and batches. Our conditions of interest are: HBR (brain) vs. UHR (cancer cell line) expression patterns. Our batches are the two methods of processing: Riboreduction and PolyA enrichment. And we have 4 replicates of both conditions in both batches. To perform this kind of batch correction you need at least some representation of each of your conditions of interest in each batch. So, for example, if we processed all the HBR samples with Riboreduction and all the UHR samples with PolyA enrichment, we would be unable to model the batch effect vs the condition effect. There are also other experiments from this published dataset we could use instead. For example, different levels of degradation?, data generated by different labs? Figure 1 and Figure 2 give a nice high level summary of all the data generated. We chose the Ribo-reduction and PolyA enrichment data for this exercise because we expect this would introduce a very strong batch effect. It is also the kind of thing that one could imagine really coming up in a meta-analysis where one you are pooling data from multiple studies. For example, imagine we find three published studies from three labs that all assayed some number of normal breast tissue and breast tumor. Each used a different approach to generate their data but they all involved this same biological comparison and by combining the three datasets we hope to substantially increase our power. If we can correct for batch effects arising from the three labs, this may be successful. Samples abbreviations used in the following analysis HBR -&gt; Human Brain Reference, Biological condition (pool of adult brain tissues) UHR -&gt; Universal Human Reference, Biological condition (pool of cancer cell lines) Ribo -&gt; Library preparation method using ribosomal reduction, Batch group Poly -&gt; Library preparation method using polyA enrichment, Batch group 1-4 -&gt; Replicate number: 1, 2, 3, 4. Perform principal component analysis (PCA) on the uncorrected counts PCA analysis can be used to identify potential batch effects in your data. The general strategy is to use PCA to identify patterns of similarity/difference in the expression signatures of your samples and to ask whether it appears to be driven by the expected biological conditions of interest. The PCA plot can be labeled with the biological conditions and also with potential sources of batch effects such as: sequencing source, date of data generation, lab technician, library construction kit batches, matrigel batches, mouse litters, software or instrumentation versions, etc. Principal component analysis is a dimensionality-reduction method that can be applied to large datasets (e.g. thousands of gene expression values for many samples). PCA tries to represent a large set of variables as a smaller set of variables that maximally capture the information content of the larger set. PCA is a general exploratory data analysis approach with many applications and nuances, the details of which are beyond the scope of this demonstration of batch effect correction. However, in the context of this module, PCA provides a way to visualize samples as “clusters” based on their overall pattern of gene expression values. The composition and arrangement of these clusters (usually visualized in 2D or interactive 3D plots) can be helpful in interpreting high level differences between samples and testing prior expectations about the similarity between conditions, replicates, etc. We will perform PCA analysis before AND after batch correction. Samples will be labelled according to biological condition (UHR vs HBR) and library preparation type (Ribo vs PolyA). Does the analysis below suggest that sample grouping according to PCA is being influenced by batch? Perform the following analyses in R: #Define working dir paths # datadir = &quot;/cloud/project/data/bulk_rna&quot; # outdir = &quot;/cloud/project/outdir&quot; datadir = &quot;~/workspace/rnaseq/batch_correction&quot; outdir = &quot;~/workspace/rnaseq/batch_correction/outputs&quot; if (!dir.exists(outdir)) dir.create(outdir) #load neccessary libraries library(&quot;sva&quot;) #Note this exercise requires sva (&gt;= v3.36.0) which is only available for R (&gt;= v4.x) library(&quot;ggplot2&quot;) library(&quot;gridExtra&quot;) library(&quot;edgeR&quot;) library(&quot;UpSetR&quot;) library(grid) #load in the uncorrected data as raw counts setwd(datadir) uncorrected_data = read.table(&quot;GSE48035_ILMN.Counts.SampleSubset.ProteinCodingGenes.tsv&quot;, header = TRUE, sep = &quot;\\t&quot;, as.is = c(1,2)) setwd(outdir) #simplify the names of the data columns # (A = Universal Human Reference RNA and B = Human Brain Reference RNA) # RNA = polyA enrichment and RIBO = ribosomal RNA depletion # 1, 2, 3, 4 are replicates names(uncorrected_data) = c(&quot;Gene&quot;, &quot;Chr&quot;, &quot;UHR_Ribo_1&quot;, &quot;UHR_Ribo_2&quot;, &quot;UHR_Ribo_3&quot;, &quot;UHR_Ribo_4&quot;, &quot;HBR_Ribo_1&quot;, &quot;HBR_Ribo_2&quot;, &quot;HBR_Ribo_3&quot;, &quot;HBR_Ribo_4&quot;, &quot;UHR_Poly_1&quot;, &quot;UHR_Poly_2&quot;, &quot;UHR_Poly_3&quot;, &quot;UHR_Poly_4&quot;, &quot;HBR_Poly_1&quot;, &quot;HBR_Poly_2&quot;, &quot;HBR_Poly_3&quot;, &quot;HBR_Poly_4&quot;) sample_names = names(uncorrected_data)[3:length(names(uncorrected_data))] #review data structure head(uncorrected_data) dim(uncorrected_data) #define conditions, library methods, and replicates conditions = c(&quot;UHR&quot;, &quot;UHR&quot;, &quot;UHR&quot;, &quot;UHR&quot;, &quot;HBR&quot;, &quot;HBR&quot;, &quot;HBR&quot;, &quot;HBR&quot;, &quot;UHR&quot;, &quot;UHR&quot;, &quot;UHR&quot;, &quot;UHR&quot;, &quot;HBR&quot;, &quot;HBR&quot;, &quot;HBR&quot;, &quot;HBR&quot;) library_methods = c(&quot;Ribo&quot;, &quot;Ribo&quot;, &quot;Ribo&quot;, &quot;Ribo&quot;, &quot;Ribo&quot;, &quot;Ribo&quot;, &quot;Ribo&quot;, &quot;Ribo&quot;, &quot;Poly&quot;, &quot;Poly&quot;, &quot;Poly&quot;, &quot;Poly&quot;, &quot;Poly&quot;, &quot;Poly&quot;, &quot;Poly&quot;, &quot;Poly&quot;) replicates = c(1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4) #calculate principal components for the uncorrected data pca_uncorrected_obj = prcomp(uncorrected_data[,sample_names]) #pull PCA values out of the PCA object pca_uncorrected = as.data.frame(pca_uncorrected_obj[2]$rotation) #assign labels to the data frame pca_uncorrected[,&quot;condition&quot;] = conditions pca_uncorrected[,&quot;library_method&quot;] = library_methods pca_uncorrected[,&quot;replicate&quot;] = replicates #plot the PCA #create a classic 2-dimension PCA plot (first two principal components) with conditions and library methods indicated cols &lt;- c(&quot;UHR&quot; = &quot;#481567FF&quot;, &quot;HBR&quot; = &quot;#1F968BFF&quot;) p1 = ggplot(data = pca_uncorrected, aes(x = PC1, y = PC2, color = condition, shape = library_method)) p1 = p1 + geom_point(size = 3) p1 = p1 + stat_ellipse(type = &quot;norm&quot;, linetype = 2) p1 = p1 + labs(title = &quot;PCA, RNA-seq counts for 16 HBR/UHR and Ribo/PolyA samples (uncorrected data)&quot;, color = &quot;Condition&quot;, shape=&quot;Library Method&quot;) p1 = p1 + scale_colour_manual(values = cols) Introduction to Bioconductor SVA and ComBat-Seq in R The ComBat-Seq package is made available as part of the SVA package for Surrogate Variable Analysis. This package is a collection of methods for removing batch effects and other unwanted variation in large datasets. It includes the ComBat method that has been widely used for batch correction of gene expression datasets, especially those generated on microarray platforms. ComBat-Seq is a modification of the ComBat approach. ComBat-Seq has been tailored to the count based data of bulk RNA-seq datasets. Particular advantages of the ComBat-Seq approach are that it: (1) uses a negative binomial regression model (the negative binomial distribution is thought to model the characteristics of bulk RNA-seq count data), and (2) allows the output of corrected data that retain the count nature of the data and can be safely fed into many existing methods for DE analysis (such as EdgeR and DESeq2). ComBat-Seq has a relatively short list of arguments, and for several of these we will use the default setting. Very basic documentation of these arguments can be found here and here. Our attempt to explain each of the ComBat-Seq arguments (for optional arguments, default is shown): counts. This is your matrix of gene expression read counts (raw counts). Each row is a gene, each column is a sample, and each cell has an integer count for the number of RNA-seq counts observed for that gene/sample combination. In R we want this data to be passed into ComBat-Seq in matrix format (use as.matrix() if neccessary). batch. This is a vector describing the batches you are concerned about. For example, if you have eight samples that you created RNA-seq data for, but for the first four you used library kit (A) and for the last four samples you used library kit (B). In this situation you would define your batch vector as: c(1,1,1,1,2,2,2,2). group = NULL. This is a vector describing your biological condition of interest. For example, if your experiment involved pairs of drug treated and untreated cells, and you did 4 biological replicates. You would define your group vector as: c(1,2,1,2,1,2,1,2). covar_mod = NULL. If you have multiple biological conditions of interest, you can define these with covar_mod (covariates) instead of group. For example, lets assume we have the same experiment as described above, except that we did four replicates (treated vs untreated pairs), but we alternated use of male and female cells for each of the replicates. You then would define a covariate matrix to supply to covar_mod as follows: #treatment_group = c(1,2,1,2,1,2,1,2) #sex_group = c(1,1,2,2,1,1,2,2) #covariate_matrix = cbind(treatment_group, sex_group) full_mod = TRUE. If TRUE include the condition of interest in model. Generally we believe this should be set to the default TRUE. We have yet to find a cohesive explanation for a situation where one would want this to be FALSE. shrink = FALSE. Whether to apply shrinkage on parameter estimation. shrink.disp = FALSE. Whether to apply shrinkage on dispersion. gene.subset.n = NULL. Number of genes to use in empirical Bayes estimation, only useful when shrink = TRUE. A detailed discussion of shrinkage (related to the shrink, shrink.disp, and gene_subset.n arguments is beyond the scope of this tutorial. Briefly, shrinkage refers to a set of methods that attempt to correct for gene-specific variability in the counts observed in RNA-seq datasets. More specifically, it relates to the dispersion parameter of the negative binomial distribution used to model RNA-seq count data that can suffer from overdispersion. The dispersion parameter describes how much variance deviates from the mean. In simple terms, shrinkage methods are an attempt to correct for problematic dispersion. A more detailed discussion of these statistical concepts can be found in the DESeq2 paper. However, for our purposes here, the bottom line is that the ComBat-Seq authors state that “We have shown that applying empirical Bayes shrinkage is not necessary for ComBat-seq because the approach is already sufficiently robust due to the distributional assumption.” So we will leave these arguments at their default FALSE settings. Demonstration of ComBat-Seq on the UHR/HBR data with two library types (Ribo/Poly) Continuing the R session started above, use ComBat-Seq to perform batch correction as follows: #perform the batch correction #first we need to transform the format of our groups and batches from names (e.g. &quot;UHR&quot;, &quot;HBR&quot;, etc.) to numbers (e.g. 1, 2, etc.) #in the command below &quot;sapply&quot; is used to apply the &quot;switch&quot; command to each element and convert names to numbers as we define groups = sapply(as.character(conditions), switch, &quot;UHR&quot; = 1, &quot;HBR&quot; = 2, USE.NAMES = FALSE) batches = sapply(as.character(library_methods), switch, &quot;Ribo&quot; = 1, &quot;Poly&quot; = 2, USE.NAMES = FALSE) #now run ComBat_seq corrected_data = ComBat_seq(counts = as.matrix(uncorrected_data[,sample_names]), batch = batches, group = groups) #join the gene and chromosome names onto the now corrected counts from ComBat_seq corrected_data = cbind(uncorrected_data[, c(&quot;Gene&quot;, &quot;Chr&quot;)], corrected_data) #compare dimensions of corrected and uncorrected data sets dim(uncorrected_data) dim(corrected_data) #visually compare values of corrected and uncorrected data sets head(uncorrected_data) head(corrected_data) Perform PCA analysis on the batch corrected data and contrast with the uncorrected data As performed above, use PCA to examine whether batch correction changes the grouping of samples by the expression patterns. Does the corrected data cluster according to biological condition (UHR vs HBR) better now regardless of library preparation type (Ribo vs PolyA)? #calculate principal components for the uncorrected data pca_corrected_obj = prcomp(corrected_data[, sample_names]) #pull PCA values out of the PCA object pca_corrected = as.data.frame(pca_corrected_obj[2]$rotation) #assign labels to the data frame pca_corrected[,&quot;condition&quot;] = conditions pca_corrected[,&quot;library_method&quot;] = library_methods pca_corrected[,&quot;replicate&quot;] = replicates #as above, create a PCA plot for comparison to the uncorrected data cols &lt;- c(&quot;UHR&quot; = &quot;#481567FF&quot;, &quot;HBR&quot; = &quot;#1F968BFF&quot;) p2 = ggplot(data = pca_corrected, aes(x = PC1, y = PC2, color = condition, shape = library_method)) p2 = p2 + geom_point(size = 3) p2 = p2 + stat_ellipse(type = &quot;norm&quot;, linetype = 2) p2 = p2 + labs(title = &quot;PCA, RNA-seq counts for 16 HBR/UHR and Ribo/PolyA samples (batch corrected data)&quot;, color = &quot;Condition&quot;, shape = &quot;Library Method&quot;) p2 = p2 + scale_colour_manual(values = cols) pdf(file = &quot;Uncorrected-vs-BatchCorrected-PCA.pdf&quot;) grid.arrange(p1, p2, nrow = 2) dev.off() If the above analysis worked you should have an image that looks like this: Note that prior to correction the UHR samples are separate from the HBR samples. Note that the PolyA and Ribo-reduction samples are also separated. The 16 samples group into 4 fairly distinct clusters. In other words, the overall expression signatures of these samples seem to reflect both the biological condition (UHR vs HBR) and library construction approach (Ribo vs PolyA). However, after correcting for the batch effect of library construction approach, we see a marked improvement. The library construction approach still seems to be noticeable, but the 16 samples now essentially group into two distinct clusters: HBR and UHR. Perform differential expression analysis of the corrected and uncorrected data How does batch correction influence differential gene expression results? Use UpSet plots to examine the overlap of significant DE genes found for the following comparisons: UHR-Ribo vs HBR-Ribo (same library type, 4 vs 4 replicates) UHR-Poly vs HBR-Poly (same library type, 4 vs 4 replicates) UHR-Ribo vs HBR-Poly (different library types, 4 vs 4 replicates) UHR-Poly vs HBR-Ribo (different library types, 4 vs 4 replicates) UHR-Comb vs HBR-Comb (combined library types, 8 vs 8 replicates) These five differential expression analysis comparisons will be performed with both the uncorrected and corrected data. Does correction increase agreement between the five comparisons? Does it appear to increase statistical power when combining all 8 replicates of UHR and HBR? What do we expect to see for comparisons like UHR-Ribo vs HBR-Poly before and after batch correction? Do we expect correction to increase or decrease the number of significant results? Explore these questions by continuing on with the R session started above and doing the following: #perform differential expression analysis on the uncorrected data and batch corrected data sets #first define the sets of samples to be compared to each other uhr_ribo_samples = c(&quot;UHR_Ribo_1&quot;, &quot;UHR_Ribo_2&quot;, &quot;UHR_Ribo_3&quot;, &quot;UHR_Ribo_4&quot;) uhr_poly_samples = c(&quot;UHR_Poly_1&quot;, &quot;UHR_Poly_2&quot;, &quot;UHR_Poly_3&quot;, &quot;UHR_Poly_4&quot;) hbr_ribo_samples = c(&quot;HBR_Ribo_1&quot;, &quot;HBR_Ribo_2&quot;, &quot;HBR_Ribo_3&quot;, &quot;HBR_Ribo_4&quot;) hbr_poly_samples = c(&quot;HBR_Poly_1&quot;, &quot;HBR_Poly_2&quot;, &quot;HBR_Poly_3&quot;, &quot;HBR_Poly_4&quot;) uhr_samples = c(uhr_ribo_samples, uhr_poly_samples) hbr_samples = c(hbr_ribo_samples, hbr_poly_samples) #create a function that will run edgeR (DE analysis) for a particular pair of sample sets run_edgeR = function(data, group_a_name, group_a_samples, group_b_samples, group_b_name){ #create a list of all samples for this current comparison samples_for_comparison = c(group_a_samples, group_b_samples) #define the class factor for this pair of sample sets class = factor(c(rep(group_a_name, length(group_a_samples)), rep(group_b_name, length(group_b_samples)))) #create a simplified data matrix for only these samples rawdata = data[, samples_for_comparison] #store gene names for later genes = rownames(data) gene_names = data[,&quot;Gene&quot;] #make DGElist object y = DGEList(counts = rawdata, genes = genes, group = class) #perform TMM normalization y = calcNormFactors(y) #estimate dispersion y = estimateCommonDisp(y, verbose = TRUE) y = estimateTagwiseDisp(y) #perform the differential expression test et = exactTest(y) #print number of up/down significant genes at FDR = 0.05 significance level and store the DE status in a new variable (de) de = decideTests(et, adjust.method = &quot;fdr&quot;, p = 0.05) summary(de) #create a matrix of the DE results mat = cbind( genes, gene_names, sprintf(&quot;%0.3f&quot;, log10(et$table$PValue)), sprintf(&quot;%0.3f&quot;, et$table$logFC) ) #create a version of this matrix that is limited to only the *significant* results mat = mat[as.logical(de),] #add name to the columns of the final matrix colnames(mat) &lt;- c(&quot;Gene&quot;, &quot;Gene_Name&quot;, &quot;Log10_Pvalue&quot;, &quot;Log_fold_change&quot;) return(mat) } #run the five comparisons through edgeR using the *uncorrected data* uhr_ribo_vs_hbr_ribo_uncorrected = run_edgeR(data = uncorrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_ribo_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_ribo_samples) uhr_poly_vs_hbr_poly_uncorrected = run_edgeR(data = uncorrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_poly_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_poly_samples) uhr_ribo_vs_hbr_poly_uncorrected = run_edgeR(data = uncorrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_ribo_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_poly_samples) uhr_poly_vs_hbr_ribo_uncorrected = run_edgeR(data = uncorrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_poly_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_ribo_samples) uhr_vs_hbr_uncorrected = run_edgeR(data = uncorrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_samples) #run the same five comparisons through edgeR using the *batch corrected data* uhr_ribo_vs_hbr_ribo_corrected = run_edgeR(data = corrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_ribo_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_ribo_samples) uhr_poly_vs_hbr_poly_corrected = run_edgeR(data = corrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_poly_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_poly_samples) uhr_ribo_vs_hbr_poly_corrected = run_edgeR(data = corrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_ribo_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_poly_samples) uhr_poly_vs_hbr_ribo_corrected = run_edgeR(data = corrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_poly_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_ribo_samples) uhr_vs_hbr_corrected = run_edgeR(data = corrected_data, group_a_name = &quot;UHR&quot;, group_a_samples = uhr_samples, group_b_name = &quot;HBR&quot;, group_b_samples = hbr_samples) #how much of a difference does batch correction make when doing the comparison of all UHR vs all HBR samples? dim(uhr_vs_hbr_uncorrected) dim(uhr_vs_hbr_corrected) #create upset plots to summarize the overlap between the comparisons performed above #first create upset plot from the *uncorrected* data listInput1 = list(&quot;4 UHR Ribo vs 4 HBR Ribo&quot; = uhr_ribo_vs_hbr_ribo_uncorrected[, &quot;Gene&quot;], &quot;4 UHR Poly vs 4HBR Poly&quot; = uhr_poly_vs_hbr_poly_uncorrected[, &quot;Gene&quot;], &quot;4 UHR Ribo vs 4 HBR Poly&quot; = uhr_ribo_vs_hbr_poly_uncorrected[, &quot;Gene&quot;], &quot;4 UHR Poly vs 4 HBR Ribo&quot; = uhr_poly_vs_hbr_ribo_uncorrected[, &quot;Gene&quot;], &quot;8 UHR vs 8 HBR&quot; = uhr_vs_hbr_uncorrected[, &quot;Gene&quot;]) pdf(file = &quot;Uncorrected-UpSet.pdf&quot;, onefile = FALSE) upset(fromList(listInput1), order.by = &quot;freq&quot;, number.angles = 45, point.size = 3) dev.off() #now create an upset plot from the *batch corrected* data listInput2 = list(&quot;4 UHR Ribo vs 4 HBR Ribo&quot; = uhr_ribo_vs_hbr_ribo_corrected[,&quot;Gene&quot;], &quot;4 UHR Poly vs 4 HBR Poly&quot; = uhr_poly_vs_hbr_poly_corrected[,&quot;Gene&quot;], &quot;4 UHR Ribo vs 4 HBR Poly&quot; = uhr_ribo_vs_hbr_poly_corrected[,&quot;Gene&quot;], &quot;4 UHR Poly vs 4 HBR Ribo&quot; = uhr_poly_vs_hbr_ribo_corrected[,&quot;Gene&quot;], &quot;8 UHR vs 8 HBR&quot; = uhr_vs_hbr_corrected[,&quot;Gene&quot;]) pdf(file = &quot;BatchCorrected-UpSet.pdf&quot;, onefile = FALSE) upset(fromList(listInput2), order.by = &quot;freq&quot;, number.angles=45, point.size=3) dev.off() #write out the final set of DE genes where all UHR and HBR samples were compared using the corrected data write.table(uhr_vs_hbr_corrected, file = &quot;DE_genes_uhr_vs_hbr_corrected.tsv&quot;, quote = FALSE, row.names = FALSE, sep = &quot;\\t&quot;) #To exit R type the following #quit(save = &quot;no&quot;) Note that an UpSet plot is an alternative to a Venn Diagram. It shows the overlap (intersection) between an arbitrary number of sets of values. In this case we are comparing the list of genes identified as significantly DE by five different comparisons. The black circles connected by a line indicate each combination of sets being considered. The bar graph above each column shows how many genes are shared across those sets. For example, the first column has all five black circles. The bar above that column indicates how many genes were found in all five DE comparisons performed. What differs in each comparison is: whether we are comparing replicates prepared with the same library construction approach (Ribo reduction or PolyA) or whether we are comparing data prepared with different approaches whether we are comparing 4 UHR vs 4 HBR replicates according to these library construction approaches, or pooling all 8 UHR and all 8 HBR samples (ignoring their different library types) whether we are doing these comparisons before or after batch correction Before batch correction Uncorrected-UpSet After batch correction BatchCorrected-UpSet There are several notable observations from the analysis above and the two UpSet plots. In the uncorrected data, we actually see more DE genes when comparing a mix of library contruction approaches (e.g. UHR-Ribo vs UHR-Poly). There are likely false positives in these results. i.e. Genes that appear to be different between UHR and HBR, but where the difference is actually caused by differences in the library preparation not the biology. If we combine all 8 samples together for each biological condition we can see that we actually get considerably fewer significant genes with the uncorrected data. Presumably this is because we are now introducing noise caused by a mix of different library construction approaches and this impacts the statistical analysis (more variability). When we apply batch correction, we see that now all five comparisons tend to agree with each other for the most part on what genes are differentially expressed. Overall agreement across comparisons is improved. With the batch corrected data we now see that combining all 8 samples actually improves statistical power and results in a larger number of significant DE genes relative to the 4 vs 4 comparisons. This is presumably the most accurate result of all the comparisons we did. In the previous Team Assignment, teams have trimmed, aligned, visualized and performed QC evaluations of their RNAseq data. Using this aligned data, students will now apply the concepts they have learned regarding expression estimation and differential expression analysis. To complete this assignment, students will need to review commands we performed in earlier sections. Before starting this team exercise, first find the folder containing your 6 aligned bam files (along with the index files). Note: In the previous exercise, you merged bams files for easy visualization in IGV, we will not be using that for expression and de analysis. Part I - Expression Estimation Goals: Familiarize yourself with Stringtie options Run Stringtie to obtain expression values Optionally, run htseq-count to obtain raw count values Remember to do this in a new directory under team_exercises mkdir -p $RNA_HOME/team_exercise/expression/ cd $RNA_HOME/team_exercise/expression/ Teams can now use Stringtie to estimate the gene expression levels in their sample and answer the following questions: Q1. Based on your stringtie results, what are the top 5 genes with highest average expression levels across all knockout samples? What about in your rescue samples? (Hint: You can use R, command-line tools, or download files to your desktop for this analysis) Part II - Differential Expression Goals: Perform differential analysis between the knockout and rescued samples Check which genes are differentially expressed with statistical significance Visualize DE results. For example you could create an MDS plot, x-y scatter plot of mean KO vs Rescue FPKM values, or a volcano plot. Teams will now use ballgown to perform differential expression analysis followed by visualization of their results. Alternatively, if raw counts were generated teams can use edgeR or DESeq2 for differential expression analysis. Hint: You will should create a separate directory under your team_exercises folder for your ballgown (or edgeR or DESeq2) outputs. Q2. How many significant differentially expressed genes do you observe? Q3. By referring back to the supplementary tutorial in the DE Visualization Module, can you construct a volcano plot showcasing the significantly de genes? Additionally, students should feel free to explore other visualization methods, including those they may have used in past research experiences and share with the class. Presenting Your Results At the end of this team exercise, students will show how they visualized their differential expression results to the class. Preamble: Note that the following integrated assignment asks you to work on new RNA-seq data and apply the concepts you have learned up to this point. To complete this assignment you will need to review commands we performed in many of the earlier sections. Try to construct these commands on your own and get all the way to the end of the assignment. If you get very stuck or would like to compare your solutions to those suggested by the instructors, refer to the answers page. The integrated assignment answers page is an expanded version of this page with all of the questions plus detailed code solutions to all problems. Avoid the temptation to look at it without trying on your own. Background: Cell lines are often used to study different experimental conditions and to study the function of specific genes by various perturbation approaches. One such type of study involves knocking down expression of a target of interest by shRNA and then using RNA-seq to measure the impact on gene expression. These eperiments often include use of a control shRNA to account for any expression changes that may occur from just the introduction of these molecules. Differential expression is performed by comparing biological replicates of shRNA knockdown vs shRNA control. Objectives: In this assignment, we will be using a subset of the GSE114360 dataset, which consists of 6 RNA-seq datasets generated from a cell line (3 transfected with shRNA, and 3 controls). Our goal will be to determine differentially expressed genes. Experimental information and other things to keep in mind: The libraries are prepared as paired end. The samples are sequenced on an Illumina 4000. Each read is 150 bp long The dataset is located here: GSE114360 3 samples transfected with target shRNA and 3 samples with control shRNA Libraries were prepared using standard Illumina protocols For this exercise we will be using a subset of the reads (first 1,000,000 reads from each pair). The files are named based on their SRR id’s, and obey the following key: SRR7155055 = CBSLR knockdown sample 1 (T1 - aka transfected 1) SRR7155056 = CBSLR knockdown sample 2 (T2 - aka transfected 2) SRR7155057 = CBSLR knockdown sample 3 (T3 - aka transfected 3) SRR7155058 = control sample 1 (C1 - aka control 1) SRR7155059 = control sample 2 (C2 - aka control 2) SRR7155060 = control sample 3 (C3 - aka control 3) Experimental descriptions from the study authors: Experimental details from the paper: “An RNA transcriptome-sequencing analysis was performed in shRNA-NC or shRNA-CBSLR-1 MKN45 cells cultured under hypoxic conditions for 24 h (Fig. 2A).” Experimental details from the GEO submission: “An RNA transcriptome sequencing analysis was performed in MKN45 cells that were transfected with tcons_00001221 shRNA or control shRNA.” Note that according to GeneCards and HGNC, CBSLR and tcons_00001221 refer to the same gene. PART 0 : Obtaining Data and References Goals: Obtain the files necessary for data processing Familiarize yourself with reference and annotation file format Familiarize yourself with sequence FASTQ format Create a working directory ~/workspace/rnaseq/integrated_assignment/ to store this exercise. Then create a unix environment variable named RNA_INT_ASSIGNMENT that stores this path for convenience in later commands. export RNA_HOME=~/workspace/rnaseq cd $RNA_HOME mkdir -p ~/workspace/rnaseq/integrated_assignment/ export RNA_INT_DIR=~/workspace/rnaseq/integrated_assignment Obtain reference, annotation, adapter and data files and place them in the integrated assignment directory Remember: when initiating an environment variable, we do NOT need the $; however, everytime we call the variable, it needs to be preceeded by a $. echo $RNA_INT_DIR cd $RNA_INT_DIR wget http://genomedata.org/rnaseq-tutorial/Integrated_Assignment_RNA_Data.tar.gz Q1.) How many items are there under the “reference” directory (counting all files in all sub-directories)? What if this reference file was not provided for you - how would you obtain/create a reference genome fasta file. How about the GTF transcripts file from Ensembl? Q2.) How many exons does the gene SOX4 have? How about the longest isoform of PCA3? Q3.) How many samples do you see under the data directory? NOTE: The fastq files you have copied above contain only the first 1,000,000 reads. Keep this in mind when you are combing through the results of the differential expression analysis. Part 1 : Data preprocessing Goals: Run a quality check with fastqc before and after trimming Familiarize yourself with the options for fastqc to be able to redirect your output Perform adapter trimming and data cleanup on your data using fastp Familiarize yourself with the output metrics from adapter trimming Examine fastqc and/or multiqc reports for the pre- and post-trimmed data Q4.) What metrics, if any, have the samples failed? Are the errors related? Q5.) What average percentage of reads remain after adapter trimming? Why do reads get tossed out? Q6.) What sample has the largest number of reads after trimming/cleanup? Part 2: Data alignment Goals: - Familiarize yourself with HISAT2 alignment options - Perform alignments - Obtain alignment summary - Convert your alignment into compressed bam format Q7.) How would you obtain summary statistics for each aligned file? Q8.) Approximately how much space is saved by converting the sam to a bam format? In order to make visualization easier, you should now merge each of your replicate sample bams into one combined BAM for each condition. Make sure to index these bams afterwards to be able to view them on IGV. Try viewing genes such as TP53 to get a sense of how the data is aligned. To do this: - Load up IGV - Change the reference genome to “Human hg38” in the top-left category - Click on File &gt; Load from URL, and in the File URL enter: “http:///rnaseq/integrated_assignment/alignments/transfected.bam”. Repeat this step and enter “http:///rnaseq/integrated_assignment/alignments/control.bam” to load the other bam. - Right-click on the alignments track in the middle, and Group alignments by “Library” - Jump to TP53 by typing it into the search bar above Q9.) What portion of the gene do the reads seem to be piling up on? What would be different if we were viewing whole-genome sequencing data? Q10.) What are the lines connecting the reads trying to convey? Part 3: Expression Estimation Goals: Familiarize yourself with Stringtie options Run Stringtie to obtain expression values Obtain expression values for the gene SOX4 Create an expression results directory, run Stringtie on all samples, and store the results in appropriately named subdirectories in this results dir Q11.) How can you obtain the expression of the gene SOX4 across the transfected and control samples? Part 4: Differential Expression Analysis Goals: Perform differential analysis between the transfected and control samples Adapt the R tutorial code that was used in Differential Expression section. Modify it to work on these data (which are also a 3x3 replicate comparison of two conditions). Q12.) Are there any significant differentially expressed genes? How many in total do you see? If we expected SOX4 to be differentially expressed, why don’t we see it in this case? Part 5: Differential Expression Analysis Visualization Q13.) What plots can you generate to help you visualize this gene expression profile? Hint, a volcano plot is popular approach to provide a high level summary of a differential expression analysis. Refer to the DE Visualization section for example R code. "]]
